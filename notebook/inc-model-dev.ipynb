{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a3f8778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import wandb\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29847982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger(name=__name__):\n",
    "    \"\"\"\n",
    "    Sets up a logger that outputs to the console (stdout).\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(name)\n",
    "    if not logger.handlers:\n",
    "        logger.setLevel(logging.INFO)\n",
    "        handler = logging.StreamHandler(sys.stdout)\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "    return logger\n",
    "\n",
    "logger = setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d93a317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:11:58,466 - INFO - Training images shape: torch.Size([241, 1, 224, 224])\n",
      "2025-12-13 15:11:58,468 - INFO - Training labels shape: torch.Size([241])\n",
      "2025-12-13 15:11:58,468 - INFO - Label mapping: {np.str_('1_Pronacio'): 0, np.str_('2_Neutralis'): 1, np.str_('3_Szupinacio'): 2}\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_folder = \"../data\"\n",
    "preped_folder = os.path.join(data_folder, \"_preped\")\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(data_folder, 'train_data.csv')).values.tolist()\n",
    "test_data = pd.read_csv(os.path.join(data_folder, 'test_data.csv')).values.tolist()\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to consistent size\n",
    "    transforms.ToTensor(),           # Convert to tensor [0, 1]\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for img_name, label in train_data:\n",
    "    img_path = os.path.join(preped_folder, img_name)\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('L') # Convert to grayscale\n",
    "        img_tensor = transform(img)\n",
    "        x_train.append(img_tensor)\n",
    "        y_train.append(label)\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Error loading {img_name}: {e}\")\n",
    "\n",
    "# Stack into tensors\n",
    "x_train_tensor = torch.stack(x_train)\n",
    "logger.info(f\"Training images shape: {x_train_tensor.shape}\")\n",
    "\n",
    "# Encode labels to integers\n",
    "label_to_idx = {label: idx for idx, label in enumerate(np.unique(y_train))}\n",
    "y_train_encoded = [label_to_idx[label] for label in y_train]\n",
    "y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.long)\n",
    "\n",
    "logger.info(f\"Training labels shape: {y_train_tensor.shape}\")\n",
    "logger.info(f\"Label mapping: {label_to_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f39e88ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:04,654 - INFO - Test images shape: torch.Size([49, 1, 224, 224])\n",
      "2025-12-13 15:12:04,655 - INFO - Test labels shape: torch.Size([49])\n"
     ]
    }
   ],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for img_name, label in test_data:\n",
    "    img_path = os.path.join(preped_folder, img_name)\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('L') # Convert to grayscale\n",
    "        img_tensor = transform(img)\n",
    "        x_test.append(img_tensor)\n",
    "        y_test.append(label)\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Error loading {img_name}: {e}\")\n",
    "\n",
    "x_test_tensor = torch.stack(x_test)\n",
    "logger.info(f\"Test images shape: {x_test_tensor.shape}\")\n",
    "y_test_encoded = [label_to_idx[label] for label in y_test]\n",
    "y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long)\n",
    "\n",
    "logger.info(f\"Test labels shape: {y_test_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f6197a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:04,707 - INFO - CUDA available: True\n",
      "2025-12-13 15:12:04,708 - INFO - Number of GPUs: 1\n",
      "2025-12-13 15:12:04,714 - INFO - \n",
      "GPU 0: NVIDIA GeForce RTX 4060\n",
      "2025-12-13 15:12:04,714 - INFO -   Memory: 8.00 GB\n",
      "2025-12-13 15:12:04,715 - INFO -   Compute Capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    logger.info(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        logger.info(f\"\\nGPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        logger.info(f\"  Memory: {props.total_memory / 1024**3:.2f} GB\")\n",
    "        logger.info(f\"  Compute Capability: {props.major}.{props.minor}\")\n",
    "else:\n",
    "    logger.info(\"CUDA not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2a044d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 70\n",
    "device = 'cuda' \n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1a2c812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Win 10\\_netrc\n"
     ]
    }
   ],
   "source": [
    "# wandb login an init\n",
    "# Login to wandb with API key\n",
    "load_dotenv()\n",
    "wandb.login(key=os.getenv(\"wandbKey\"))\n",
    "\n",
    "def init_wandb():\n",
    "    # Initialize wandb project\n",
    "    wandb.init(\n",
    "        project=\"ankle-align-inc-model\",\n",
    "        config={\n",
    "            \"batch_size\": batch_size,\n",
    "            \"num_epochs\": num_epochs,\n",
    "      \n",
    "            \"architecture\": \"Custom CNN\",\n",
    "            \"dataset\": \"AnkleAlign\",\n",
    "            \"optimizer\": \"Adam\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd9b01ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [16, 3]                   --\n",
       "├─Conv2d: 1-1                            [16, 8, 112, 112]         80\n",
       "├─ReLU: 1-2                              [16, 8, 112, 112]         --\n",
       "├─Conv2d: 1-3                            [16, 16, 56, 56]          1,168\n",
       "├─ReLU: 1-4                              [16, 16, 56, 56]          --\n",
       "├─Conv2d: 1-5                            [16, 32, 28, 28]          4,640\n",
       "├─ReLU: 1-6                              [16, 32, 28, 28]          --\n",
       "├─AdaptiveAvgPool2d: 1-7                 [16, 32, 1, 1]            --\n",
       "├─Flatten: 1-8                           [16, 32]                  --\n",
       "├─Linear: 1-9                            [16, 128]                 4,224\n",
       "├─ReLU: 1-10                             [16, 128]                 --\n",
       "├─Linear: 1-11                           [16, 64]                  8,256\n",
       "├─ReLU: 1-12                             [16, 64]                  --\n",
       "├─Linear: 1-13                           [16, 3]                   195\n",
       "==========================================================================================\n",
       "Total params: 18,563\n",
       "Trainable params: 18,563\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 133.07\n",
       "==========================================================================================\n",
       "Input size (MB): 3.21\n",
       "Forward/backward pass size (MB): 22.50\n",
       "Params size (MB): 0.07\n",
       "Estimated Total Size (MB): 25.79\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net0 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1),   # 224x224 -> 112x112\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),  # 112x112 -> 56x56\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # 56x56 -> 28x28\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.AdaptiveAvgPool2d(1),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(32, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 3)                       # Output layer     \n",
    ").to(device)\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "net0.apply(init_weights)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net0.parameters(), lr=0.01)\n",
    "\n",
    "summary(net0, input_size=(batch_size, 1, 224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e528be05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Win 10\\Desktop\\BME\\DeepL\\BMEVITMMA18_Deep-Learning_AnkleAlign_D6AE9F\\notebook\\wandb\\run-20251213_151206-w6xu5w2q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/w6xu5w2q' target=\"_blank\">major-dawn-1</a></strong> to <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/w6xu5w2q' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/w6xu5w2q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 70/70 [00:00<00:00, 180.74it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train_loss</td><td>███▇▇▇▆▆▆▅▅▅▄▃▅▄▄▃▂▃▃▃▂▂▂▂▂▂▂▂▁▁▁▂▄▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>70</td></tr><tr><td>train_loss</td><td>0.07373</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">major-dawn-1</strong> at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/w6xu5w2q' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/w6xu5w2q</a><br> View project at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251213_151206-w6xu5w2q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0581742525100708, 0.9670201539993286, 0.9727962017059326, 0.9077773690223694, 0.9199650287628174, 0.9004878997802734, 0.8884644508361816, 0.8728632926940918, 0.8450402021408081, 0.8295108675956726, 0.8084721565246582, 0.7869530320167542, 0.7585417032241821, 0.7349890470504761, 0.7065781354904175, 0.6773555278778076, 0.6501045227050781, 0.6146928071975708, 0.5823861360549927, 0.5504868030548096, 0.5249641537666321, 0.4958270192146301, 0.45998427271842957, 0.42188993096351624, 0.3856785297393799, 0.4135778546333313, 0.7269619107246399, 0.48664823174476624, 0.5767006874084473, 0.48961764574050903, 0.3356057405471802, 0.4124259054660797, 0.41717058420181274, 0.5303608179092407, 0.42846354842185974, 0.3833099603652954, 0.2570996582508087, 0.3637549877166748, 0.3280019462108612, 0.30245280265808105, 0.34380239248275757, 0.2971813976764679, 0.23902207612991333, 0.26879552006721497, 0.22528496384620667, 0.22261683642864227, 0.2360658049583435, 0.1880386918783188, 0.21882149577140808, 0.1755811721086502, 0.16684138774871826, 0.17640420794487, 0.14062026143074036, 0.1665807068347931, 0.1365821212530136, 0.14681263267993927, 0.11174613237380981, 0.11094030737876892, 0.14383555948734283, 0.08581644296646118, 0.2076040804386139, 0.41441458463668823, 0.18768414855003357, 0.21766608953475952, 0.09130329638719559, 0.15008902549743652, 0.1320047378540039, 0.07323625683784485, 0.14136676490306854, 0.07373499870300293]\n"
     ]
    }
   ],
   "source": [
    "# Trying to overfit one batch\n",
    "init_wandb()\n",
    "one_batch = next(iter(train_loader))\n",
    "images, labels = one_batch\n",
    "\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "loss_values = []\n",
    "net0.train()\n",
    "for epoch in tqdm(range(num_epochs), desc='Training model'):\n",
    "        pred_logits = net0(images)\n",
    "        loss = loss_fn(pred_logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_values.append(loss.item())\n",
    "        wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": loss.item()\n",
    "            })\n",
    "        \n",
    "wandb.finish()\n",
    "print(loss_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e6a9d4",
   "metadata": {},
   "source": [
    "Net0 looks the most simply CNN which could learn on a 16 image batch, and overfit on this data. Smaller networks were not sifficent enaught to learon on 16 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9f0ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(network, optimizer, loss_fn, enable_early_stopping=False, patience=5):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    loss_values = []\n",
    "\n",
    "    if enable_early_stopping:\n",
    "        early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "    network.train()\n",
    "    for epoch in tqdm(range(num_epochs), desc='Training model'):\n",
    "        network.train()\n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "        for images, target_labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            target_labels = target_labels.to(device)\n",
    "\n",
    "            pred_logits = network(images)\n",
    "            loss = loss_fn(pred_logits, target_labels)\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        avg_train_loss = epoch_loss / num_batches\n",
    "\n",
    "        if enable_early_stopping:\n",
    "            network.eval()\n",
    "            val_loss = 0.0\n",
    "            val_batches = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for images, target_labels in val_loader:\n",
    "                    images = images.to(device)\n",
    "                    target_labels = target_labels.to(device)\n",
    "                    \n",
    "                    pred_logits = network(images)\n",
    "                    loss = loss_fn(pred_logits, target_labels)\n",
    "                    val_loss += loss.item()\n",
    "                    val_batches += 1\n",
    "                    \n",
    "                    _, predicted = torch.max(pred_logits, 1)\n",
    "                    total += target_labels.size(0)\n",
    "                    correct += (predicted == target_labels).sum().item()\n",
    "            \n",
    "            avg_val_loss = val_loss / val_batches\n",
    "            val_accuracy = correct / total\n",
    "\n",
    "        # Log metrics\n",
    "        if enable_early_stopping:\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": avg_train_loss,\n",
    "                \"val_loss\": avg_val_loss,\n",
    "                \"val_accuracy\": val_accuracy\n",
    "            })\n",
    "        else:\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": avg_train_loss\n",
    "            })\n",
    "        loss_values.append(avg_train_loss)\n",
    "        \n",
    "        if enable_early_stopping:\n",
    "            logger.info(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "        else:\n",
    "            logger.info(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if enable_early_stopping:\n",
    "            early_stopping(avg_val_loss, network)\n",
    "            if early_stopping.early_stop:\n",
    "                logger.info(\"Early stopping triggered\")\n",
    "                network.load_state_dict(early_stopping.best_model)\n",
    "                break\n",
    "    \n",
    "    # Load best model\n",
    "    if enable_early_stopping and early_stopping.best_model is not None:\n",
    "        network.load_state_dict(early_stopping.best_model)\n",
    "        logger.info(\"Loaded best model weights\")\n",
    "\n",
    "    logger.info(loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "517e5537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(network):\n",
    "    # Training score\n",
    "    true_labels = y_test_encoded\n",
    "    predicted_labels = []\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = network(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    balanced_accuracy = balanced_accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "    logger.info(f\"network accuracy: {balanced_accuracy * 100:.2f}%\")\n",
    "    logger.info(f\"network precision: {precision * 100:.2f}%\")\n",
    "    logger.info(f\"network recall: {recall * 100:.2f}%\")\n",
    "    logger.info(f\"network F1 score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    logger.info(f\"Detailed Classification Report: \\n{classification_report(true_labels, predicted_labels)}\")\n",
    "\n",
    "    # Log test metrics\n",
    "    wandb.log({\n",
    "        \"test_accuracy\": balanced_accuracy,\n",
    "        \"test_precision\": precision,\n",
    "        \"test_recall\": recall,\n",
    "        \"test_f1\": f1\n",
    "    })\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56f0bf57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Win 10\\Desktop\\BME\\DeepL\\BMEVITMMA18_Deep-Learning_AnkleAlign_D6AE9F\\notebook\\wandb\\run-20251213_151212-6393r66f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/6393r66f' target=\"_blank\">autumn-lion-2</a></strong> to <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/6393r66f' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/6393r66f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:13,034 - INFO - Epoch 1/70, Train Loss: 2.8289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   1%|▏         | 1/70 [00:00<00:13,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:13,177 - INFO - Epoch 2/70, Train Loss: 1.0543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   3%|▎         | 2/70 [00:00<00:11,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:13,324 - INFO - Epoch 3/70, Train Loss: 0.9901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   4%|▍         | 3/70 [00:00<00:10,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:13,445 - INFO - Epoch 4/70, Train Loss: 0.9886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   6%|▌         | 4/70 [00:00<00:09,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:13,521 - INFO - Epoch 5/70, Train Loss: 1.0537\n",
      "2025-12-13 15:12:13,603 - INFO - Epoch 6/70, Train Loss: 1.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   9%|▊         | 6/70 [00:00<00:06,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:13,685 - INFO - Epoch 7/70, Train Loss: 0.9860\n",
      "2025-12-13 15:12:13,770 - INFO - Epoch 8/70, Train Loss: 0.9730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  11%|█▏        | 8/70 [00:00<00:06, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:13,856 - INFO - Epoch 9/70, Train Loss: 0.9650\n",
      "2025-12-13 15:12:13,940 - INFO - Epoch 10/70, Train Loss: 0.9724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  14%|█▍        | 10/70 [00:01<00:05, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:14,025 - INFO - Epoch 11/70, Train Loss: 0.9679\n",
      "2025-12-13 15:12:14,104 - INFO - Epoch 12/70, Train Loss: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  17%|█▋        | 12/70 [00:01<00:05, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:14,191 - INFO - Epoch 13/70, Train Loss: 0.9848\n",
      "2025-12-13 15:12:14,277 - INFO - Epoch 14/70, Train Loss: 0.9675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  20%|██        | 14/70 [00:01<00:04, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:14,359 - INFO - Epoch 15/70, Train Loss: 0.9952\n",
      "2025-12-13 15:12:14,445 - INFO - Epoch 16/70, Train Loss: 0.9745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  23%|██▎       | 16/70 [00:01<00:04, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:14,530 - INFO - Epoch 17/70, Train Loss: 0.9400\n",
      "2025-12-13 15:12:14,611 - INFO - Epoch 18/70, Train Loss: 0.9567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  26%|██▌       | 18/70 [00:01<00:04, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:14,694 - INFO - Epoch 19/70, Train Loss: 0.9402\n",
      "2025-12-13 15:12:14,771 - INFO - Epoch 20/70, Train Loss: 0.9566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  29%|██▊       | 20/70 [00:01<00:04, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:14,855 - INFO - Epoch 21/70, Train Loss: 0.9357\n",
      "2025-12-13 15:12:14,934 - INFO - Epoch 22/70, Train Loss: 0.9241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  31%|███▏      | 22/70 [00:02<00:03, 12.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:15,010 - INFO - Epoch 23/70, Train Loss: 0.9783\n",
      "2025-12-13 15:12:15,093 - INFO - Epoch 24/70, Train Loss: 0.9329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  34%|███▍      | 24/70 [00:02<00:03, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:15,176 - INFO - Epoch 25/70, Train Loss: 0.9299\n",
      "2025-12-13 15:12:15,261 - INFO - Epoch 26/70, Train Loss: 0.9176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  37%|███▋      | 26/70 [00:02<00:03, 12.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:15,350 - INFO - Epoch 27/70, Train Loss: 0.8957\n",
      "2025-12-13 15:12:15,431 - INFO - Epoch 28/70, Train Loss: 0.8998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  40%|████      | 28/70 [00:02<00:03, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:15,512 - INFO - Epoch 29/70, Train Loss: 0.8832\n",
      "2025-12-13 15:12:15,597 - INFO - Epoch 30/70, Train Loss: 0.8854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  43%|████▎     | 30/70 [00:02<00:03, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:15,679 - INFO - Epoch 31/70, Train Loss: 0.8916\n",
      "2025-12-13 15:12:15,760 - INFO - Epoch 32/70, Train Loss: 0.8682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  46%|████▌     | 32/70 [00:02<00:03, 12.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:15,847 - INFO - Epoch 33/70, Train Loss: 0.8547\n",
      "2025-12-13 15:12:15,928 - INFO - Epoch 34/70, Train Loss: 0.8549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  49%|████▊     | 34/70 [00:03<00:02, 12.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:16,004 - INFO - Epoch 35/70, Train Loss: 0.8424\n",
      "2025-12-13 15:12:16,091 - INFO - Epoch 36/70, Train Loss: 0.9325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  51%|█████▏    | 36/70 [00:03<00:02, 12.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:16,180 - INFO - Epoch 37/70, Train Loss: 0.9609\n",
      "2025-12-13 15:12:16,261 - INFO - Epoch 38/70, Train Loss: 0.8654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  54%|█████▍    | 38/70 [00:03<00:02, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:16,348 - INFO - Epoch 39/70, Train Loss: 0.8585\n",
      "2025-12-13 15:12:16,432 - INFO - Epoch 40/70, Train Loss: 0.8291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  57%|█████▋    | 40/70 [00:03<00:02, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:16,519 - INFO - Epoch 41/70, Train Loss: 0.8535\n",
      "2025-12-13 15:12:16,600 - INFO - Epoch 42/70, Train Loss: 0.7929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  60%|██████    | 42/70 [00:03<00:02, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:16,681 - INFO - Epoch 43/70, Train Loss: 0.7591\n",
      "2025-12-13 15:12:16,761 - INFO - Epoch 44/70, Train Loss: 0.8933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  63%|██████▎   | 44/70 [00:03<00:02, 12.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:16,840 - INFO - Epoch 45/70, Train Loss: 0.8936\n",
      "2025-12-13 15:12:16,921 - INFO - Epoch 46/70, Train Loss: 0.8291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  66%|██████▌   | 46/70 [00:04<00:01, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:16,999 - INFO - Epoch 47/70, Train Loss: 0.7428\n",
      "2025-12-13 15:12:17,081 - INFO - Epoch 48/70, Train Loss: 0.7234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  69%|██████▊   | 48/70 [00:04<00:01, 12.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:17,165 - INFO - Epoch 49/70, Train Loss: 0.7270\n",
      "2025-12-13 15:12:17,249 - INFO - Epoch 50/70, Train Loss: 0.8925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  71%|███████▏  | 50/70 [00:04<00:01, 12.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:17,335 - INFO - Epoch 51/70, Train Loss: 0.7995\n",
      "2025-12-13 15:12:17,421 - INFO - Epoch 52/70, Train Loss: 0.8590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  74%|███████▍  | 52/70 [00:04<00:01, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:17,499 - INFO - Epoch 53/70, Train Loss: 0.7459\n",
      "2025-12-13 15:12:17,583 - INFO - Epoch 54/70, Train Loss: 0.6258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  77%|███████▋  | 54/70 [00:04<00:01, 12.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:17,678 - INFO - Epoch 55/70, Train Loss: 0.6511\n",
      "2025-12-13 15:12:17,774 - INFO - Epoch 56/70, Train Loss: 0.6691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  80%|████████  | 56/70 [00:04<00:01, 11.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:17,876 - INFO - Epoch 57/70, Train Loss: 0.6153\n",
      "2025-12-13 15:12:17,962 - INFO - Epoch 58/70, Train Loss: 0.6537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  83%|████████▎ | 58/70 [00:05<00:01, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:18,044 - INFO - Epoch 59/70, Train Loss: 0.5918\n",
      "2025-12-13 15:12:18,127 - INFO - Epoch 60/70, Train Loss: 0.5144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  86%|████████▌ | 60/70 [00:05<00:00, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:18,214 - INFO - Epoch 61/70, Train Loss: 0.4706\n",
      "2025-12-13 15:12:18,305 - INFO - Epoch 62/70, Train Loss: 0.5963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  89%|████████▊ | 62/70 [00:05<00:00, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:18,385 - INFO - Epoch 63/70, Train Loss: 0.5442\n",
      "2025-12-13 15:12:18,462 - INFO - Epoch 64/70, Train Loss: 0.4984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  91%|█████████▏| 64/70 [00:05<00:00, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:18,543 - INFO - Epoch 65/70, Train Loss: 0.4310\n",
      "2025-12-13 15:12:18,626 - INFO - Epoch 66/70, Train Loss: 0.5272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  94%|█████████▍| 66/70 [00:05<00:00, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:18,703 - INFO - Epoch 67/70, Train Loss: 0.7059\n",
      "2025-12-13 15:12:18,788 - INFO - Epoch 68/70, Train Loss: 0.5550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  97%|█████████▋| 68/70 [00:05<00:00, 12.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:18,868 - INFO - Epoch 69/70, Train Loss: 0.4919\n",
      "2025-12-13 15:12:18,953 - INFO - Epoch 70/70, Train Loss: 0.5344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 70/70 [00:06<00:00, 11.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:18,955 - INFO - [2.8288876973092556, 1.0543148964643478, 0.9900975152850151, 0.9886178970336914, 1.0536944270133972, 1.0068634450435638, 0.986005425453186, 0.9730230793356895, 0.9650396108627319, 0.9724284037947655, 0.9679272286593914, 0.9688276834785938, 0.984809335321188, 0.9674697928130627, 0.9952278211712837, 0.9745336249470711, 0.9400264099240303, 0.9566500522196293, 0.9401758387684822, 0.9565533101558685, 0.9356943182647228, 0.9241379201412201, 0.9782601222395897, 0.932905524969101, 0.9299440570175648, 0.9175514318048954, 0.8956962414085865, 0.8998011834919453, 0.8831529654562473, 0.885401364415884, 0.8916499838232994, 0.8682254068553448, 0.8547017276287079, 0.8548958227038383, 0.84241608902812, 0.9325481355190277, 0.9608963802456856, 0.8653992414474487, 0.8585188575088978, 0.8291248418390751, 0.8535263873636723, 0.7928954921662807, 0.7590807257220149, 0.8933034278452396, 0.8935810551047325, 0.8291191644966602, 0.7427658755332232, 0.72342748939991, 0.7269770242273808, 0.8925131410360336, 0.7995056062936783, 0.858989629894495, 0.745880326256156, 0.6258188027422875, 0.651131046935916, 0.6691064648330212, 0.6152986958622932, 0.6537324953824282, 0.5918324645608664, 0.5143677243031561, 0.470568140260184, 0.5962535440921783, 0.5441694362089038, 0.49841908004600555, 0.4309852970764041, 0.527168108150363, 0.7058604191988707, 0.5550454398744478, 0.4918615650385618, 0.5344212744385004]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "init_wandb()\n",
    "train_model(net0, optimizer, loss_fn, enable_early_stopping=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4409bad",
   "metadata": {},
   "source": [
    "Net0 can learn on one batch of 16 images, but can not learn on all the provided train data, to simple for 200+ images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36e5e606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [16, 3]                   --\n",
       "├─Conv2d: 1-1                            [16, 8, 112, 112]         80\n",
       "├─ReLU: 1-2                              [16, 8, 112, 112]         --\n",
       "├─Conv2d: 1-3                            [16, 16, 56, 56]          1,168\n",
       "├─ReLU: 1-4                              [16, 16, 56, 56]          --\n",
       "├─Conv2d: 1-5                            [16, 32, 28, 28]          4,640\n",
       "├─ReLU: 1-6                              [16, 32, 28, 28]          --\n",
       "├─Conv2d: 1-7                            [16, 32, 14, 14]          9,248\n",
       "├─ReLU: 1-8                              [16, 32, 14, 14]          --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [16, 32, 1, 1]            --\n",
       "├─Flatten: 1-10                          [16, 32]                  --\n",
       "├─Linear: 1-11                           [16, 128]                 4,224\n",
       "├─ReLU: 1-12                             [16, 128]                 --\n",
       "├─Linear: 1-13                           [16, 64]                  8,256\n",
       "├─ReLU: 1-14                             [16, 64]                  --\n",
       "├─Linear: 1-15                           [16, 3]                   195\n",
       "==========================================================================================\n",
       "Total params: 27,811\n",
       "Trainable params: 27,811\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 162.07\n",
       "==========================================================================================\n",
       "Input size (MB): 3.21\n",
       "Forward/backward pass size (MB): 23.31\n",
       "Params size (MB): 0.11\n",
       "Estimated Total Size (MB): 26.63\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1),   # 224x224 -> 112x112   // (3x3x1)x8\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),  # 112x112 -> 56x56     // (3x3x8)x16\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # 56x56 -> 28x28      // (3x3x16)x32\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),  # 28x28 -> 14x14      // (3x3x32)x32\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.AdaptiveAvgPool2d(1),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(32, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 3)                       # Output layer     \n",
    ").to(device)\n",
    "\n",
    "net1.apply(init_weights)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net1.parameters(), lr=0.001)\n",
    "\n",
    "summary(net1, input_size=(batch_size, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e0f02b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train_loss</td><td>█▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>70</td></tr><tr><td>train_loss</td><td>0.53442</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">autumn-lion-2</strong> at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/6393r66f' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/6393r66f</a><br> View project at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251213_151212-6393r66f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Win 10\\Desktop\\BME\\DeepL\\BMEVITMMA18_Deep-Learning_AnkleAlign_D6AE9F\\notebook\\wandb\\run-20251213_151219-kl5pl0df</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/kl5pl0df' target=\"_blank\">polar-glitter-3</a></strong> to <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/kl5pl0df' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/kl5pl0df</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:22,045 - INFO - Epoch 1/70, Train Loss: 1.0980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   1%|▏         | 1/70 [00:00<00:14,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:22,222 - INFO - Epoch 2/70, Train Loss: 0.9738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   3%|▎         | 2/70 [00:00<00:13,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:22,370 - INFO - Epoch 3/70, Train Loss: 0.9853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   4%|▍         | 3/70 [00:00<00:11,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:22,473 - INFO - Epoch 4/70, Train Loss: 1.0332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   6%|▌         | 4/70 [00:00<00:09,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:22,556 - INFO - Epoch 5/70, Train Loss: 0.9755\n",
      "2025-12-13 15:12:22,643 - INFO - Epoch 6/70, Train Loss: 0.9703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   9%|▊         | 6/70 [00:00<00:07,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:22,734 - INFO - Epoch 7/70, Train Loss: 0.9599\n",
      "2025-12-13 15:12:22,845 - INFO - Epoch 8/70, Train Loss: 0.9548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  11%|█▏        | 8/70 [00:01<00:06,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:22,939 - INFO - Epoch 9/70, Train Loss: 1.0313\n",
      "2025-12-13 15:12:23,027 - INFO - Epoch 10/70, Train Loss: 0.9922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  14%|█▍        | 10/70 [00:01<00:06,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:23,113 - INFO - Epoch 11/70, Train Loss: 0.9762\n",
      "2025-12-13 15:12:23,196 - INFO - Epoch 12/70, Train Loss: 0.9628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  17%|█▋        | 12/70 [00:01<00:05, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:23,286 - INFO - Epoch 13/70, Train Loss: 0.9618\n",
      "2025-12-13 15:12:23,367 - INFO - Epoch 14/70, Train Loss: 0.9642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  20%|██        | 14/70 [00:01<00:05, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:23,452 - INFO - Epoch 15/70, Train Loss: 0.9497\n",
      "2025-12-13 15:12:23,542 - INFO - Epoch 16/70, Train Loss: 0.9707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  23%|██▎       | 16/70 [00:01<00:04, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:23,631 - INFO - Epoch 17/70, Train Loss: 0.9723\n",
      "2025-12-13 15:12:23,707 - INFO - Epoch 18/70, Train Loss: 0.9539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  26%|██▌       | 18/70 [00:01<00:04, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:23,793 - INFO - Epoch 19/70, Train Loss: 0.9779\n",
      "2025-12-13 15:12:23,890 - INFO - Epoch 20/70, Train Loss: 0.9378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  29%|██▊       | 20/70 [00:02<00:04, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:24,002 - INFO - Epoch 21/70, Train Loss: 0.9758\n",
      "2025-12-13 15:12:24,173 - INFO - Epoch 22/70, Train Loss: 0.9603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  31%|███▏      | 22/70 [00:02<00:05,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:24,262 - INFO - Epoch 23/70, Train Loss: 1.0300\n",
      "2025-12-13 15:12:24,351 - INFO - Epoch 24/70, Train Loss: 0.9732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  34%|███▍      | 24/70 [00:02<00:04,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:24,434 - INFO - Epoch 25/70, Train Loss: 0.9551\n",
      "2025-12-13 15:12:24,518 - INFO - Epoch 26/70, Train Loss: 0.9365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  37%|███▋      | 26/70 [00:02<00:04, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:24,603 - INFO - Epoch 27/70, Train Loss: 0.9975\n",
      "2025-12-13 15:12:24,691 - INFO - Epoch 28/70, Train Loss: 0.9454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  40%|████      | 28/70 [00:02<00:03, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:24,782 - INFO - Epoch 29/70, Train Loss: 0.9199\n",
      "2025-12-13 15:12:24,876 - INFO - Epoch 30/70, Train Loss: 0.8901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  43%|████▎     | 30/70 [00:03<00:03, 10.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:24,955 - INFO - Epoch 31/70, Train Loss: 0.9409\n",
      "2025-12-13 15:12:25,038 - INFO - Epoch 32/70, Train Loss: 0.8677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  46%|████▌     | 32/70 [00:03<00:03, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:25,126 - INFO - Epoch 33/70, Train Loss: 0.8734\n",
      "2025-12-13 15:12:25,213 - INFO - Epoch 34/70, Train Loss: 0.9281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  49%|████▊     | 34/70 [00:03<00:03, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:25,302 - INFO - Epoch 35/70, Train Loss: 0.8849\n",
      "2025-12-13 15:12:25,394 - INFO - Epoch 36/70, Train Loss: 0.8405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  51%|█████▏    | 36/70 [00:03<00:03, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:25,487 - INFO - Epoch 37/70, Train Loss: 0.7894\n",
      "2025-12-13 15:12:25,577 - INFO - Epoch 38/70, Train Loss: 0.7945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  54%|█████▍    | 38/70 [00:03<00:02, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:25,670 - INFO - Epoch 39/70, Train Loss: 0.7900\n",
      "2025-12-13 15:12:25,755 - INFO - Epoch 40/70, Train Loss: 0.7374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  57%|█████▋    | 40/70 [00:03<00:02, 11.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:25,847 - INFO - Epoch 41/70, Train Loss: 0.8709\n",
      "2025-12-13 15:12:25,937 - INFO - Epoch 42/70, Train Loss: 0.8102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  60%|██████    | 42/70 [00:04<00:02, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:26,019 - INFO - Epoch 43/70, Train Loss: 0.9423\n",
      "2025-12-13 15:12:26,107 - INFO - Epoch 44/70, Train Loss: 0.8493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  63%|██████▎   | 44/70 [00:04<00:02, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:26,193 - INFO - Epoch 45/70, Train Loss: 0.7996\n",
      "2025-12-13 15:12:26,274 - INFO - Epoch 46/70, Train Loss: 0.7295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  66%|██████▌   | 46/70 [00:04<00:02, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:26,360 - INFO - Epoch 47/70, Train Loss: 0.7054\n",
      "2025-12-13 15:12:26,451 - INFO - Epoch 48/70, Train Loss: 0.8226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  69%|██████▊   | 48/70 [00:04<00:01, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:26,537 - INFO - Epoch 49/70, Train Loss: 1.0332\n",
      "2025-12-13 15:12:26,619 - INFO - Epoch 50/70, Train Loss: 0.7497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  71%|███████▏  | 50/70 [00:04<00:01, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:26,764 - INFO - Epoch 51/70, Train Loss: 0.7095\n",
      "2025-12-13 15:12:26,853 - INFO - Epoch 52/70, Train Loss: 0.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  74%|███████▍  | 52/70 [00:05<00:01, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:26,933 - INFO - Epoch 53/70, Train Loss: 0.7186\n",
      "2025-12-13 15:12:27,023 - INFO - Epoch 54/70, Train Loss: 0.6533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  77%|███████▋  | 54/70 [00:05<00:01, 10.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:27,109 - INFO - Epoch 55/70, Train Loss: 0.6804\n",
      "2025-12-13 15:12:27,190 - INFO - Epoch 56/70, Train Loss: 0.5673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  80%|████████  | 56/70 [00:05<00:01, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:27,273 - INFO - Epoch 57/70, Train Loss: 0.6212\n",
      "2025-12-13 15:12:27,353 - INFO - Epoch 58/70, Train Loss: 0.5604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  83%|████████▎ | 58/70 [00:05<00:01, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:27,443 - INFO - Epoch 59/70, Train Loss: 0.5434\n",
      "2025-12-13 15:12:27,527 - INFO - Epoch 60/70, Train Loss: 0.5722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  86%|████████▌ | 60/70 [00:05<00:00, 11.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:27,612 - INFO - Epoch 61/70, Train Loss: 0.6138\n",
      "2025-12-13 15:12:27,700 - INFO - Epoch 62/70, Train Loss: 0.6788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  89%|████████▊ | 62/70 [00:05<00:00, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:27,797 - INFO - Epoch 63/70, Train Loss: 0.6225\n",
      "2025-12-13 15:12:27,885 - INFO - Epoch 64/70, Train Loss: 0.5496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  91%|█████████▏| 64/70 [00:06<00:00, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:27,983 - INFO - Epoch 65/70, Train Loss: 0.4817\n",
      "2025-12-13 15:12:28,080 - INFO - Epoch 66/70, Train Loss: 0.5147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  94%|█████████▍| 66/70 [00:06<00:00, 10.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:28,178 - INFO - Epoch 67/70, Train Loss: 0.5253\n",
      "2025-12-13 15:12:28,275 - INFO - Epoch 68/70, Train Loss: 0.4921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  97%|█████████▋| 68/70 [00:06<00:00, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:28,367 - INFO - Epoch 69/70, Train Loss: 0.4723\n",
      "2025-12-13 15:12:28,453 - INFO - Epoch 70/70, Train Loss: 0.4469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 70/70 [00:06<00:00, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:28,455 - INFO - [1.0980132706463337, 0.9737811982631683, 0.985345970839262, 1.033153835684061, 0.975472379475832, 0.9702713824808598, 0.9599343352019787, 0.9548133164644241, 1.0313443951308727, 0.9922207295894623, 0.9761888794600964, 0.9627539999783039, 0.9618349336087704, 0.9642414040863514, 0.9496512375771999, 0.970670823007822, 0.9722770005464554, 0.9539233110845089, 0.9779463186860085, 0.937753651291132, 0.9758425801992416, 0.9602543003857136, 1.0300241522490978, 0.973215576261282, 0.9550528340041637, 0.9365019574761391, 0.997471671551466, 0.9454287067055702, 0.9199320301413536, 0.8900775350630283, 0.9409403055906296, 0.8677223846316338, 0.8734305314719677, 0.9281336925923824, 0.8849347159266472, 0.8405459448695183, 0.7894293991848826, 0.7944715432822704, 0.7900476083159447, 0.7374011885840446, 0.8708726316690445, 0.8102416172623634, 0.9423232525587082, 0.8492570146918297, 0.7995656691491604, 0.729454031214118, 0.7054288741201162, 0.8225831836462021, 1.0331609398126602, 0.7496655620634556, 0.7094564735889435, 0.6863481290638447, 0.7186374515295029, 0.6533276848495007, 0.6804093830287457, 0.5672795813297853, 0.621201828122139, 0.5604141735238954, 0.5433679670095444, 0.5722410790622234, 0.6137620992958546, 0.6788453496992588, 0.6225190367549658, 0.5495929755270481, 0.4817249048501253, 0.5147433178499341, 0.5252634789794683, 0.4920737808570266, 0.47225804859772325, 0.4468645863234997]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train_loss</td><td>▇█▇▇▇██▇▇▇▇▇▇▇▇▇▇█▆▇▆▇▆▆▅▇▆▅▄▅▄▃▂▃▂▄▃▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>70</td></tr><tr><td>train_loss</td><td>0.44686</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polar-glitter-3</strong> at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/kl5pl0df' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/kl5pl0df</a><br> View project at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251213_151219-kl5pl0df\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_wandb()\n",
    "train_model(net1, optimizer, loss_fn, enable_early_stopping=False)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6af345f",
   "metadata": {},
   "source": [
    "Net1 could learn on all the provided train data, but it took the model over 50 epoch to converge below 0.5 loss on train set. So I think I will create 1 more little bit more complex network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68ccf6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [16, 3]                   --\n",
       "├─Conv2d: 1-1                            [16, 8, 112, 112]         80\n",
       "├─ReLU: 1-2                              [16, 8, 112, 112]         --\n",
       "├─Conv2d: 1-3                            [16, 16, 56, 56]          1,168\n",
       "├─ReLU: 1-4                              [16, 16, 56, 56]          --\n",
       "├─Conv2d: 1-5                            [16, 32, 28, 28]          4,640\n",
       "├─ReLU: 1-6                              [16, 32, 28, 28]          --\n",
       "├─Conv2d: 1-7                            [16, 64, 14, 14]          18,496\n",
       "├─ReLU: 1-8                              [16, 64, 14, 14]          --\n",
       "├─Conv2d: 1-9                            [16, 32, 7, 7]            18,464\n",
       "├─ReLU: 1-10                             [16, 32, 7, 7]            --\n",
       "├─AdaptiveAvgPool2d: 1-11                [16, 32, 1, 1]            --\n",
       "├─Flatten: 1-12                          [16, 32]                  --\n",
       "├─Linear: 1-13                           [16, 128]                 4,224\n",
       "├─ReLU: 1-14                             [16, 128]                 --\n",
       "├─Linear: 1-15                           [16, 64]                  8,256\n",
       "├─ReLU: 1-16                             [16, 64]                  --\n",
       "├─Linear: 1-17                           [16, 3]                   195\n",
       "==========================================================================================\n",
       "Total params: 55,523\n",
       "Trainable params: 55,523\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 205.55\n",
       "==========================================================================================\n",
       "Input size (MB): 3.21\n",
       "Forward/backward pass size (MB): 24.31\n",
       "Params size (MB): 0.22\n",
       "Estimated Total Size (MB): 27.74\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1),   # 224x224 -> 112x112   // (3x3x1)x8\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),  # 112x112 -> 56x56     // (3x3x8)x16\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # 56x56 -> 28x28      // (3x3x16)x32\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # 28x28 -> 14x14      // (3x3x32)x64\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(64, 32, kernel_size=3, stride=2, padding=1),  # 14x14 -> 7x7        // (3x3x64)x32\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.AdaptiveAvgPool2d(1),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(32, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 3)                       # Output layer     \n",
    ").to(device)\n",
    "\n",
    "net2.apply(init_weights)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net2.parameters(), lr=0.001)\n",
    "\n",
    "summary(net2, input_size=(batch_size, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6abe7d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Win 10\\Desktop\\BME\\DeepL\\BMEVITMMA18_Deep-Learning_AnkleAlign_D6AE9F\\notebook\\wandb\\run-20251213_151230-aqeji3qc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/aqeji3qc' target=\"_blank\">sparkling-thunder-4</a></strong> to <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/aqeji3qc' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/aqeji3qc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:31,348 - INFO - Epoch 1/70, Train Loss: 1.1290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   1%|▏         | 1/70 [00:00<00:12,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:31,536 - INFO - Epoch 2/70, Train Loss: 1.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   3%|▎         | 2/70 [00:00<00:12,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:31,651 - INFO - Epoch 3/70, Train Loss: 1.0552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   4%|▍         | 3/70 [00:00<00:10,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:31,744 - INFO - Epoch 4/70, Train Loss: 0.9918\n",
      "2025-12-13 15:12:31,832 - INFO - Epoch 5/70, Train Loss: 0.9569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   7%|▋         | 5/70 [00:00<00:07,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:31,924 - INFO - Epoch 6/70, Train Loss: 0.9552\n",
      "2025-12-13 15:12:32,011 - INFO - Epoch 7/70, Train Loss: 0.9981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  10%|█         | 7/70 [00:00<00:06,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:32,102 - INFO - Epoch 8/70, Train Loss: 0.9633\n",
      "2025-12-13 15:12:32,185 - INFO - Epoch 9/70, Train Loss: 0.9529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  13%|█▎        | 9/70 [00:01<00:05, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:32,276 - INFO - Epoch 10/70, Train Loss: 0.9201\n",
      "2025-12-13 15:12:32,366 - INFO - Epoch 11/70, Train Loss: 1.0935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  16%|█▌        | 11/70 [00:01<00:05, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:32,455 - INFO - Epoch 12/70, Train Loss: 0.9907\n",
      "2025-12-13 15:12:32,545 - INFO - Epoch 13/70, Train Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  19%|█▊        | 13/70 [00:01<00:05, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:32,635 - INFO - Epoch 14/70, Train Loss: 0.9483\n",
      "2025-12-13 15:12:32,733 - INFO - Epoch 15/70, Train Loss: 1.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  21%|██▏       | 15/70 [00:01<00:05, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:32,853 - INFO - Epoch 16/70, Train Loss: 0.9730\n",
      "2025-12-13 15:12:32,985 - INFO - Epoch 17/70, Train Loss: 0.9264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  24%|██▍       | 17/70 [00:01<00:05,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:33,074 - INFO - Epoch 18/70, Train Loss: 0.8942\n",
      "2025-12-13 15:12:33,178 - INFO - Epoch 19/70, Train Loss: 0.8338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  27%|██▋       | 19/70 [00:02<00:05,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:33,308 - INFO - Epoch 20/70, Train Loss: 0.8458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  29%|██▊       | 20/70 [00:02<00:05,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:33,447 - INFO - Epoch 21/70, Train Loss: 0.8133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  30%|███       | 21/70 [00:02<00:05,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:33,590 - INFO - Epoch 22/70, Train Loss: 0.8147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  31%|███▏      | 22/70 [00:02<00:05,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:33,708 - INFO - Epoch 23/70, Train Loss: 0.8973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  33%|███▎      | 23/70 [00:02<00:05,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:33,812 - INFO - Epoch 24/70, Train Loss: 0.6855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  34%|███▍      | 24/70 [00:02<00:05,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:33,916 - INFO - Epoch 25/70, Train Loss: 0.5944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  36%|███▌      | 25/70 [00:02<00:05,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:34,014 - INFO - Epoch 26/70, Train Loss: 0.6057\n",
      "2025-12-13 15:12:34,145 - INFO - Epoch 27/70, Train Loss: 0.5092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  39%|███▊      | 27/70 [00:02<00:04,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:34,287 - INFO - Epoch 28/70, Train Loss: 0.5201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  40%|████      | 28/70 [00:03<00:05,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:34,402 - INFO - Epoch 29/70, Train Loss: 0.4381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  41%|████▏     | 29/70 [00:03<00:04,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:34,560 - INFO - Epoch 30/70, Train Loss: 0.3534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  43%|████▎     | 30/70 [00:03<00:05,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:34,695 - INFO - Epoch 31/70, Train Loss: 0.3639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  44%|████▍     | 31/70 [00:03<00:05,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:34,812 - INFO - Epoch 32/70, Train Loss: 0.4109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  46%|████▌     | 32/70 [00:03<00:04,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:34,944 - INFO - Epoch 33/70, Train Loss: 0.3155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  47%|████▋     | 33/70 [00:03<00:04,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:35,052 - INFO - Epoch 34/70, Train Loss: 0.3173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  49%|████▊     | 34/70 [00:03<00:04,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:35,166 - INFO - Epoch 35/70, Train Loss: 0.2744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  50%|█████     | 35/70 [00:03<00:04,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:35,287 - INFO - Epoch 36/70, Train Loss: 0.2056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  51%|█████▏    | 36/70 [00:04<00:04,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:35,403 - INFO - Epoch 37/70, Train Loss: 0.1840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  53%|█████▎    | 37/70 [00:04<00:03,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:35,531 - INFO - Epoch 38/70, Train Loss: 0.1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  54%|█████▍    | 38/70 [00:04<00:03,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:35,652 - INFO - Epoch 39/70, Train Loss: 0.1559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  56%|█████▌    | 39/70 [00:04<00:03,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:35,788 - INFO - Epoch 40/70, Train Loss: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  57%|█████▋    | 40/70 [00:04<00:03,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:35,912 - INFO - Epoch 41/70, Train Loss: 0.1633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  59%|█████▊    | 41/70 [00:04<00:03,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:36,041 - INFO - Epoch 42/70, Train Loss: 0.3789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  60%|██████    | 42/70 [00:04<00:03,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:36,189 - INFO - Epoch 43/70, Train Loss: 0.7051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  61%|██████▏   | 43/70 [00:05<00:03,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:36,333 - INFO - Epoch 44/70, Train Loss: 0.5958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  63%|██████▎   | 44/70 [00:05<00:03,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:36,465 - INFO - Epoch 45/70, Train Loss: 0.4963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  64%|██████▍   | 45/70 [00:05<00:03,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:36,589 - INFO - Epoch 46/70, Train Loss: 0.3736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  66%|██████▌   | 46/70 [00:05<00:03,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:36,759 - INFO - Epoch 47/70, Train Loss: 0.2435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  67%|██████▋   | 47/70 [00:05<00:03,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:36,900 - INFO - Epoch 48/70, Train Loss: 0.2006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  69%|██████▊   | 48/70 [00:05<00:03,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:37,157 - INFO - Epoch 49/70, Train Loss: 0.1637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  70%|███████   | 49/70 [00:05<00:03,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:37,380 - INFO - Epoch 50/70, Train Loss: 0.1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  71%|███████▏  | 50/70 [00:06<00:03,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:37,524 - INFO - Epoch 51/70, Train Loss: 0.1267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  73%|███████▎  | 51/70 [00:06<00:03,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:37,652 - INFO - Epoch 52/70, Train Loss: 0.1209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  74%|███████▍  | 52/70 [00:06<00:02,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:37,885 - INFO - Epoch 53/70, Train Loss: 0.1052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  76%|███████▌  | 53/70 [00:06<00:03,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:38,066 - INFO - Epoch 54/70, Train Loss: 0.1061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  77%|███████▋  | 54/70 [00:06<00:02,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:38,189 - INFO - Epoch 55/70, Train Loss: 0.0827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  79%|███████▊  | 55/70 [00:07<00:02,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:38,328 - INFO - Epoch 56/70, Train Loss: 0.0813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  80%|████████  | 56/70 [00:07<00:02,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:38,483 - INFO - Epoch 57/70, Train Loss: 0.0814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  81%|████████▏ | 57/70 [00:07<00:02,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:38,619 - INFO - Epoch 58/70, Train Loss: 0.0748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  83%|████████▎ | 58/70 [00:07<00:01,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:38,753 - INFO - Epoch 59/70, Train Loss: 0.0709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  84%|████████▍ | 59/70 [00:07<00:01,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:38,876 - INFO - Epoch 60/70, Train Loss: 0.0663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  86%|████████▌ | 60/70 [00:07<00:01,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:39,004 - INFO - Epoch 61/70, Train Loss: 0.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  87%|████████▋ | 61/70 [00:07<00:01,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:39,147 - INFO - Epoch 62/70, Train Loss: 0.0817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  89%|████████▊ | 62/70 [00:07<00:01,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:39,333 - INFO - Epoch 63/70, Train Loss: 0.1133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  90%|█████████ | 63/70 [00:08<00:01,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:39,504 - INFO - Epoch 64/70, Train Loss: 0.1018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  91%|█████████▏| 64/70 [00:08<00:00,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:39,770 - INFO - Epoch 65/70, Train Loss: 0.1185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  93%|█████████▎| 65/70 [00:08<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:39,930 - INFO - Epoch 66/70, Train Loss: 0.0767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  94%|█████████▍| 66/70 [00:08<00:00,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:40,084 - INFO - Epoch 67/70, Train Loss: 0.0517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  96%|█████████▌| 67/70 [00:08<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:40,227 - INFO - Epoch 68/70, Train Loss: 0.0650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  97%|█████████▋| 68/70 [00:09<00:00,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:40,351 - INFO - Epoch 69/70, Train Loss: 0.0542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  99%|█████████▊| 69/70 [00:09<00:00,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:40,480 - INFO - Epoch 70/70, Train Loss: 0.0637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 70/70 [00:09<00:00,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:40,482 - INFO - [1.128953706473112, 1.0152508057653904, 1.0551845915615559, 0.9917939081788063, 0.9568653926253319, 0.9551576264202595, 0.9980925507843494, 0.9632662162184715, 0.9529300108551979, 0.9201431628316641, 1.0935109071433544, 0.9907349273562431, 0.9297497626394033, 0.9483215883374214, 1.0065739825367928, 0.9730098620057106, 0.9263771623373032, 0.8941906467080116, 0.8338040113449097, 0.8458393402397633, 0.8133164457976818, 0.8147167712450027, 0.8972919546067715, 0.685528723988682, 0.5943929916247725, 0.6056549847126007, 0.5091847740113735, 0.5200991872698069, 0.4380995538085699, 0.3533913432620466, 0.36389950942248106, 0.4108554683625698, 0.3155387270380743, 0.3173329159617424, 0.2744336361065507, 0.20559349981340347, 0.1840467118890956, 0.16244903313236136, 0.15588786933221854, 0.1429109300370328, 0.16334831807762384, 0.3789045000448823, 0.705118122510612, 0.5957707650959492, 0.49630474112927914, 0.37360685877501965, 0.243512105778791, 0.2005699034780264, 0.1636515298159793, 0.12179218381061219, 0.12666572956368327, 0.12086906633339822, 0.10518021904863417, 0.10612228527133993, 0.08269660593941808, 0.08130760849780927, 0.08143052068771794, 0.0747603734198492, 0.07091720798052847, 0.06632342835064264, 0.08923298152512871, 0.08167273667640984, 0.11329156879219227, 0.10181769286282183, 0.11851354724058183, 0.07671922357803851, 0.05170598772747326, 0.06499945305222354, 0.05422240600455552, 0.06374194675299805]\n",
      "2025-12-13 15:12:40,521 - INFO - network accuracy: 44.05%\n",
      "2025-12-13 15:12:40,522 - INFO - network precision: 76.83%\n",
      "2025-12-13 15:12:40,523 - INFO - network recall: 24.49%\n",
      "2025-12-13 15:12:40,524 - INFO - network F1 score: 27.11%\n",
      "2025-12-13 15:12:40,535 - INFO - Detailed Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.71      0.22         7\n",
      "           1       0.88      0.17      0.28        42\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.24        49\n",
      "   macro avg       0.33      0.29      0.17        49\n",
      "weighted avg       0.77      0.24      0.27        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2801: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇██</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>test_precision</td><td>▁</td></tr><tr><td>test_recall</td><td>▁</td></tr><tr><td>train_loss</td><td>▇█▇▇▇▇▇█▇▇▇▆▆▆▇▅▄▃▃▃▂▂▂▂▂▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>70</td></tr><tr><td>test_accuracy</td><td>0.44048</td></tr><tr><td>test_f1</td><td>0.27106</td></tr><tr><td>test_precision</td><td>0.76832</td></tr><tr><td>test_recall</td><td>0.2449</td></tr><tr><td>train_loss</td><td>0.06374</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sparkling-thunder-4</strong> at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/aqeji3qc' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/aqeji3qc</a><br> View project at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251213_151230-aqeji3qc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_wandb()\n",
    "train_model(net2, optimizer, loss_fn, enable_early_stopping=False)\n",
    "evaluate_model(net2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9660da",
   "metadata": {},
   "source": [
    "Net2 seems the best in convergence but it definitely overfits, so the next step is to solve this with net3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5784b860",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.0001, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.best_model = None\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = model.state_dict().copy()\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                logger.info(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = model.state_dict().copy()\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8288f9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [32, 3]                   --\n",
       "├─Conv2d: 1-1                            [32, 8, 224, 224]         80\n",
       "├─ReLU: 1-2                              [32, 8, 224, 224]         --\n",
       "├─MaxPool2d: 1-3                         [32, 8, 112, 112]         --\n",
       "├─Conv2d: 1-4                            [32, 16, 112, 112]        1,168\n",
       "├─ReLU: 1-5                              [32, 16, 112, 112]        --\n",
       "├─MaxPool2d: 1-6                         [32, 16, 56, 56]          --\n",
       "├─Conv2d: 1-7                            [32, 32, 56, 56]          4,640\n",
       "├─ReLU: 1-8                              [32, 32, 56, 56]          --\n",
       "├─MaxPool2d: 1-9                         [32, 32, 28, 28]          --\n",
       "├─Conv2d: 1-10                           [32, 64, 28, 28]          18,496\n",
       "├─ReLU: 1-11                             [32, 64, 28, 28]          --\n",
       "├─MaxPool2d: 1-12                        [32, 64, 14, 14]          --\n",
       "├─Conv2d: 1-13                           [32, 32, 14, 14]          18,464\n",
       "├─ReLU: 1-14                             [32, 32, 14, 14]          --\n",
       "├─MaxPool2d: 1-15                        [32, 32, 7, 7]            --\n",
       "├─AdaptiveAvgPool2d: 1-16                [32, 32, 1, 1]            --\n",
       "├─Flatten: 1-17                          [32, 32]                  --\n",
       "├─Linear: 1-18                           [32, 128]                 4,224\n",
       "├─ReLU: 1-19                             [32, 128]                 --\n",
       "├─Linear: 1-20                           [32, 64]                  8,256\n",
       "├─ReLU: 1-21                             [32, 64]                  --\n",
       "├─Linear: 1-22                           [32, 3]                   195\n",
       "==========================================================================================\n",
       "Total params: 55,523\n",
       "Trainable params: 55,523\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.64\n",
       "==========================================================================================\n",
       "Input size (MB): 6.42\n",
       "Forward/backward pass size (MB): 194.33\n",
       "Params size (MB): 0.22\n",
       "Estimated Total Size (MB): 200.98\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "net3 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1),      # (3x3x1)x8\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 224x224 -> 112x112\n",
    "\n",
    "    torch.nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),       # (3x3x8)x16\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 112x112 -> 56x56\n",
    "\n",
    "    torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),       # (3x3x16)x32\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 56x56 -> 28x28 \n",
    "\n",
    "    torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),       # (3x3x32)x64\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 28x28 -> 14x14 \n",
    "\n",
    "    torch.nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),       # (3x3x64)x32\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 14x14 -> 7x7\n",
    "\n",
    "    torch.nn.AdaptiveAvgPool2d(1),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(32, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 3)                       # Output layer     \n",
    ").to(device)\n",
    "\n",
    "net3.apply(init_weights)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net3.parameters(), lr=0.001)\n",
    "\n",
    "summary(net3, input_size=(batch_size, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13a0d7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Win 10\\Desktop\\BME\\DeepL\\BMEVITMMA18_Deep-Learning_AnkleAlign_D6AE9F\\notebook\\wandb\\run-20251213_151242-r510ayga</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/r510ayga' target=\"_blank\">elated-frost-5</a></strong> to <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/r510ayga' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/r510ayga</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:43,726 - INFO - Epoch 1/70, Train Loss: 1.1033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   1%|▏         | 1/70 [00:00<00:28,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:43,837 - INFO - Epoch 2/70, Train Loss: 1.0451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   3%|▎         | 2/70 [00:00<00:15,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:43,950 - INFO - Epoch 3/70, Train Loss: 0.9921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   4%|▍         | 3/70 [00:00<00:12,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:44,061 - INFO - Epoch 4/70, Train Loss: 0.9792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   6%|▌         | 4/70 [00:00<00:10,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:44,173 - INFO - Epoch 5/70, Train Loss: 0.9773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   7%|▋         | 5/70 [00:00<00:08,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:44,290 - INFO - Epoch 6/70, Train Loss: 0.9840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   9%|▊         | 6/70 [00:00<00:08,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:44,402 - INFO - Epoch 7/70, Train Loss: 0.9777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  10%|█         | 7/70 [00:01<00:07,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:44,514 - INFO - Epoch 8/70, Train Loss: 0.9721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  11%|█▏        | 8/70 [00:01<00:07,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:44,626 - INFO - Epoch 9/70, Train Loss: 0.9926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  13%|█▎        | 9/70 [00:01<00:07,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:44,741 - INFO - Epoch 10/70, Train Loss: 0.9922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  14%|█▍        | 10/70 [00:01<00:07,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:44,849 - INFO - Epoch 11/70, Train Loss: 0.9604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  16%|█▌        | 11/70 [00:01<00:06,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:44,958 - INFO - Epoch 12/70, Train Loss: 0.9706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  17%|█▋        | 12/70 [00:01<00:06,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:45,067 - INFO - Epoch 13/70, Train Loss: 0.9449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  19%|█▊        | 13/70 [00:01<00:06,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:45,178 - INFO - Epoch 14/70, Train Loss: 0.9122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  20%|██        | 14/70 [00:01<00:06,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:45,289 - INFO - Epoch 15/70, Train Loss: 0.9579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  21%|██▏       | 15/70 [00:01<00:06,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:45,401 - INFO - Epoch 16/70, Train Loss: 0.9286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  23%|██▎       | 16/70 [00:02<00:06,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:45,513 - INFO - Epoch 17/70, Train Loss: 0.9558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  24%|██▍       | 17/70 [00:02<00:05,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:45,622 - INFO - Epoch 18/70, Train Loss: 0.9683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  26%|██▌       | 18/70 [00:02<00:05,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:45,741 - INFO - Epoch 19/70, Train Loss: 0.9100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  27%|██▋       | 19/70 [00:02<00:05,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:45,849 - INFO - Epoch 20/70, Train Loss: 0.9370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  29%|██▊       | 20/70 [00:02<00:05,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:45,961 - INFO - Epoch 21/70, Train Loss: 0.8583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  30%|███       | 21/70 [00:02<00:05,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:46,071 - INFO - Epoch 22/70, Train Loss: 0.8821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  31%|███▏      | 22/70 [00:02<00:05,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:46,181 - INFO - Epoch 23/70, Train Loss: 0.8452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  33%|███▎      | 23/70 [00:02<00:05,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:46,291 - INFO - Epoch 24/70, Train Loss: 0.9404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  34%|███▍      | 24/70 [00:02<00:05,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:46,397 - INFO - Epoch 25/70, Train Loss: 0.9145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  36%|███▌      | 25/70 [00:03<00:04,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:46,504 - INFO - Epoch 26/70, Train Loss: 0.8262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  37%|███▋      | 26/70 [00:03<00:04,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:46,619 - INFO - Epoch 27/70, Train Loss: 0.8251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  39%|███▊      | 27/70 [00:03<00:04,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:46,728 - INFO - Epoch 28/70, Train Loss: 0.8182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  40%|████      | 28/70 [00:03<00:04,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:46,840 - INFO - Epoch 29/70, Train Loss: 0.8135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  41%|████▏     | 29/70 [00:03<00:04,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:46,951 - INFO - Epoch 30/70, Train Loss: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  43%|████▎     | 30/70 [00:03<00:04,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:47,062 - INFO - Epoch 31/70, Train Loss: 0.7682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  44%|████▍     | 31/70 [00:03<00:04,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:47,171 - INFO - Epoch 32/70, Train Loss: 0.8817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  46%|████▌     | 32/70 [00:03<00:04,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:47,281 - INFO - Epoch 33/70, Train Loss: 0.7813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  47%|████▋     | 33/70 [00:03<00:04,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:47,393 - INFO - Epoch 34/70, Train Loss: 0.7364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  49%|████▊     | 34/70 [00:04<00:03,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:47,506 - INFO - Epoch 35/70, Train Loss: 0.7548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  50%|█████     | 35/70 [00:04<00:03,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:47,617 - INFO - Epoch 36/70, Train Loss: 0.6827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  51%|█████▏    | 36/70 [00:04<00:03,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:47,728 - INFO - Epoch 37/70, Train Loss: 0.6428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  53%|█████▎    | 37/70 [00:04<00:03,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:47,838 - INFO - Epoch 38/70, Train Loss: 0.7205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  54%|█████▍    | 38/70 [00:04<00:03,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:47,948 - INFO - Epoch 39/70, Train Loss: 0.6231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  56%|█████▌    | 39/70 [00:04<00:03,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:48,061 - INFO - Epoch 40/70, Train Loss: 0.6497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  57%|█████▋    | 40/70 [00:04<00:03,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:48,179 - INFO - Epoch 41/70, Train Loss: 0.7756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  59%|█████▊    | 41/70 [00:04<00:03,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:48,318 - INFO - Epoch 42/70, Train Loss: 0.6067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  60%|██████    | 42/70 [00:05<00:03,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:48,430 - INFO - Epoch 43/70, Train Loss: 0.6977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  61%|██████▏   | 43/70 [00:05<00:03,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:48,545 - INFO - Epoch 44/70, Train Loss: 0.5209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  63%|██████▎   | 44/70 [00:05<00:03,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:48,656 - INFO - Epoch 45/70, Train Loss: 0.5252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  64%|██████▍   | 45/70 [00:05<00:02,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:48,764 - INFO - Epoch 46/70, Train Loss: 0.6361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  66%|██████▌   | 46/70 [00:05<00:02,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:48,885 - INFO - Epoch 47/70, Train Loss: 0.4644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  67%|██████▋   | 47/70 [00:05<00:02,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:49,002 - INFO - Epoch 48/70, Train Loss: 0.4728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  69%|██████▊   | 48/70 [00:05<00:02,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:49,124 - INFO - Epoch 49/70, Train Loss: 0.4582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  70%|███████   | 49/70 [00:05<00:02,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:49,231 - INFO - Epoch 50/70, Train Loss: 0.5918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  71%|███████▏  | 50/70 [00:05<00:02,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:49,342 - INFO - Epoch 51/70, Train Loss: 0.4538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  73%|███████▎  | 51/70 [00:06<00:02,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:49,452 - INFO - Epoch 52/70, Train Loss: 0.3979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  74%|███████▍  | 52/70 [00:06<00:02,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:49,562 - INFO - Epoch 53/70, Train Loss: 0.3400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  76%|███████▌  | 53/70 [00:06<00:01,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:49,669 - INFO - Epoch 54/70, Train Loss: 0.2828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  77%|███████▋  | 54/70 [00:06<00:01,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:49,776 - INFO - Epoch 55/70, Train Loss: 0.3595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  79%|███████▊  | 55/70 [00:06<00:01,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:49,883 - INFO - Epoch 56/70, Train Loss: 0.2601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  80%|████████  | 56/70 [00:06<00:01,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:49,995 - INFO - Epoch 57/70, Train Loss: 0.2430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  81%|████████▏ | 57/70 [00:06<00:01,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:50,108 - INFO - Epoch 58/70, Train Loss: 0.2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  83%|████████▎ | 58/70 [00:06<00:01,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:50,216 - INFO - Epoch 59/70, Train Loss: 0.2175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  84%|████████▍ | 59/70 [00:06<00:01,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:50,326 - INFO - Epoch 60/70, Train Loss: 0.2875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  86%|████████▌ | 60/70 [00:07<00:01,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:50,437 - INFO - Epoch 61/70, Train Loss: 0.1857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  87%|████████▋ | 61/70 [00:07<00:00,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:50,548 - INFO - Epoch 62/70, Train Loss: 0.1539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  89%|████████▊ | 62/70 [00:07<00:00,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:50,657 - INFO - Epoch 63/70, Train Loss: 0.2187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  90%|█████████ | 63/70 [00:07<00:00,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:50,764 - INFO - Epoch 64/70, Train Loss: 0.2484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  91%|█████████▏| 64/70 [00:07<00:00,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:50,877 - INFO - Epoch 65/70, Train Loss: 0.1611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  93%|█████████▎| 65/70 [00:07<00:00,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:50,987 - INFO - Epoch 66/70, Train Loss: 0.3536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  94%|█████████▍| 66/70 [00:07<00:00,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:51,095 - INFO - Epoch 67/70, Train Loss: 0.5810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  96%|█████████▌| 67/70 [00:07<00:00,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:51,202 - INFO - Epoch 68/70, Train Loss: 0.3388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  97%|█████████▋| 68/70 [00:07<00:00,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:51,312 - INFO - Epoch 69/70, Train Loss: 0.2507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  99%|█████████▊| 69/70 [00:07<00:00,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:51,422 - INFO - Epoch 70/70, Train Loss: 0.2437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 70/70 [00:08<00:00,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:12:51,424 - INFO - [1.1033370196819305, 1.0450826063752174, 0.9920924566686153, 0.9791661575436592, 0.977278720587492, 0.9839993752539158, 0.9776948690414429, 0.9720984809100628, 0.9925960823893547, 0.9922092147171497, 0.960443951189518, 0.9706465303897858, 0.9449320510029793, 0.9122158885002136, 0.9578891545534134, 0.9285791404545307, 0.9557551965117455, 0.9683436900377274, 0.9100451059639454, 0.9369592182338238, 0.8582910466939211, 0.8820824734866619, 0.8452195972204208, 0.9403965435922146, 0.9145348407328129, 0.8261917866766453, 0.8251167125999928, 0.8181727007031441, 0.8134674727916718, 0.833258930593729, 0.7682208716869354, 0.8816547282040119, 0.7813036227598786, 0.736373906955123, 0.754819568246603, 0.6826564967632294, 0.6428337823599577, 0.720543198287487, 0.6230727918446064, 0.6497019156813622, 0.77556411921978, 0.6067338909488171, 0.6976957954466343, 0.5209095953032374, 0.5252386219799519, 0.6361428480231552, 0.4644148927181959, 0.47276318073272705, 0.45817940682172775, 0.5918054119683802, 0.4538022615015507, 0.39788744784891605, 0.3400002373382449, 0.2827741513028741, 0.3594698456436163, 0.2600961299069695, 0.24301460711285472, 0.20072170093317254, 0.21745850332081318, 0.28745465667452663, 0.18572703655809164, 0.15385518805123866, 0.21865158167202026, 0.24838070443365723, 0.16113209206378087, 0.3536407353822142, 0.5809643138200045, 0.3387989391339943, 0.25072635151445866, 0.24366004159674048]\n",
      "2025-12-13 15:12:51,445 - INFO - network accuracy: 53.57%\n",
      "2025-12-13 15:12:51,445 - INFO - network precision: 78.18%\n",
      "2025-12-13 15:12:51,446 - INFO - network recall: 40.82%\n",
      "2025-12-13 15:12:51,446 - INFO - network F1 score: 47.67%\n",
      "2025-12-13 15:12:51,457 - INFO - Detailed Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.71      0.29         7\n",
      "           1       0.88      0.36      0.51        42\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.41        49\n",
      "   macro avg       0.35      0.36      0.26        49\n",
      "weighted avg       0.78      0.41      0.48        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2801: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>test_precision</td><td>▁</td></tr><tr><td>test_recall</td><td>▁</td></tr><tr><td>train_loss</td><td>██▇▇███▇▇▇▇▇▇▆▇▆▆▆▆▆▅▅▅▆▅▅▃▃▄▃▂▃▂▁▁▂▁▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>70</td></tr><tr><td>test_accuracy</td><td>0.53571</td></tr><tr><td>test_f1</td><td>0.47665</td></tr><tr><td>test_precision</td><td>0.78181</td></tr><tr><td>test_recall</td><td>0.40816</td></tr><tr><td>train_loss</td><td>0.24366</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">elated-frost-5</strong> at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/r510ayga' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last/runs/r510ayga</a><br> View project at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model-last</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251213_151242-r510ayga\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_wandb()\n",
    "train_model(net3, optimizer, loss_fn, enable_early_stopping=False)\n",
    "evaluate_model(net3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2306168",
   "metadata": {},
   "source": [
    "Net3 intorduced maxpool layers after each conv layer and acheved better generalisation, more over batch size could be inreased to 32, and still perfomed godd on it unlike previous networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a7a8852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train test split, for getting validation metrics during training\n",
    "x_train_tensor, x_val_tensor, y_train_tensor, y_val_tensor = train_test_split(\n",
    "    x_train_tensor, y_train_tensor, test_size=0.2, random_state=42, stratify=y_train_tensor)\n",
    "\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d37b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, torch.nn.BatchNorm2d):\n",
    "        torch.nn.init.constant_(m.weight, 1)\n",
    "        torch.nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ceea8786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [32, 3]                   --\n",
       "├─Conv2d: 1-1                            [32, 8, 224, 224]         80\n",
       "├─BatchNorm2d: 1-2                       [32, 8, 224, 224]         16\n",
       "├─ReLU: 1-3                              [32, 8, 224, 224]         --\n",
       "├─MaxPool2d: 1-4                         [32, 8, 112, 112]         --\n",
       "├─Conv2d: 1-5                            [32, 16, 112, 112]        1,168\n",
       "├─BatchNorm2d: 1-6                       [32, 16, 112, 112]        32\n",
       "├─ReLU: 1-7                              [32, 16, 112, 112]        --\n",
       "├─MaxPool2d: 1-8                         [32, 16, 56, 56]          --\n",
       "├─Conv2d: 1-9                            [32, 32, 56, 56]          4,640\n",
       "├─BatchNorm2d: 1-10                      [32, 32, 56, 56]          64\n",
       "├─ReLU: 1-11                             [32, 32, 56, 56]          --\n",
       "├─MaxPool2d: 1-12                        [32, 32, 28, 28]          --\n",
       "├─Conv2d: 1-13                           [32, 64, 28, 28]          18,496\n",
       "├─BatchNorm2d: 1-14                      [32, 64, 28, 28]          128\n",
       "├─ReLU: 1-15                             [32, 64, 28, 28]          --\n",
       "├─MaxPool2d: 1-16                        [32, 64, 14, 14]          --\n",
       "├─Conv2d: 1-17                           [32, 32, 14, 14]          18,464\n",
       "├─BatchNorm2d: 1-18                      [32, 32, 14, 14]          64\n",
       "├─ReLU: 1-19                             [32, 32, 14, 14]          --\n",
       "├─MaxPool2d: 1-20                        [32, 32, 7, 7]            --\n",
       "├─AdaptiveAvgPool2d: 1-21                [32, 32, 1, 1]            --\n",
       "├─Flatten: 1-22                          [32, 32]                  --\n",
       "├─Linear: 1-23                           [32, 128]                 4,224\n",
       "├─ReLU: 1-24                             [32, 128]                 --\n",
       "├─Linear: 1-25                           [32, 64]                  8,256\n",
       "├─ReLU: 1-26                             [32, 64]                  --\n",
       "├─Linear: 1-27                           [32, 3]                   195\n",
       "==========================================================================================\n",
       "Total params: 55,827\n",
       "Trainable params: 55,827\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.64\n",
       "==========================================================================================\n",
       "Input size (MB): 6.42\n",
       "Forward/backward pass size (MB): 388.61\n",
       "Params size (MB): 0.22\n",
       "Estimated Total Size (MB): 395.26\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net4 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1),      # (3x3x1)x8\n",
    "    torch.nn.BatchNorm2d(8),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 224x224 -> 112x112\n",
    "\n",
    "    torch.nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),       # (3x3x8)x16\n",
    "    torch.nn.BatchNorm2d(16),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 112x112 -> 56x56\n",
    "\n",
    "    torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),       # (3x3x16)x32\n",
    "    torch.nn.BatchNorm2d(32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 56x56 -> 28x28 \n",
    "\n",
    "    torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),       # (3x3x32)x64\n",
    "    torch.nn.BatchNorm2d(64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 28x28 -> 14x14 \n",
    "\n",
    "    torch.nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),       # (3x3x64)x32\n",
    "    torch.nn.BatchNorm2d(32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 14x14 -> 7x7\n",
    "\n",
    "    torch.nn.AdaptiveAvgPool2d(1),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(32, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 3)                       # Output layer     \n",
    ").to(device)\n",
    "\n",
    "net4.apply(init_weights)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net4.parameters(), lr=0.0005)\n",
    "\n",
    "summary(net4, input_size=(batch_size, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d66c699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Win 10\\Desktop\\BME\\DeepL\\BMEVITMMA18_Deep-Learning_AnkleAlign_D6AE9F\\notebook\\wandb\\run-20251213_151630-yt5p5817</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/yt5p5817' target=\"_blank\">lilac-snowflake-77</a></strong> to <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/yt5p5817' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/yt5p5817</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:16:31,650 - INFO - Epoch 1/70, Train Loss: 1.1161, Val Loss: 1.0317, Val Acc: 0.3469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   1%|▏         | 1/70 [00:00<00:22,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:16:31,780 - INFO - Epoch 2/70, Train Loss: 0.9851, Val Loss: 1.0954, Val Acc: 0.3469\n",
      "2025-12-13 15:16:31,781 - INFO - EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   3%|▎         | 2/70 [00:00<00:14,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:16:31,907 - INFO - Epoch 3/70, Train Loss: 0.9209, Val Loss: 1.0621, Val Acc: 0.3265\n",
      "2025-12-13 15:16:31,908 - INFO - EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   4%|▍         | 3/70 [00:00<00:11,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:16:32,036 - INFO - Epoch 4/70, Train Loss: 0.8793, Val Loss: 1.0329, Val Acc: 0.5306\n",
      "2025-12-13 15:16:32,037 - INFO - EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   6%|▌         | 4/70 [00:00<00:10,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:16:32,166 - INFO - Epoch 5/70, Train Loss: 0.8427, Val Loss: 1.0189, Val Acc: 0.5306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   7%|▋         | 5/70 [00:00<00:09,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:16:32,284 - INFO - Epoch 6/70, Train Loss: 0.8192, Val Loss: 1.0201, Val Acc: 0.4898\n",
      "2025-12-13 15:16:32,285 - INFO - EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   9%|▊         | 6/70 [00:00<00:08,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:16:32,406 - INFO - Epoch 7/70, Train Loss: 0.7749, Val Loss: 1.0072, Val Acc: 0.5306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  10%|█         | 7/70 [00:01<00:08,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:16:32,528 - INFO - Epoch 8/70, Train Loss: 0.7634, Val Loss: 1.0014, Val Acc: 0.5306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  11%|█▏        | 8/70 [00:01<00:08,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:16:32,657 - INFO - Epoch 9/70, Train Loss: 0.7345, Val Loss: 1.0214, Val Acc: 0.4898\n",
      "2025-12-13 15:16:32,657 - INFO - EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  13%|█▎        | 9/70 [00:01<00:07,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:16:32,774 - INFO - Epoch 10/70, Train Loss: 0.7110, Val Loss: 1.0280, Val Acc: 0.5510\n",
      "2025-12-13 15:16:32,775 - INFO - EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  14%|█▍        | 10/70 [00:01<00:07,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:16:32,894 - INFO - Epoch 11/70, Train Loss: 0.6820, Val Loss: 1.0217, Val Acc: 0.5918\n",
      "2025-12-13 15:16:32,895 - INFO - EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  16%|█▌        | 11/70 [00:01<00:07,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:16:33,068 - INFO - Epoch 12/70, Train Loss: 0.6592, Val Loss: 1.0124, Val Acc: 0.5102\n",
      "2025-12-13 15:16:33,068 - INFO - EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  17%|█▋        | 12/70 [00:01<00:08,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:16:33,188 - INFO - Epoch 13/70, Train Loss: 0.6656, Val Loss: 1.0383, Val Acc: 0.5102\n",
      "2025-12-13 15:16:33,188 - INFO - EarlyStopping counter: 5 out of 5\n",
      "2025-12-13 15:16:33,189 - INFO - Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  17%|█▋        | 12/70 [00:01<00:09,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:16:33,193 - INFO - Loaded best model weights\n",
      "2025-12-13 15:16:33,193 - INFO - [1.1161300539970398, 0.985075443983078, 0.9209022025267283, 0.8792893091837565, 0.8427437742551168, 0.8192348182201385, 0.7748598953088125, 0.7633983890215555, 0.7344794869422913, 0.7110288341840109, 0.6819542249043783, 0.6592182715733846, 0.6656493445237478]\n",
      "2025-12-13 15:16:33,221 - INFO - network accuracy: 58.33%\n",
      "2025-12-13 15:16:33,222 - INFO - network precision: 89.42%\n",
      "2025-12-13 15:16:33,222 - INFO - network recall: 28.57%\n",
      "2025-12-13 15:16:33,223 - INFO - network F1 score: 30.37%\n",
      "2025-12-13 15:16:33,231 - INFO - Detailed Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      1.00      0.41         7\n",
      "           1       1.00      0.17      0.29        42\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.29        49\n",
      "   macro avg       0.42      0.39      0.23        49\n",
      "weighted avg       0.89      0.29      0.30        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2801: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▃▄▅▅▆▆▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>test_precision</td><td>▁</td></tr><tr><td>test_recall</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▃▃▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▂▂▁▆▆▅▆▆▅▇█▆▆</td></tr><tr><td>val_loss</td><td>▃█▆▃▂▂▁▁▂▃▃▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>13</td></tr><tr><td>test_accuracy</td><td>0.58333</td></tr><tr><td>test_f1</td><td>0.30372</td></tr><tr><td>test_precision</td><td>0.89418</td></tr><tr><td>test_recall</td><td>0.28571</td></tr><tr><td>train_loss</td><td>0.66565</td></tr><tr><td>val_accuracy</td><td>0.5102</td></tr><tr><td>val_loss</td><td>1.03833</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lilac-snowflake-77</strong> at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/yt5p5817' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/yt5p5817</a><br> View project at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251213_151630-yt5p5817\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_wandb()\n",
    "train_model(net4, optimizer, loss_fn, enable_early_stopping=True, patience=5)\n",
    "evaluate_model(net4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2b120b",
   "metadata": {},
   "source": [
    "Net4 introduced some batch normalization to help with the overfitting problem. The learning rate also got decreased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ec8c231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [32, 3]                   --\n",
       "├─Conv2d: 1-1                            [32, 8, 224, 224]         80\n",
       "├─BatchNorm2d: 1-2                       [32, 8, 224, 224]         16\n",
       "├─ReLU: 1-3                              [32, 8, 224, 224]         --\n",
       "├─MaxPool2d: 1-4                         [32, 8, 112, 112]         --\n",
       "├─Conv2d: 1-5                            [32, 16, 112, 112]        1,168\n",
       "├─BatchNorm2d: 1-6                       [32, 16, 112, 112]        32\n",
       "├─ReLU: 1-7                              [32, 16, 112, 112]        --\n",
       "├─MaxPool2d: 1-8                         [32, 16, 56, 56]          --\n",
       "├─Conv2d: 1-9                            [32, 32, 56, 56]          4,640\n",
       "├─BatchNorm2d: 1-10                      [32, 32, 56, 56]          64\n",
       "├─ReLU: 1-11                             [32, 32, 56, 56]          --\n",
       "├─MaxPool2d: 1-12                        [32, 32, 28, 28]          --\n",
       "├─Conv2d: 1-13                           [32, 64, 28, 28]          18,496\n",
       "├─BatchNorm2d: 1-14                      [32, 64, 28, 28]          128\n",
       "├─ReLU: 1-15                             [32, 64, 28, 28]          --\n",
       "├─MaxPool2d: 1-16                        [32, 64, 14, 14]          --\n",
       "├─Conv2d: 1-17                           [32, 32, 14, 14]          18,464\n",
       "├─BatchNorm2d: 1-18                      [32, 32, 14, 14]          64\n",
       "├─ReLU: 1-19                             [32, 32, 14, 14]          --\n",
       "├─MaxPool2d: 1-20                        [32, 32, 7, 7]            --\n",
       "├─AdaptiveAvgPool2d: 1-21                [32, 32, 1, 1]            --\n",
       "├─Flatten: 1-22                          [32, 32]                  --\n",
       "├─Linear: 1-23                           [32, 128]                 4,224\n",
       "├─ReLU: 1-24                             [32, 128]                 --\n",
       "├─Dropout: 1-25                          [32, 128]                 --\n",
       "├─Linear: 1-26                           [32, 64]                  8,256\n",
       "├─ReLU: 1-27                             [32, 64]                  --\n",
       "├─Dropout: 1-28                          [32, 64]                  --\n",
       "├─Linear: 1-29                           [32, 3]                   195\n",
       "==========================================================================================\n",
       "Total params: 55,827\n",
       "Trainable params: 55,827\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.64\n",
       "==========================================================================================\n",
       "Input size (MB): 6.42\n",
       "Forward/backward pass size (MB): 388.61\n",
       "Params size (MB): 0.22\n",
       "Estimated Total Size (MB): 395.26\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net5 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1),      # (3x3x1)x8\n",
    "    torch.nn.BatchNorm2d(8),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 224x224 -> 112x112\n",
    "\n",
    "    torch.nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),       # (3x3x8)x16\n",
    "    torch.nn.BatchNorm2d(16),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 112x112 -> 56x56\n",
    "\n",
    "    torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),       # (3x3x16)x32\n",
    "    torch.nn.BatchNorm2d(32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 56x56 -> 28x28 \n",
    "\n",
    "    torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),       # (3x3x32)x64\n",
    "    torch.nn.BatchNorm2d(64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 28x28 -> 14x14 \n",
    "\n",
    "    torch.nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),       # (3x3x64)x32\n",
    "    torch.nn.BatchNorm2d(32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 14x14 -> 7x7\n",
    "\n",
    "    torch.nn.AdaptiveAvgPool2d(1),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(32, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(128, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(64, 3)                       # Output layer     \n",
    ").to(device)\n",
    "\n",
    "net5.apply(init_weights)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net5.parameters(), lr=0.0005)\n",
    "\n",
    "summary(net5, input_size=(batch_size, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b536162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Win 10\\Desktop\\BME\\DeepL\\BMEVITMMA18_Deep-Learning_AnkleAlign_D6AE9F\\notebook\\wandb\\run-20251213_155741-5d964ma9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/5d964ma9' target=\"_blank\">twilight-lake-80</a></strong> to <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/5d964ma9' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/5d964ma9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:57:42,182 - INFO - Epoch 1/70, Train Loss: 1.4819, Val Loss: 1.0912, Val Acc: 0.3878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   1%|▏         | 1/70 [00:00<00:15,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:57:42,308 - INFO - Epoch 2/70, Train Loss: 1.1386, Val Loss: 1.0551, Val Acc: 0.4286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   3%|▎         | 2/70 [00:00<00:11,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:57:42,489 - INFO - Epoch 3/70, Train Loss: 1.1347, Val Loss: 1.0378, Val Acc: 0.4898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   4%|▍         | 3/70 [00:00<00:11,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:57:42,637 - INFO - Epoch 4/70, Train Loss: 1.0606, Val Loss: 1.0251, Val Acc: 0.4490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   6%|▌         | 4/70 [00:00<00:10,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:57:42,767 - INFO - Epoch 5/70, Train Loss: 0.9933, Val Loss: 1.0068, Val Acc: 0.5918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   7%|▋         | 5/70 [00:00<00:09,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:57:42,900 - INFO - Epoch 6/70, Train Loss: 0.9415, Val Loss: 1.0032, Val Acc: 0.5714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   9%|▊         | 6/70 [00:00<00:09,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:57:43,024 - INFO - Epoch 7/70, Train Loss: 0.9744, Val Loss: 1.0096, Val Acc: 0.5714\n",
      "2025-12-13 15:57:43,024 - INFO - EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  10%|█         | 7/70 [00:01<00:08,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:57:43,241 - INFO - Epoch 8/70, Train Loss: 0.9258, Val Loss: 1.0378, Val Acc: 0.5102\n",
      "2025-12-13 15:57:43,242 - INFO - EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  11%|█▏        | 8/70 [00:01<00:10,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:57:43,364 - INFO - Epoch 9/70, Train Loss: 0.9108, Val Loss: 1.0369, Val Acc: 0.5510\n",
      "2025-12-13 15:57:43,364 - INFO - EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  13%|█▎        | 9/70 [00:01<00:09,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:57:43,571 - INFO - Epoch 10/70, Train Loss: 0.9153, Val Loss: 1.0458, Val Acc: 0.6327\n",
      "2025-12-13 15:57:43,572 - INFO - EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  14%|█▍        | 10/70 [00:01<00:10,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:57:43,702 - INFO - Epoch 11/70, Train Loss: 0.8838, Val Loss: 1.0887, Val Acc: 0.5102\n",
      "2025-12-13 15:57:43,702 - INFO - EarlyStopping counter: 5 out of 5\n",
      "2025-12-13 15:57:43,702 - INFO - Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  14%|█▍        | 10/70 [00:01<00:10,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:57:43,708 - INFO - Loaded best model weights\n",
      "2025-12-13 15:57:43,709 - INFO - [1.4818991422653198, 1.1385776698589325, 1.134666085243225, 1.0605972806612651, 0.9933082362016042, 0.9415448606014252, 0.9744154115517935, 0.9258333047231039, 0.910777618487676, 0.9152572055657705, 0.8837806483109792]\n",
      "2025-12-13 15:57:43,752 - INFO - network accuracy: 51.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 15:57:43,753 - INFO - network precision: 87.80%\n",
      "2025-12-13 15:57:43,754 - INFO - network recall: 16.33%\n",
      "2025-12-13 15:57:43,756 - INFO - network F1 score: 7.62%\n",
      "2025-12-13 15:57:43,769 - INFO - Detailed Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      1.00      0.25         7\n",
      "           1       1.00      0.02      0.05        42\n",
      "\n",
      "    accuracy                           0.16        49\n",
      "   macro avg       0.57      0.51      0.15        49\n",
      "weighted avg       0.88      0.16      0.08        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>test_precision</td><td>▁</td></tr><tr><td>test_recall</td><td>▁</td></tr><tr><td>train_loss</td><td>█▄▄▃▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▄▃▇▆▆▅▆█▅</td></tr><tr><td>val_loss</td><td>█▅▄▃▁▁▂▄▄▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>11</td></tr><tr><td>test_accuracy</td><td>0.5119</td></tr><tr><td>test_f1</td><td>0.07623</td></tr><tr><td>test_precision</td><td>0.87798</td></tr><tr><td>test_recall</td><td>0.16327</td></tr><tr><td>train_loss</td><td>0.88378</td></tr><tr><td>val_accuracy</td><td>0.5102</td></tr><tr><td>val_loss</td><td>1.08871</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twilight-lake-80</strong> at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/5d964ma9' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/5d964ma9</a><br> View project at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251213_155741-5d964ma9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_wandb()\n",
    "train_model(net5, optimizer, loss_fn, enable_early_stopping=True, patience=5)\n",
    "evaluate_model(net5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacc7fb5",
   "metadata": {},
   "source": [
    "Net5 introdiced dropout to the fully connected layers but it did not imrpoved the model's performance compared to the previous net4.\n",
    "I think I overshot the complexity a little, I will remove some complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b0b7198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:07:20,459 - INFO - Training images shape: torch.Size([241, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Introduce some transformations to train and val datasets\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to consistent size\n",
    "    transforms.RandomHorizontalFlip(p=0.3), # Random horizontal flip\n",
    "    transforms.RandomRotation(degrees=15),  # Random rotation\n",
    "    transforms.ToTensor(),           # Convert to tensor [0, 1]\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for img_name, label in train_data:\n",
    "    img_path = os.path.join(preped_folder, img_name)\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('L') # Convert to grayscale\n",
    "        img_tensor = transform(img)\n",
    "        x_train.append(img_tensor)\n",
    "        y_train.append(label)\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Error loading {img_name}: {e}\")\n",
    "\n",
    "# Stack into tensors\n",
    "x_train_tensor = torch.stack(x_train)\n",
    "logger.info(f\"Training images shape: {x_train_tensor.shape}\")\n",
    "\n",
    "# Encode labels to integers\n",
    "label_to_idx = {label: idx for idx, label in enumerate(np.unique(y_train))}\n",
    "y_train_encoded = [label_to_idx[label] for label in y_train]\n",
    "y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1cc224b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train test split, for getting validation metrics during training\n",
    "x_train_tensor, x_val_tensor, y_train_tensor, y_val_tensor = train_test_split(\n",
    "    x_train_tensor, y_train_tensor, test_size=0.2, random_state=42, stratify=y_train_tensor)\n",
    "\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f31768dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [32, 3]                   --\n",
       "├─Conv2d: 1-1                            [32, 8, 224, 224]         80\n",
       "├─BatchNorm2d: 1-2                       [32, 8, 224, 224]         16\n",
       "├─ReLU: 1-3                              [32, 8, 224, 224]         --\n",
       "├─MaxPool2d: 1-4                         [32, 8, 112, 112]         --\n",
       "├─Conv2d: 1-5                            [32, 16, 112, 112]        1,168\n",
       "├─BatchNorm2d: 1-6                       [32, 16, 112, 112]        32\n",
       "├─ReLU: 1-7                              [32, 16, 112, 112]        --\n",
       "├─MaxPool2d: 1-8                         [32, 16, 56, 56]          --\n",
       "├─Conv2d: 1-9                            [32, 32, 56, 56]          4,640\n",
       "├─BatchNorm2d: 1-10                      [32, 32, 56, 56]          64\n",
       "├─ReLU: 1-11                             [32, 32, 56, 56]          --\n",
       "├─MaxPool2d: 1-12                        [32, 32, 28, 28]          --\n",
       "├─Conv2d: 1-13                           [32, 64, 28, 28]          18,496\n",
       "├─BatchNorm2d: 1-14                      [32, 64, 28, 28]          128\n",
       "├─ReLU: 1-15                             [32, 64, 28, 28]          --\n",
       "├─MaxPool2d: 1-16                        [32, 64, 14, 14]          --\n",
       "├─AdaptiveAvgPool2d: 1-17                [32, 64, 1, 1]            --\n",
       "├─Flatten: 1-18                          [32, 64]                  --\n",
       "├─Linear: 1-19                           [32, 128]                 8,320\n",
       "├─ReLU: 1-20                             [32, 128]                 --\n",
       "├─Dropout: 1-21                          [32, 128]                 --\n",
       "├─Linear: 1-22                           [32, 3]                   387\n",
       "==========================================================================================\n",
       "Total params: 33,331\n",
       "Trainable params: 33,331\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.53\n",
       "==========================================================================================\n",
       "Input size (MB): 6.42\n",
       "Forward/backward pass size (MB): 385.39\n",
       "Params size (MB): 0.13\n",
       "Estimated Total Size (MB): 391.94\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net6 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1),      # (3x3x1)x8\n",
    "    torch.nn.BatchNorm2d(8),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 224x224 -> 112x112\n",
    "\n",
    "    torch.nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),       # (3x3x8)x16\n",
    "    torch.nn.BatchNorm2d(16),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 112x112 -> 56x56\n",
    "\n",
    "    torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),       # (3x3x16)x32\n",
    "    torch.nn.BatchNorm2d(32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 56x56 -> 28x28 \n",
    "\n",
    "    torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),       # (3x3x32)x64\n",
    "    torch.nn.BatchNorm2d(64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 28x28 -> 14x14 \n",
    "\n",
    "    torch.nn.AdaptiveAvgPool2d(1),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(64, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(128, 3),\n",
    ").to(device)\n",
    "\n",
    "net6.apply(init_weights)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net6.parameters(), lr=0.0005)\n",
    "summary(net6, input_size=(batch_size, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e746ce0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Win 10\\Desktop\\BME\\DeepL\\BMEVITMMA18_Deep-Learning_AnkleAlign_D6AE9F\\notebook\\wandb\\run-20251213_160855-vz497py4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/vz497py4' target=\"_blank\">visionary-sunset-86</a></strong> to <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/vz497py4' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/vz497py4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:08:56,735 - INFO - Epoch 1/70, Train Loss: 1.0942, Val Loss: 1.1332, Val Acc: 0.4082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   1%|▏         | 1/70 [00:00<00:29,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:08:56,864 - INFO - Epoch 2/70, Train Loss: 0.9878, Val Loss: 1.0450, Val Acc: 0.4286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   3%|▎         | 2/70 [00:00<00:16,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:08:56,984 - INFO - Epoch 3/70, Train Loss: 0.9853, Val Loss: 1.0164, Val Acc: 0.4490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   4%|▍         | 3/70 [00:00<00:12,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:08:57,097 - INFO - Epoch 4/70, Train Loss: 0.9671, Val Loss: 1.0156, Val Acc: 0.5102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   6%|▌         | 4/70 [00:00<00:10,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:08:57,213 - INFO - Epoch 5/70, Train Loss: 0.9939, Val Loss: 1.0174, Val Acc: 0.4898\n",
      "2025-12-13 16:08:57,213 - INFO - EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   7%|▋         | 5/70 [00:00<00:09,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:08:57,327 - INFO - Epoch 6/70, Train Loss: 1.0014, Val Loss: 1.0161, Val Acc: 0.5510\n",
      "2025-12-13 16:08:57,327 - INFO - EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   9%|▊         | 6/70 [00:01<00:08,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:08:57,455 - INFO - Epoch 7/70, Train Loss: 0.9679, Val Loss: 1.0098, Val Acc: 0.5714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  10%|█         | 7/70 [00:01<00:08,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:08:57,578 - INFO - Epoch 8/70, Train Loss: 0.9739, Val Loss: 1.0081, Val Acc: 0.5102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  11%|█▏        | 8/70 [00:01<00:07,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:08:57,705 - INFO - Epoch 9/70, Train Loss: 0.9466, Val Loss: 1.0164, Val Acc: 0.5306\n",
      "2025-12-13 16:08:57,705 - INFO - EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  13%|█▎        | 9/70 [00:01<00:07,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:08:57,822 - INFO - Epoch 10/70, Train Loss: 0.9444, Val Loss: 1.0193, Val Acc: 0.5306\n",
      "2025-12-13 16:08:57,822 - INFO - EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  14%|█▍        | 10/70 [00:01<00:07,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:08:57,943 - INFO - Epoch 11/70, Train Loss: 0.9497, Val Loss: 1.0320, Val Acc: 0.5102\n",
      "2025-12-13 16:08:57,943 - INFO - EarlyStopping counter: 3 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  16%|█▌        | 11/70 [00:01<00:07,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:08:58,068 - INFO - Epoch 12/70, Train Loss: 0.9621, Val Loss: 1.0393, Val Acc: 0.4694\n",
      "2025-12-13 16:08:58,069 - INFO - EarlyStopping counter: 4 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  17%|█▋        | 12/70 [00:01<00:07,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:08:58,190 - INFO - Epoch 13/70, Train Loss: 0.9119, Val Loss: 1.0414, Val Acc: 0.4694\n",
      "2025-12-13 16:08:58,191 - INFO - EarlyStopping counter: 5 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  19%|█▊        | 13/70 [00:01<00:07,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:08:58,320 - INFO - Epoch 14/70, Train Loss: 0.9256, Val Loss: 1.0381, Val Acc: 0.4490\n",
      "2025-12-13 16:08:58,320 - INFO - EarlyStopping counter: 6 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  20%|██        | 14/70 [00:02<00:07,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:08:58,441 - INFO - Epoch 15/70, Train Loss: 0.9336, Val Loss: 1.0230, Val Acc: 0.5102\n",
      "2025-12-13 16:08:58,441 - INFO - EarlyStopping counter: 7 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  21%|██▏       | 15/70 [00:02<00:06,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:08:58,566 - INFO - Epoch 16/70, Train Loss: 0.9283, Val Loss: 1.0212, Val Acc: 0.5714\n",
      "2025-12-13 16:08:58,567 - INFO - EarlyStopping counter: 8 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  23%|██▎       | 16/70 [00:02<00:06,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:08:58,688 - INFO - Epoch 17/70, Train Loss: 0.9094, Val Loss: 1.0381, Val Acc: 0.5102\n",
      "2025-12-13 16:08:58,688 - INFO - EarlyStopping counter: 9 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  24%|██▍       | 17/70 [00:02<00:06,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:08:58,804 - INFO - Epoch 18/70, Train Loss: 0.8929, Val Loss: 1.0336, Val Acc: 0.6122\n",
      "2025-12-13 16:08:58,804 - INFO - EarlyStopping counter: 10 out of 10\n",
      "2025-12-13 16:08:58,804 - INFO - Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  24%|██▍       | 17/70 [00:02<00:07,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-13 16:08:58,808 - INFO - Loaded best model weights\n",
      "2025-12-13 16:08:58,808 - INFO - [1.09416929880778, 0.9878494342168173, 0.985325038433075, 0.9670831660429636, 0.993853231271108, 1.0014472007751465, 0.9679023226102194, 0.9739410976568857, 0.9466008941332499, 0.9444488286972046, 0.9497192005316416, 0.9621264139811198, 0.9119105835755666, 0.9256239036719004, 0.933592309554418, 0.9282891054948171, 0.9093623459339142, 0.8928599953651428]\n",
      "2025-12-13 16:08:58,836 - INFO - network accuracy: 55.95%\n",
      "2025-12-13 16:08:58,837 - INFO - network precision: 88.49%\n",
      "2025-12-13 16:08:58,837 - INFO - network recall: 24.49%\n",
      "2025-12-13 16:08:58,838 - INFO - network F1 score: 22.89%\n",
      "2025-12-13 16:08:58,850 - INFO - Detailed Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      1.00      0.33         7\n",
      "           1       1.00      0.12      0.21        42\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.24        49\n",
      "   macro avg       0.40      0.37      0.18        49\n",
      "weighted avg       0.88      0.24      0.23        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2801: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>test_precision</td><td>▁</td></tr><tr><td>test_recall</td><td>▁</td></tr><tr><td>train_loss</td><td>█▄▄▄▅▅▄▄▃▃▃▃▂▂▂▂▂▁</td></tr><tr><td>val_accuracy</td><td>▁▂▂▄▄▆▇▄▅▅▄▃▃▂▄▇▄█</td></tr><tr><td>val_loss</td><td>█▃▁▁▂▁▁▁▁▂▂▃▃▃▂▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>18</td></tr><tr><td>test_accuracy</td><td>0.55952</td></tr><tr><td>test_f1</td><td>0.22888</td></tr><tr><td>test_precision</td><td>0.88492</td></tr><tr><td>test_recall</td><td>0.2449</td></tr><tr><td>train_loss</td><td>0.89286</td></tr><tr><td>val_accuracy</td><td>0.61224</td></tr><tr><td>val_loss</td><td>1.03359</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">visionary-sunset-86</strong> at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/vz497py4' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/vz497py4</a><br> View project at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251213_160855-vz497py4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_wandb()\n",
    "train_model(net6, optimizer, loss_fn, enable_early_stopping=True, patience=10)\n",
    "evaluate_model(net6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLankle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
