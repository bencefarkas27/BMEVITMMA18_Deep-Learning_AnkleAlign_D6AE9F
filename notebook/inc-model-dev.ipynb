{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a3f8778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import wandb\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29847982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger(name=__name__):\n",
    "    \"\"\"\n",
    "    Sets up a logger that outputs to the console (stdout).\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(name)\n",
    "    if not logger.handlers:\n",
    "        logger.setLevel(logging.INFO)\n",
    "        handler = logging.StreamHandler(sys.stdout)\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "    return logger\n",
    "\n",
    "logger = setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d93a317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:37,752 - INFO - Training images shape: torch.Size([241, 1, 224, 224])\n",
      "2025-12-12 15:23:37,753 - INFO - Training labels shape: torch.Size([241])\n",
      "2025-12-12 15:23:37,754 - INFO - Label mapping: {np.str_('1_Pronacio'): 0, np.str_('2_Neutralis'): 1, np.str_('3_Szupinacio'): 2}\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_folder = \"../data\"\n",
    "preped_folder = os.path.join(data_folder, \"_preped\")\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(data_folder, 'train_data.csv')).values.tolist()\n",
    "test_data = pd.read_csv(os.path.join(data_folder, 'test_data.csv')).values.tolist()\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to consistent size\n",
    "    transforms.ToTensor(),           # Convert to tensor [0, 1]\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for img_name, label in train_data:\n",
    "    img_path = os.path.join(preped_folder, img_name)\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('L') # Convert to grayscale\n",
    "        img_tensor = transform(img)\n",
    "        x_train.append(img_tensor)\n",
    "        y_train.append(label)\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Error loading {img_name}: {e}\")\n",
    "\n",
    "# Stack into tensors\n",
    "x_train_tensor = torch.stack(x_train)\n",
    "logger.info(f\"Training images shape: {x_train_tensor.shape}\")\n",
    "\n",
    "# Encode labels to integers\n",
    "label_to_idx = {label: idx for idx, label in enumerate(np.unique(y_train))}\n",
    "y_train_encoded = [label_to_idx[label] for label in y_train]\n",
    "y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.long)\n",
    "\n",
    "logger.info(f\"Training labels shape: {y_train_tensor.shape}\")\n",
    "logger.info(f\"Label mapping: {label_to_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f39e88ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:44,175 - INFO - Test images shape: torch.Size([49, 1, 224, 224])\n",
      "2025-12-12 15:23:44,175 - INFO - Test labels shape: torch.Size([49])\n"
     ]
    }
   ],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for img_name, label in test_data:\n",
    "    img_path = os.path.join(preped_folder, img_name)\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('L') # Convert to grayscale\n",
    "        img_tensor = transform(img)\n",
    "        x_test.append(img_tensor)\n",
    "        y_test.append(label)\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Error loading {img_name}: {e}\")\n",
    "\n",
    "x_test_tensor = torch.stack(x_test)\n",
    "logger.info(f\"Test images shape: {x_test_tensor.shape}\")\n",
    "y_test_encoded = [label_to_idx[label] for label in y_test]\n",
    "y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long)\n",
    "\n",
    "logger.info(f\"Test labels shape: {y_test_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f6197a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:44,185 - INFO - CUDA available: True\n",
      "2025-12-12 15:23:44,186 - INFO - Number of GPUs: 1\n",
      "2025-12-12 15:23:44,187 - INFO - \n",
      "GPU 0: NVIDIA GeForce RTX 4060\n",
      "2025-12-12 15:23:44,188 - INFO -   Memory: 8.00 GB\n",
      "2025-12-12 15:23:44,189 - INFO -   Compute Capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    logger.info(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        logger.info(f\"\\nGPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        logger.info(f\"  Memory: {props.total_memory / 1024**3:.2f} GB\")\n",
    "        logger.info(f\"  Compute Capability: {props.major}.{props.minor}\")\n",
    "else:\n",
    "    logger.info(\"CUDA not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2a044d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 70\n",
    "device = 'cuda' \n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1a2c812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Win 10\\_netrc\n"
     ]
    }
   ],
   "source": [
    "# wandb login an init\n",
    "# Login to wandb with API key\n",
    "load_dotenv()\n",
    "wandb.login(key=os.getenv(\"wandbKey\"))\n",
    "\n",
    "def init_wandb():\n",
    "    # Initialize wandb project\n",
    "    wandb.init(\n",
    "        project=\"ankle-align-inc-model\",\n",
    "        config={\n",
    "            \"batch_size\": batch_size,\n",
    "            \"num_epochs\": num_epochs,\n",
    "      \n",
    "            \"architecture\": \"Custom CNN\",\n",
    "            \"dataset\": \"AnkleAlign\",\n",
    "            \"optimizer\": \"Adam\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd9b01ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [16, 3]                   --\n",
       "├─Conv2d: 1-1                            [16, 8, 112, 112]         80\n",
       "├─ReLU: 1-2                              [16, 8, 112, 112]         --\n",
       "├─Conv2d: 1-3                            [16, 16, 56, 56]          1,168\n",
       "├─ReLU: 1-4                              [16, 16, 56, 56]          --\n",
       "├─Conv2d: 1-5                            [16, 32, 28, 28]          4,640\n",
       "├─ReLU: 1-6                              [16, 32, 28, 28]          --\n",
       "├─AdaptiveAvgPool2d: 1-7                 [16, 32, 1, 1]            --\n",
       "├─Flatten: 1-8                           [16, 32]                  --\n",
       "├─Linear: 1-9                            [16, 128]                 4,224\n",
       "├─ReLU: 1-10                             [16, 128]                 --\n",
       "├─Linear: 1-11                           [16, 64]                  8,256\n",
       "├─ReLU: 1-12                             [16, 64]                  --\n",
       "├─Linear: 1-13                           [16, 3]                   195\n",
       "==========================================================================================\n",
       "Total params: 18,563\n",
       "Trainable params: 18,563\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 133.07\n",
       "==========================================================================================\n",
       "Input size (MB): 3.21\n",
       "Forward/backward pass size (MB): 22.50\n",
       "Params size (MB): 0.07\n",
       "Estimated Total Size (MB): 25.79\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net0 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1),   # 224x224 -> 112x112\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),  # 112x112 -> 56x56\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # 56x56 -> 28x28\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.AdaptiveAvgPool2d(1),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(32, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 3)                       # Output layer     \n",
    ").to(device)\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "net0.apply(init_weights)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(net0.parameters(), lr=0.1, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(net0.parameters(), lr=0.01)\n",
    "\n",
    "summary(net0, input_size=(batch_size, 1, 224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e528be05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Win 10\\Desktop\\BME\\DeepL\\BMEVITMMA18_Deep-Learning_AnkleAlign_D6AE9F\\notebook\\wandb\\run-20251212_152345-mj0kejr3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/mj0kejr3' target=\"_blank\">apricot-jazz-1</a></strong> to <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/mj0kejr3' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/mj0kejr3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 70/70 [00:00<00:00, 125.56it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>██▇▇▇▆▆▆▆▆▅▅▄▅▄▄▄▃▃▄▂▂▃▂▂▂▁▁▁▁▁▁▂▅▂▂▄▅▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>70</td></tr><tr><td>train_loss</td><td>0.10161</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">apricot-jazz-1</strong> at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/mj0kejr3' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/mj0kejr3</a><br> View project at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251212_152345-mj0kejr3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1201071739196777, 1.133108377456665, 1.0402389764785767, 0.9731132984161377, 0.9565080404281616, 0.9460327625274658, 0.903011679649353, 0.8771029710769653, 0.865113377571106, 0.8425642251968384, 0.8185439109802246, 0.7937295436859131, 0.7641617059707642, 0.7389482855796814, 0.7124192714691162, 0.6814556121826172, 0.6469080448150635, 0.6081164479255676, 0.6201109290122986, 0.6805386543273926, 0.5522283911705017, 0.5590860843658447, 0.5181375741958618, 0.4898614287376404, 0.47567176818847656, 0.3925952911376953, 0.41096431016921997, 0.3562488257884979, 0.364826500415802, 0.3263346552848816, 0.5982373952865601, 0.4799767732620239, 0.34488189220428467, 0.3888360261917114, 0.31425362825393677, 0.2902117669582367, 0.3504578471183777, 0.21387368440628052, 0.27393537759780884, 0.2102767378091812, 0.23218084871768951, 0.19255468249320984, 0.16975906491279602, 0.18739774823188782, 0.1539849489927292, 0.15938788652420044, 0.1312681883573532, 0.11715013533830643, 0.10791566967964172, 0.09306634962558746, 0.0914798304438591, 0.1914462149143219, 0.7349300384521484, 0.648547887802124, 0.27502965927124023, 0.733291506767273, 0.2696552872657776, 0.4618455171585083, 0.274141401052475, 0.5522375106811523, 0.12870875000953674, 0.6202230453491211, 0.11830948293209076, 0.41063541173934937, 0.15044845640659332, 0.21115782856941223, 0.2070327252149582, 0.24417021870613098, 0.15101858973503113, 0.10160976648330688]\n"
     ]
    }
   ],
   "source": [
    "# Trying to overfit one batch\n",
    "init_wandb()\n",
    "one_batch = next(iter(train_loader))\n",
    "images, labels = one_batch\n",
    "\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "loss_values = []\n",
    "net0.train()\n",
    "for epoch in tqdm(range(num_epochs), desc='Training model'):\n",
    "        pred_logits = net0(images)\n",
    "        loss = loss_fn(pred_logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_values.append(loss.item())\n",
    "        wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": loss.item()\n",
    "            })\n",
    "        \n",
    "wandb.finish()\n",
    "print(loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a9f0ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(network, optimizer, loss_fn, enable_early_stopping=False, patience=5):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    loss_values = []\n",
    "\n",
    "    if enable_early_stopping:\n",
    "        early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "    network.train()\n",
    "    for epoch in tqdm(range(num_epochs), desc='Training model'):\n",
    "        network.train()\n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "        for images, target_labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            target_labels = target_labels.to(device)\n",
    "\n",
    "            pred_logits = network(images)\n",
    "            loss = loss_fn(pred_logits, target_labels)\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        avg_train_loss = epoch_loss / num_batches\n",
    "\n",
    "        if enable_early_stopping:\n",
    "            network.eval()\n",
    "            val_loss = 0.0\n",
    "            val_batches = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for images, target_labels in val_loader:\n",
    "                    images = images.to(device)\n",
    "                    target_labels = target_labels.to(device)\n",
    "                    \n",
    "                    pred_logits = network(images)\n",
    "                    loss = loss_fn(pred_logits, target_labels)\n",
    "                    val_loss += loss.item()\n",
    "                    val_batches += 1\n",
    "                    \n",
    "                    _, predicted = torch.max(pred_logits, 1)\n",
    "                    total += target_labels.size(0)\n",
    "                    correct += (predicted == target_labels).sum().item()\n",
    "            \n",
    "            avg_val_loss = val_loss / val_batches\n",
    "            val_accuracy = correct / total\n",
    "\n",
    "        # Log metrics\n",
    "        if enable_early_stopping:\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": avg_train_loss,\n",
    "                \"val_loss\": avg_val_loss,\n",
    "                \"val_accuracy\": val_accuracy\n",
    "            })\n",
    "        else:\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": avg_train_loss\n",
    "            })\n",
    "        loss_values.append(avg_train_loss)\n",
    "        \n",
    "        if enable_early_stopping:\n",
    "            logger.info(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "        else:\n",
    "            logger.info(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if enable_early_stopping:\n",
    "            early_stopping(avg_val_loss, network)\n",
    "            if early_stopping.early_stop:\n",
    "                logger.info(\"Early stopping triggered\")\n",
    "                network.load_state_dict(early_stopping.best_model)\n",
    "                break\n",
    "    \n",
    "    # Load best model\n",
    "    if enable_early_stopping and early_stopping.best_model is not None:\n",
    "        network.load_state_dict(early_stopping.best_model)\n",
    "        logger.info(\"Loaded best model weights\")\n",
    "\n",
    "    logger.info(loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "517e5537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(network):\n",
    "    # Training score\n",
    "    true_labels = y_test_encoded\n",
    "    predicted_labels = []\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = network(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = np.mean([true == pred for true, pred in zip(true_labels, predicted_labels)])\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "    logger.info(f\"network accuracy: {accuracy * 100:.2f}%\")\n",
    "    logger.info(f\"network precision: {precision * 100:.2f}%\")\n",
    "    logger.info(f\"network recall: {recall * 100:.2f}%\")\n",
    "    logger.info(f\"network F1 score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    logger.info(f\"Detailed Classification Report: \\n{classification_report(true_labels, predicted_labels)}\")\n",
    "\n",
    "    # Log test metrics\n",
    "    wandb.log({\n",
    "        \"test_accuracy\": accuracy,\n",
    "        \"test_precision\": precision,\n",
    "        \"test_recall\": recall,\n",
    "        \"test_f1\": f1\n",
    "    })\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56f0bf57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Win 10\\Desktop\\BME\\DeepL\\BMEVITMMA18_Deep-Learning_AnkleAlign_D6AE9F\\notebook\\wandb\\run-20251212_152349-ff34wcrx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/ff34wcrx' target=\"_blank\">helpful-lion-2</a></strong> to <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/ff34wcrx' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/ff34wcrx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:50,170 - INFO - Epoch 1/70, Train Loss: 2.1479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   1%|▏         | 1/70 [00:00<00:10,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:50,323 - INFO - Epoch 2/70, Train Loss: 1.0423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   3%|▎         | 2/70 [00:00<00:10,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:50,445 - INFO - Epoch 3/70, Train Loss: 0.9985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   4%|▍         | 3/70 [00:00<00:09,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:50,542 - INFO - Epoch 4/70, Train Loss: 1.0615\n",
      "2025-12-12 15:23:50,631 - INFO - Epoch 5/70, Train Loss: 1.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   7%|▋         | 5/70 [00:00<00:07,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:50,721 - INFO - Epoch 6/70, Train Loss: 1.0168\n",
      "2025-12-12 15:23:50,805 - INFO - Epoch 7/70, Train Loss: 0.9731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  10%|█         | 7/70 [00:00<00:06,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:50,884 - INFO - Epoch 8/70, Train Loss: 0.9736\n",
      "2025-12-12 15:23:50,965 - INFO - Epoch 9/70, Train Loss: 1.0406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  13%|█▎        | 9/70 [00:00<00:05, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:51,049 - INFO - Epoch 10/70, Train Loss: 1.0123\n",
      "2025-12-12 15:23:51,134 - INFO - Epoch 11/70, Train Loss: 0.9852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  16%|█▌        | 11/70 [00:01<00:05, 11.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:51,237 - INFO - Epoch 12/70, Train Loss: 0.9852\n",
      "2025-12-12 15:23:51,346 - INFO - Epoch 13/70, Train Loss: 1.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  19%|█▊        | 13/70 [00:01<00:05, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:51,431 - INFO - Epoch 14/70, Train Loss: 0.9885\n",
      "2025-12-12 15:23:51,516 - INFO - Epoch 15/70, Train Loss: 0.9790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  21%|██▏       | 15/70 [00:01<00:05, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:51,599 - INFO - Epoch 16/70, Train Loss: 0.9676\n",
      "2025-12-12 15:23:51,676 - INFO - Epoch 17/70, Train Loss: 0.9933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  24%|██▍       | 17/70 [00:01<00:04, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:51,761 - INFO - Epoch 18/70, Train Loss: 1.0163\n",
      "2025-12-12 15:23:51,848 - INFO - Epoch 19/70, Train Loss: 0.9779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  27%|██▋       | 19/70 [00:01<00:04, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:51,935 - INFO - Epoch 20/70, Train Loss: 1.0521\n",
      "2025-12-12 15:23:52,015 - INFO - Epoch 21/70, Train Loss: 0.9724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  30%|███       | 21/70 [00:01<00:04, 11.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:52,093 - INFO - Epoch 22/70, Train Loss: 1.0017\n",
      "2025-12-12 15:23:52,171 - INFO - Epoch 23/70, Train Loss: 0.9597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  33%|███▎      | 23/70 [00:02<00:03, 11.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:52,248 - INFO - Epoch 24/70, Train Loss: 0.9888\n",
      "2025-12-12 15:23:52,325 - INFO - Epoch 25/70, Train Loss: 0.9704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  36%|███▌      | 25/70 [00:02<00:03, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:52,405 - INFO - Epoch 26/70, Train Loss: 0.9868\n",
      "2025-12-12 15:23:52,483 - INFO - Epoch 27/70, Train Loss: 0.9608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  39%|███▊      | 27/70 [00:02<00:03, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:52,567 - INFO - Epoch 28/70, Train Loss: 0.9653\n",
      "2025-12-12 15:23:52,643 - INFO - Epoch 29/70, Train Loss: 0.9623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  41%|████▏     | 29/70 [00:02<00:03, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:52,736 - INFO - Epoch 30/70, Train Loss: 0.9592\n",
      "2025-12-12 15:23:52,819 - INFO - Epoch 31/70, Train Loss: 1.0202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  44%|████▍     | 31/70 [00:02<00:03, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:52,897 - INFO - Epoch 32/70, Train Loss: 0.9623\n",
      "2025-12-12 15:23:52,987 - INFO - Epoch 33/70, Train Loss: 0.9675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  47%|████▋     | 33/70 [00:02<00:03, 12.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:53,071 - INFO - Epoch 34/70, Train Loss: 0.9955\n",
      "2025-12-12 15:23:53,152 - INFO - Epoch 35/70, Train Loss: 1.0891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  50%|█████     | 35/70 [00:03<00:02, 12.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:53,233 - INFO - Epoch 36/70, Train Loss: 0.9954\n",
      "2025-12-12 15:23:53,313 - INFO - Epoch 37/70, Train Loss: 0.9975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  53%|█████▎    | 37/70 [00:03<00:02, 12.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:53,393 - INFO - Epoch 38/70, Train Loss: 0.9728\n",
      "2025-12-12 15:23:53,477 - INFO - Epoch 39/70, Train Loss: 0.9406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  56%|█████▌    | 39/70 [00:03<00:02, 12.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:53,567 - INFO - Epoch 40/70, Train Loss: 0.9466\n",
      "2025-12-12 15:23:53,646 - INFO - Epoch 41/70, Train Loss: 0.9268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  59%|█████▊    | 41/70 [00:03<00:02, 12.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:53,727 - INFO - Epoch 42/70, Train Loss: 0.9297\n",
      "2025-12-12 15:23:53,808 - INFO - Epoch 43/70, Train Loss: 0.9230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  61%|██████▏   | 43/70 [00:03<00:02, 12.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:53,888 - INFO - Epoch 44/70, Train Loss: 0.9026\n",
      "2025-12-12 15:23:53,965 - INFO - Epoch 45/70, Train Loss: 0.8643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  64%|██████▍   | 45/70 [00:03<00:02, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:54,044 - INFO - Epoch 46/70, Train Loss: 0.8784\n",
      "2025-12-12 15:23:54,126 - INFO - Epoch 47/70, Train Loss: 0.9626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  67%|██████▋   | 47/70 [00:04<00:01, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:54,208 - INFO - Epoch 48/70, Train Loss: 0.9104\n",
      "2025-12-12 15:23:54,291 - INFO - Epoch 49/70, Train Loss: 0.8463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  70%|███████   | 49/70 [00:04<00:01, 12.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:54,379 - INFO - Epoch 50/70, Train Loss: 0.8831\n",
      "2025-12-12 15:23:54,464 - INFO - Epoch 51/70, Train Loss: 0.8730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  73%|███████▎  | 51/70 [00:04<00:01, 12.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:54,542 - INFO - Epoch 52/70, Train Loss: 0.8286\n",
      "2025-12-12 15:23:54,620 - INFO - Epoch 53/70, Train Loss: 0.8179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  76%|███████▌  | 53/70 [00:04<00:01, 12.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:54,703 - INFO - Epoch 54/70, Train Loss: 0.9207\n",
      "2025-12-12 15:23:54,779 - INFO - Epoch 55/70, Train Loss: 0.8255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  79%|███████▊  | 55/70 [00:04<00:01, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:54,866 - INFO - Epoch 56/70, Train Loss: 0.8622\n",
      "2025-12-12 15:23:54,948 - INFO - Epoch 57/70, Train Loss: 0.8982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  81%|████████▏ | 57/70 [00:04<00:01, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:55,030 - INFO - Epoch 58/70, Train Loss: 0.8893\n",
      "2025-12-12 15:23:55,112 - INFO - Epoch 59/70, Train Loss: 1.0718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  84%|████████▍ | 59/70 [00:05<00:00, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:55,191 - INFO - Epoch 60/70, Train Loss: 0.9130\n",
      "2025-12-12 15:23:55,279 - INFO - Epoch 61/70, Train Loss: 0.8735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  87%|████████▋ | 61/70 [00:05<00:00, 12.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:55,361 - INFO - Epoch 62/70, Train Loss: 0.8439\n",
      "2025-12-12 15:23:55,444 - INFO - Epoch 63/70, Train Loss: 0.8646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  90%|█████████ | 63/70 [00:05<00:00, 12.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:55,527 - INFO - Epoch 64/70, Train Loss: 0.8963\n",
      "2025-12-12 15:23:55,606 - INFO - Epoch 65/70, Train Loss: 0.8113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  93%|█████████▎| 65/70 [00:05<00:00, 12.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:55,687 - INFO - Epoch 66/70, Train Loss: 0.8476\n",
      "2025-12-12 15:23:55,769 - INFO - Epoch 67/70, Train Loss: 0.7763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  96%|█████████▌| 67/70 [00:05<00:00, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:55,846 - INFO - Epoch 68/70, Train Loss: 0.7467\n",
      "2025-12-12 15:23:55,929 - INFO - Epoch 69/70, Train Loss: 0.7141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  99%|█████████▊| 69/70 [00:05<00:00, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:56,012 - INFO - Epoch 70/70, Train Loss: 0.7612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 70/70 [00:05<00:00, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:56,012 - INFO - [2.1479397527873516, 1.04226703196764, 0.9984908476471901, 1.0615405179560184, 1.0285776518285275, 1.0168384462594986, 0.9730907045304775, 0.973577369004488, 1.040578480809927, 1.0123360753059387, 0.9851948097348213, 0.9852248169481754, 1.0044987797737122, 0.9884758777916431, 0.9790437780320644, 0.9676056504249573, 0.9932688437402248, 1.016283307224512, 0.9778604730963707, 1.0521416179835796, 0.9723548591136932, 1.0016769617795944, 0.9596938230097294, 0.9887978546321392, 0.9703733585774899, 0.9867909550666809, 0.9607554562389851, 0.9653241857886314, 0.9622937403619289, 0.9591629132628441, 1.0202210135757923, 0.962305523455143, 0.967531181871891, 0.9954728111624718, 1.089143592864275, 0.9954351782798767, 0.9975288361310959, 0.9728072956204414, 0.9406430348753929, 0.9466492906212807, 0.9267650470137596, 0.9296736307442188, 0.9229747951030731, 0.9026137441396713, 0.8643356338143349, 0.8784051313996315, 0.962618250399828, 0.910431481897831, 0.8462686017155647, 0.883111160248518, 0.8730238154530525, 0.8286345675587654, 0.8178605269640684, 0.9207054674625397, 0.8255042359232903, 0.8621596470475197, 0.8982313126325607, 0.8892700336873531, 1.0718415677547455, 0.9130158498883247, 0.8734549321234226, 0.8439121544361115, 0.864641610532999, 0.8963025286793709, 0.811345923691988, 0.847565621137619, 0.7762815654277802, 0.746730700135231, 0.7141413055360317, 0.7611561845988035]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "init_wandb()\n",
    "train_model(net0, optimizer, loss_fn, enable_early_stopping=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36e5e606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [16, 3]                   --\n",
       "├─Conv2d: 1-1                            [16, 8, 112, 112]         80\n",
       "├─ReLU: 1-2                              [16, 8, 112, 112]         --\n",
       "├─Conv2d: 1-3                            [16, 16, 56, 56]          1,168\n",
       "├─ReLU: 1-4                              [16, 16, 56, 56]          --\n",
       "├─Conv2d: 1-5                            [16, 32, 28, 28]          4,640\n",
       "├─ReLU: 1-6                              [16, 32, 28, 28]          --\n",
       "├─Conv2d: 1-7                            [16, 32, 14, 14]          9,248\n",
       "├─ReLU: 1-8                              [16, 32, 14, 14]          --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [16, 32, 1, 1]            --\n",
       "├─Flatten: 1-10                          [16, 32]                  --\n",
       "├─Linear: 1-11                           [16, 128]                 4,224\n",
       "├─ReLU: 1-12                             [16, 128]                 --\n",
       "├─Linear: 1-13                           [16, 64]                  8,256\n",
       "├─ReLU: 1-14                             [16, 64]                  --\n",
       "├─Linear: 1-15                           [16, 3]                   195\n",
       "==========================================================================================\n",
       "Total params: 27,811\n",
       "Trainable params: 27,811\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 162.07\n",
       "==========================================================================================\n",
       "Input size (MB): 3.21\n",
       "Forward/backward pass size (MB): 23.31\n",
       "Params size (MB): 0.11\n",
       "Estimated Total Size (MB): 26.63\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1),   # 224x224 -> 112x112   // (3x3x1)x8\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),  # 112x112 -> 56x56     // (3x3x8)x16\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # 56x56 -> 28x28      // (3x3x16)x32\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),  # 28x28 -> 14x14      // (3x3x32)x32\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.AdaptiveAvgPool2d(1),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(32, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 3)                       # Output layer     \n",
    ").to(device)\n",
    "\n",
    "net1.apply(init_weights)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(net0.parameters(), lr=0.1, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(net1.parameters(), lr=0.001)\n",
    "\n",
    "summary(net1, input_size=(batch_size, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e0f02b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>▇▇▇▆▇▆▆▆▆▆▆▆▆▆▆▆▆█▆▆▅▅▅▆▅▄▄▃▃▃▄▄█▅▄▄▃▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>70</td></tr><tr><td>train_loss</td><td>0.76116</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">helpful-lion-2</strong> at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/ff34wcrx' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/ff34wcrx</a><br> View project at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251212_152349-ff34wcrx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Win 10\\Desktop\\BME\\DeepL\\BMEVITMMA18_Deep-Learning_AnkleAlign_D6AE9F\\notebook\\wandb\\run-20251212_152356-e7o2f64b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/e7o2f64b' target=\"_blank\">confused-violet-3</a></strong> to <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/e7o2f64b' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/e7o2f64b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:59,245 - INFO - Epoch 1/70, Train Loss: 1.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   1%|▏         | 1/70 [00:00<00:13,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:59,409 - INFO - Epoch 2/70, Train Loss: 0.9830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   3%|▎         | 2/70 [00:00<00:11,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:59,499 - INFO - Epoch 3/70, Train Loss: 0.9704\n",
      "2025-12-12 15:23:59,584 - INFO - Epoch 4/70, Train Loss: 0.9628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   6%|▌         | 4/70 [00:00<00:07,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:59,668 - INFO - Epoch 5/70, Train Loss: 0.9753\n",
      "2025-12-12 15:23:59,750 - INFO - Epoch 6/70, Train Loss: 1.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   9%|▊         | 6/70 [00:00<00:06,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:23:59,833 - INFO - Epoch 7/70, Train Loss: 0.9637\n",
      "2025-12-12 15:23:59,920 - INFO - Epoch 8/70, Train Loss: 0.9407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  11%|█▏        | 8/70 [00:00<00:05, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:00,003 - INFO - Epoch 9/70, Train Loss: 0.9950\n",
      "2025-12-12 15:24:00,085 - INFO - Epoch 10/70, Train Loss: 1.0566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  14%|█▍        | 10/70 [00:01<00:05, 11.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:00,162 - INFO - Epoch 11/70, Train Loss: 0.9978\n",
      "2025-12-12 15:24:00,257 - INFO - Epoch 12/70, Train Loss: 0.9706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  17%|█▋        | 12/70 [00:01<00:05, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:00,333 - INFO - Epoch 13/70, Train Loss: 0.9491\n",
      "2025-12-12 15:24:00,415 - INFO - Epoch 14/70, Train Loss: 0.9876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  20%|██        | 14/70 [00:01<00:04, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:00,506 - INFO - Epoch 15/70, Train Loss: 0.9680\n",
      "2025-12-12 15:24:00,591 - INFO - Epoch 16/70, Train Loss: 0.9549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  23%|██▎       | 16/70 [00:01<00:04, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:00,680 - INFO - Epoch 17/70, Train Loss: 1.0065\n",
      "2025-12-12 15:24:00,768 - INFO - Epoch 18/70, Train Loss: 0.9551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  26%|██▌       | 18/70 [00:01<00:04, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:00,857 - INFO - Epoch 19/70, Train Loss: 0.9345\n",
      "2025-12-12 15:24:00,947 - INFO - Epoch 20/70, Train Loss: 0.9275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  29%|██▊       | 20/70 [00:01<00:04, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:01,077 - INFO - Epoch 21/70, Train Loss: 0.9432\n",
      "2025-12-12 15:24:01,186 - INFO - Epoch 22/70, Train Loss: 0.9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  31%|███▏      | 22/70 [00:02<00:04, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:01,278 - INFO - Epoch 23/70, Train Loss: 0.9060\n",
      "2025-12-12 15:24:01,367 - INFO - Epoch 24/70, Train Loss: 0.9273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  34%|███▍      | 24/70 [00:02<00:04, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:01,453 - INFO - Epoch 25/70, Train Loss: 0.9291\n",
      "2025-12-12 15:24:01,539 - INFO - Epoch 26/70, Train Loss: 0.8931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  37%|███▋      | 26/70 [00:02<00:04, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:01,626 - INFO - Epoch 27/70, Train Loss: 0.9692\n",
      "2025-12-12 15:24:01,707 - INFO - Epoch 28/70, Train Loss: 0.8549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  40%|████      | 28/70 [00:02<00:03, 11.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:01,783 - INFO - Epoch 29/70, Train Loss: 0.9182\n",
      "2025-12-12 15:24:01,859 - INFO - Epoch 30/70, Train Loss: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  43%|████▎     | 30/70 [00:02<00:03, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:01,944 - INFO - Epoch 31/70, Train Loss: 0.8818\n",
      "2025-12-12 15:24:02,031 - INFO - Epoch 32/70, Train Loss: 0.8725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  46%|████▌     | 32/70 [00:02<00:03, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:02,120 - INFO - Epoch 33/70, Train Loss: 0.8487\n",
      "2025-12-12 15:24:02,208 - INFO - Epoch 34/70, Train Loss: 0.8857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  49%|████▊     | 34/70 [00:03<00:03, 11.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:02,289 - INFO - Epoch 35/70, Train Loss: 0.8434\n",
      "2025-12-12 15:24:02,374 - INFO - Epoch 36/70, Train Loss: 0.8281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  51%|█████▏    | 36/70 [00:03<00:02, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:02,457 - INFO - Epoch 37/70, Train Loss: 0.8240\n",
      "2025-12-12 15:24:02,545 - INFO - Epoch 38/70, Train Loss: 0.7674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  54%|█████▍    | 38/70 [00:03<00:02, 11.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:02,629 - INFO - Epoch 39/70, Train Loss: 0.8406\n",
      "2025-12-12 15:24:02,707 - INFO - Epoch 40/70, Train Loss: 0.7890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  57%|█████▋    | 40/70 [00:03<00:02, 11.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:02,787 - INFO - Epoch 41/70, Train Loss: 0.7575\n",
      "2025-12-12 15:24:02,870 - INFO - Epoch 42/70, Train Loss: 0.7330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  60%|██████    | 42/70 [00:03<00:02, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:02,952 - INFO - Epoch 43/70, Train Loss: 0.6783\n",
      "2025-12-12 15:24:03,043 - INFO - Epoch 44/70, Train Loss: 0.6900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  63%|██████▎   | 44/70 [00:03<00:02, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:03,130 - INFO - Epoch 45/70, Train Loss: 0.6385\n",
      "2025-12-12 15:24:03,213 - INFO - Epoch 46/70, Train Loss: 0.6851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  66%|██████▌   | 46/70 [00:04<00:02, 11.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:03,302 - INFO - Epoch 47/70, Train Loss: 0.6103\n",
      "2025-12-12 15:24:03,387 - INFO - Epoch 48/70, Train Loss: 0.6220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  69%|██████▊   | 48/70 [00:04<00:01, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:03,500 - INFO - Epoch 49/70, Train Loss: 0.6716\n",
      "2025-12-12 15:24:03,604 - INFO - Epoch 50/70, Train Loss: 0.5680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  71%|███████▏  | 50/70 [00:04<00:01, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:03,686 - INFO - Epoch 51/70, Train Loss: 0.5274\n",
      "2025-12-12 15:24:03,771 - INFO - Epoch 52/70, Train Loss: 0.5172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  74%|███████▍  | 52/70 [00:04<00:01, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:03,854 - INFO - Epoch 53/70, Train Loss: 0.5038\n",
      "2025-12-12 15:24:03,939 - INFO - Epoch 54/70, Train Loss: 0.4442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  77%|███████▋  | 54/70 [00:04<00:01, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:04,020 - INFO - Epoch 55/70, Train Loss: 0.5087\n",
      "2025-12-12 15:24:04,108 - INFO - Epoch 56/70, Train Loss: 0.4670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  80%|████████  | 56/70 [00:05<00:01, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:04,188 - INFO - Epoch 57/70, Train Loss: 0.5162\n",
      "2025-12-12 15:24:04,273 - INFO - Epoch 58/70, Train Loss: 0.4401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  83%|████████▎ | 58/70 [00:05<00:01, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:04,360 - INFO - Epoch 59/70, Train Loss: 0.4126\n",
      "2025-12-12 15:24:04,446 - INFO - Epoch 60/70, Train Loss: 0.3771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  86%|████████▌ | 60/70 [00:05<00:00, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:04,529 - INFO - Epoch 61/70, Train Loss: 0.4635\n",
      "2025-12-12 15:24:04,611 - INFO - Epoch 62/70, Train Loss: 0.7784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  89%|████████▊ | 62/70 [00:05<00:00, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:04,695 - INFO - Epoch 63/70, Train Loss: 0.4578\n",
      "2025-12-12 15:24:04,775 - INFO - Epoch 64/70, Train Loss: 0.4590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  91%|█████████▏| 64/70 [00:05<00:00, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:04,862 - INFO - Epoch 65/70, Train Loss: 0.4413\n",
      "2025-12-12 15:24:04,942 - INFO - Epoch 66/70, Train Loss: 0.3685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  94%|█████████▍| 66/70 [00:05<00:00, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:05,025 - INFO - Epoch 67/70, Train Loss: 0.3168\n",
      "2025-12-12 15:24:05,106 - INFO - Epoch 68/70, Train Loss: 0.2883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  97%|█████████▋| 68/70 [00:06<00:00, 12.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:05,186 - INFO - Epoch 69/70, Train Loss: 0.2646\n",
      "2025-12-12 15:24:05,269 - INFO - Epoch 70/70, Train Loss: 0.2874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 70/70 [00:06<00:00, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:05,272 - INFO - [1.0115926787257195, 0.9830499030649662, 0.9704258069396019, 0.9627848975360394, 0.9753327183425426, 1.0136880353093147, 0.9636528678238392, 0.9407158717513084, 0.9950308538973331, 1.056626982986927, 0.9978022091090679, 0.9706433191895485, 0.9490678235888481, 0.9876094870269299, 0.9679656252264977, 0.9548828601837158, 1.0064869113266468, 0.9551485665142536, 0.9344771504402161, 0.927479337900877, 0.9431587606668472, 0.9058591052889824, 0.9059640876948833, 0.927317850291729, 0.9290850628167391, 0.8930986188352108, 0.9691943116486073, 0.8548582680523396, 0.918174222111702, 0.8637864962220192, 0.8818483129143715, 0.8725329972803593, 0.8486837185919285, 0.8857207410037518, 0.8433896042406559, 0.8281376399099827, 0.8239557966589928, 0.7674390841275454, 0.8406185954809189, 0.7890063002705574, 0.7574590370059013, 0.7330352254211903, 0.6783143617212772, 0.6899918941780925, 0.6385442595928907, 0.6851181220263243, 0.6103464476764202, 0.6220027394592762, 0.6716229771263897, 0.5679977294057608, 0.5274316892027855, 0.5171731449663639, 0.5037669595330954, 0.444227991392836, 0.5087068444117904, 0.46700771152973175, 0.5162128768861294, 0.44011938525363803, 0.412552785128355, 0.3771202223142609, 0.46351735293865204, 0.7783727422356606, 0.4577815532684326, 0.4590437915176153, 0.44127101451158524, 0.3685447098687291, 0.3168077194131911, 0.28832991560921073, 0.26459664292633533, 0.2874370478093624]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train_loss</td><td>████▇▇▇▇▇▇▇▇▇█▆▇▇▇▇▆▆▆▆▅▅▅▄▃▃▃▃▃▂▂▂▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>70</td></tr><tr><td>train_loss</td><td>0.28744</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">confused-violet-3</strong> at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/e7o2f64b' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/e7o2f64b</a><br> View project at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251212_152356-e7o2f64b\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_wandb()\n",
    "train_model(net1, optimizer, loss_fn, enable_early_stopping=False)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68ccf6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [16, 3]                   --\n",
       "├─Conv2d: 1-1                            [16, 8, 112, 112]         80\n",
       "├─ReLU: 1-2                              [16, 8, 112, 112]         --\n",
       "├─Conv2d: 1-3                            [16, 16, 56, 56]          1,168\n",
       "├─ReLU: 1-4                              [16, 16, 56, 56]          --\n",
       "├─Conv2d: 1-5                            [16, 32, 28, 28]          4,640\n",
       "├─ReLU: 1-6                              [16, 32, 28, 28]          --\n",
       "├─Conv2d: 1-7                            [16, 64, 14, 14]          18,496\n",
       "├─ReLU: 1-8                              [16, 64, 14, 14]          --\n",
       "├─Conv2d: 1-9                            [16, 32, 7, 7]            18,464\n",
       "├─ReLU: 1-10                             [16, 32, 7, 7]            --\n",
       "├─AdaptiveAvgPool2d: 1-11                [16, 32, 1, 1]            --\n",
       "├─Flatten: 1-12                          [16, 32]                  --\n",
       "├─Linear: 1-13                           [16, 128]                 4,224\n",
       "├─ReLU: 1-14                             [16, 128]                 --\n",
       "├─Linear: 1-15                           [16, 64]                  8,256\n",
       "├─ReLU: 1-16                             [16, 64]                  --\n",
       "├─Linear: 1-17                           [16, 3]                   195\n",
       "==========================================================================================\n",
       "Total params: 55,523\n",
       "Trainable params: 55,523\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 205.55\n",
       "==========================================================================================\n",
       "Input size (MB): 3.21\n",
       "Forward/backward pass size (MB): 24.31\n",
       "Params size (MB): 0.22\n",
       "Estimated Total Size (MB): 27.74\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1),   # 224x224 -> 112x112   // (3x3x1)x8\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),  # 112x112 -> 56x56     // (3x3x8)x16\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # 56x56 -> 28x28      // (3x3x16)x32\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # 28x28 -> 14x14      // (3x3x32)x64\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(64, 32, kernel_size=3, stride=2, padding=1),  # 14x14 -> 7x7        // (3x3x64)x32\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.AdaptiveAvgPool2d(1),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(32, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 3)                       # Output layer     \n",
    ").to(device)\n",
    "\n",
    "net2.apply(init_weights)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(net0.parameters(), lr=0.1, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(net2.parameters(), lr=0.001)\n",
    "\n",
    "summary(net2, input_size=(batch_size, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6abe7d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Win 10\\Desktop\\BME\\DeepL\\BMEVITMMA18_Deep-Learning_AnkleAlign_D6AE9F\\notebook\\wandb\\run-20251212_152409-x4j9haiv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/x4j9haiv' target=\"_blank\">vague-dew-4</a></strong> to <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/x4j9haiv' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/x4j9haiv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:10,880 - INFO - Epoch 1/70, Train Loss: 1.0514\n",
      "2025-12-12 15:24:10,965 - INFO - Epoch 2/70, Train Loss: 0.9922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   3%|▎         | 2/70 [00:00<00:06, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:11,056 - INFO - Epoch 3/70, Train Loss: 1.0469\n",
      "2025-12-12 15:24:11,144 - INFO - Epoch 4/70, Train Loss: 0.9588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   6%|▌         | 4/70 [00:00<00:05, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:11,232 - INFO - Epoch 5/70, Train Loss: 1.0077\n",
      "2025-12-12 15:24:11,320 - INFO - Epoch 6/70, Train Loss: 1.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   9%|▊         | 6/70 [00:00<00:05, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:11,406 - INFO - Epoch 7/70, Train Loss: 1.0312\n",
      "2025-12-12 15:24:11,492 - INFO - Epoch 8/70, Train Loss: 0.9913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  11%|█▏        | 8/70 [00:00<00:05, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:11,579 - INFO - Epoch 9/70, Train Loss: 0.9605\n",
      "2025-12-12 15:24:11,665 - INFO - Epoch 10/70, Train Loss: 0.9726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  14%|█▍        | 10/70 [00:00<00:05, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:11,762 - INFO - Epoch 11/70, Train Loss: 0.9482\n",
      "2025-12-12 15:24:11,846 - INFO - Epoch 12/70, Train Loss: 0.9567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  17%|█▋        | 12/70 [00:01<00:05, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:11,938 - INFO - Epoch 13/70, Train Loss: 0.9147\n",
      "2025-12-12 15:24:12,030 - INFO - Epoch 14/70, Train Loss: 0.9193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  20%|██        | 14/70 [00:01<00:05, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:12,116 - INFO - Epoch 15/70, Train Loss: 1.0029\n",
      "2025-12-12 15:24:12,204 - INFO - Epoch 16/70, Train Loss: 0.9045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  23%|██▎       | 16/70 [00:01<00:04, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:12,292 - INFO - Epoch 17/70, Train Loss: 0.8962\n",
      "2025-12-12 15:24:12,379 - INFO - Epoch 18/70, Train Loss: 0.9419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  26%|██▌       | 18/70 [00:01<00:04, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:12,471 - INFO - Epoch 19/70, Train Loss: 0.8418\n",
      "2025-12-12 15:24:12,568 - INFO - Epoch 20/70, Train Loss: 0.7624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  29%|██▊       | 20/70 [00:01<00:04, 11.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:12,657 - INFO - Epoch 21/70, Train Loss: 0.8284\n",
      "2025-12-12 15:24:12,743 - INFO - Epoch 22/70, Train Loss: 0.6755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  31%|███▏      | 22/70 [00:01<00:04, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:12,836 - INFO - Epoch 23/70, Train Loss: 0.8268\n",
      "2025-12-12 15:24:12,926 - INFO - Epoch 24/70, Train Loss: 0.7386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  34%|███▍      | 24/70 [00:02<00:04, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:13,016 - INFO - Epoch 25/70, Train Loss: 0.6944\n",
      "2025-12-12 15:24:13,104 - INFO - Epoch 26/70, Train Loss: 0.6358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  37%|███▋      | 26/70 [00:02<00:03, 11.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:13,194 - INFO - Epoch 27/70, Train Loss: 0.5427\n",
      "2025-12-12 15:24:13,291 - INFO - Epoch 28/70, Train Loss: 0.5171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  40%|████      | 28/70 [00:02<00:03, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:13,381 - INFO - Epoch 29/70, Train Loss: 0.5087\n",
      "2025-12-12 15:24:13,472 - INFO - Epoch 30/70, Train Loss: 0.4189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  43%|████▎     | 30/70 [00:02<00:03, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:13,561 - INFO - Epoch 31/70, Train Loss: 0.3836\n",
      "2025-12-12 15:24:13,649 - INFO - Epoch 32/70, Train Loss: 0.4067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  46%|████▌     | 32/70 [00:02<00:03, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:13,751 - INFO - Epoch 33/70, Train Loss: 0.3383\n",
      "2025-12-12 15:24:13,869 - INFO - Epoch 34/70, Train Loss: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  49%|████▊     | 34/70 [00:03<00:03, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:13,964 - INFO - Epoch 35/70, Train Loss: 0.3604\n",
      "2025-12-12 15:24:14,050 - INFO - Epoch 36/70, Train Loss: 0.6133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  51%|█████▏    | 36/70 [00:03<00:03, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:14,131 - INFO - Epoch 37/70, Train Loss: 0.4498\n",
      "2025-12-12 15:24:14,222 - INFO - Epoch 38/70, Train Loss: 0.2944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  54%|█████▍    | 38/70 [00:03<00:02, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:14,307 - INFO - Epoch 39/70, Train Loss: 0.2915\n",
      "2025-12-12 15:24:14,389 - INFO - Epoch 40/70, Train Loss: 0.2667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  57%|█████▋    | 40/70 [00:03<00:02, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:14,479 - INFO - Epoch 41/70, Train Loss: 0.1859\n",
      "2025-12-12 15:24:14,562 - INFO - Epoch 42/70, Train Loss: 0.1883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  60%|██████    | 42/70 [00:03<00:02, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:14,647 - INFO - Epoch 43/70, Train Loss: 0.1460\n",
      "2025-12-12 15:24:14,733 - INFO - Epoch 44/70, Train Loss: 0.1506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  63%|██████▎   | 44/70 [00:03<00:02, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:14,822 - INFO - Epoch 45/70, Train Loss: 0.1368\n",
      "2025-12-12 15:24:14,909 - INFO - Epoch 46/70, Train Loss: 0.1121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  66%|██████▌   | 46/70 [00:04<00:02, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:14,999 - INFO - Epoch 47/70, Train Loss: 0.1211\n",
      "2025-12-12 15:24:15,092 - INFO - Epoch 48/70, Train Loss: 0.1289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  69%|██████▊   | 48/70 [00:04<00:01, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:15,183 - INFO - Epoch 49/70, Train Loss: 0.0985\n",
      "2025-12-12 15:24:15,266 - INFO - Epoch 50/70, Train Loss: 0.3266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  71%|███████▏  | 50/70 [00:04<00:01, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:15,372 - INFO - Epoch 51/70, Train Loss: 0.5259\n",
      "2025-12-12 15:24:15,485 - INFO - Epoch 52/70, Train Loss: 0.4664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  74%|███████▍  | 52/70 [00:04<00:01, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:15,585 - INFO - Epoch 53/70, Train Loss: 0.2746\n",
      "2025-12-12 15:24:15,681 - INFO - Epoch 54/70, Train Loss: 0.1897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  77%|███████▋  | 54/70 [00:04<00:01, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:15,770 - INFO - Epoch 55/70, Train Loss: 0.1398\n",
      "2025-12-12 15:24:15,855 - INFO - Epoch 56/70, Train Loss: 0.1278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  80%|████████  | 56/70 [00:05<00:01, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:15,944 - INFO - Epoch 57/70, Train Loss: 0.1510\n",
      "2025-12-12 15:24:16,030 - INFO - Epoch 58/70, Train Loss: 0.1148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  83%|████████▎ | 58/70 [00:05<00:01, 10.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:16,115 - INFO - Epoch 59/70, Train Loss: 0.0820\n",
      "2025-12-12 15:24:16,204 - INFO - Epoch 60/70, Train Loss: 0.0979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  86%|████████▌ | 60/70 [00:05<00:00, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:16,294 - INFO - Epoch 61/70, Train Loss: 0.2106\n",
      "2025-12-12 15:24:16,380 - INFO - Epoch 62/70, Train Loss: 0.2612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  89%|████████▊ | 62/70 [00:05<00:00, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:16,465 - INFO - Epoch 63/70, Train Loss: 0.1641\n",
      "2025-12-12 15:24:16,558 - INFO - Epoch 64/70, Train Loss: 0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  91%|█████████▏| 64/70 [00:05<00:00, 11.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:16,649 - INFO - Epoch 65/70, Train Loss: 0.0949\n",
      "2025-12-12 15:24:16,734 - INFO - Epoch 66/70, Train Loss: 0.0850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  94%|█████████▍| 66/70 [00:05<00:00, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:16,826 - INFO - Epoch 67/70, Train Loss: 0.0743\n",
      "2025-12-12 15:24:16,911 - INFO - Epoch 68/70, Train Loss: 0.0774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  97%|█████████▋| 68/70 [00:06<00:00, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:17,005 - INFO - Epoch 69/70, Train Loss: 0.0771\n",
      "2025-12-12 15:24:17,095 - INFO - Epoch 70/70, Train Loss: 0.0633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 70/70 [00:06<00:00, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 15:24:17,096 - INFO - [1.051427885890007, 0.9921970665454865, 1.0468668714165688, 0.958775706589222, 1.0076817981898785, 1.0076289884746075, 1.0311594568192959, 0.9913340248167515, 0.9604760892689228, 0.9726138636469841, 0.9481767825782299, 0.956697154790163, 0.9146808385848999, 0.9193496108055115, 1.002855259925127, 0.904484212398529, 0.8962045051157475, 0.9418727159500122, 0.8418341893702745, 0.7624243693426251, 0.8283914234489202, 0.675548393279314, 0.8267624471336603, 0.7385589703917503, 0.694431658834219, 0.6357737481594086, 0.5427270596846938, 0.5170914766786154, 0.5087445545941591, 0.4188974661519751, 0.38363224058412015, 0.4066608380526304, 0.3383357410784811, 0.312480756547302, 0.36042136745527387, 0.6133073754608631, 0.44981733383610845, 0.29436886589974165, 0.2915016404876951, 0.26665277825668454, 0.1858931153838057, 0.18833525478839874, 0.14599887577060144, 0.1506289696553722, 0.13675254295230843, 0.1120947960880585, 0.12109300503652776, 0.12890389945741276, 0.09847787511716888, 0.32656991691328585, 0.5259174592792988, 0.46641615498811007, 0.2746199143730337, 0.1896569710224867, 0.1397733600861102, 0.12780242261942476, 0.15099420549813658, 0.11475301531027071, 0.08204865484731272, 0.09791402040173125, 0.21064243966247886, 0.2612045935820788, 0.1640784441260621, 0.09383176459232345, 0.094934581185953, 0.08497850806452334, 0.07429792646212263, 0.0774443905102089, 0.07710789276461583, 0.063280589896749]\n",
      "2025-12-12 15:24:17,113 - INFO - network accuracy: 38.78%\n",
      "2025-12-12 15:24:17,114 - INFO - network precision: 82.65%\n",
      "2025-12-12 15:24:17,114 - INFO - network recall: 38.78%\n",
      "2025-12-12 15:24:17,115 - INFO - network F1 score: 46.31%\n",
      "2025-12-12 15:24:17,123 - INFO - Detailed Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.71      0.29         7\n",
      "           1       0.93      0.33      0.49        42\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.39        49\n",
      "   macro avg       0.37      0.35      0.26        49\n",
      "weighted avg       0.83      0.39      0.46        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>test_precision</td><td>▁</td></tr><tr><td>test_recall</td><td>▁</td></tr><tr><td>train_loss</td><td>██▇██▇▇▇▇█▇▇▅▅▄▃▃▃▃▅▃▃▂▂▁▁▁▁▄▂▂▁▁▁▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>70</td></tr><tr><td>test_accuracy</td><td>0.38776</td></tr><tr><td>test_f1</td><td>0.46307</td></tr><tr><td>test_precision</td><td>0.82646</td></tr><tr><td>test_recall</td><td>0.38776</td></tr><tr><td>train_loss</td><td>0.06328</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vague-dew-4</strong> at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/x4j9haiv' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/x4j9haiv</a><br> View project at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251212_152409-x4j9haiv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_wandb()\n",
    "train_model(net2, optimizer, loss_fn, enable_early_stopping=False)\n",
    "evaluate_model(net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5784b860",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.0001, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.best_model = None\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = model.state_dict().copy()\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                logger.info(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = model.state_dict().copy()\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8288f9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [32, 3]                   --\n",
       "├─Conv2d: 1-1                            [32, 8, 224, 224]         80\n",
       "├─ReLU: 1-2                              [32, 8, 224, 224]         --\n",
       "├─MaxPool2d: 1-3                         [32, 8, 112, 112]         --\n",
       "├─Conv2d: 1-4                            [32, 16, 112, 112]        1,168\n",
       "├─ReLU: 1-5                              [32, 16, 112, 112]        --\n",
       "├─MaxPool2d: 1-6                         [32, 16, 56, 56]          --\n",
       "├─Conv2d: 1-7                            [32, 32, 56, 56]          4,640\n",
       "├─ReLU: 1-8                              [32, 32, 56, 56]          --\n",
       "├─MaxPool2d: 1-9                         [32, 32, 28, 28]          --\n",
       "├─Conv2d: 1-10                           [32, 64, 28, 28]          18,496\n",
       "├─ReLU: 1-11                             [32, 64, 28, 28]          --\n",
       "├─MaxPool2d: 1-12                        [32, 64, 14, 14]          --\n",
       "├─Conv2d: 1-13                           [32, 32, 14, 14]          18,464\n",
       "├─ReLU: 1-14                             [32, 32, 14, 14]          --\n",
       "├─MaxPool2d: 1-15                        [32, 32, 7, 7]            --\n",
       "├─AdaptiveAvgPool2d: 1-16                [32, 32, 1, 1]            --\n",
       "├─Flatten: 1-17                          [32, 32]                  --\n",
       "├─Linear: 1-18                           [32, 128]                 4,224\n",
       "├─ReLU: 1-19                             [32, 128]                 --\n",
       "├─Linear: 1-20                           [32, 64]                  8,256\n",
       "├─ReLU: 1-21                             [32, 64]                  --\n",
       "├─Linear: 1-22                           [32, 3]                   195\n",
       "==========================================================================================\n",
       "Total params: 55,523\n",
       "Trainable params: 55,523\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.64\n",
       "==========================================================================================\n",
       "Input size (MB): 6.42\n",
       "Forward/backward pass size (MB): 194.33\n",
       "Params size (MB): 0.22\n",
       "Estimated Total Size (MB): 200.98\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "net3 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1),      # (3x3x1)x8\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 224x224 -> 112x112\n",
    "\n",
    "    torch.nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),       # (3x3x8)x16\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 112x112 -> 56x56\n",
    "\n",
    "    torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),       # (3x3x16)x32\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 56x56 -> 28x28 \n",
    "\n",
    "    torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),       # (3x3x32)x64\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 28x28 -> 14x14 \n",
    "\n",
    "    torch.nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),       # (3x3x64)x32\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 14x14 -> 7x7\n",
    "\n",
    "    torch.nn.AdaptiveAvgPool2d(1),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(32, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 3)                       # Output layer     \n",
    ").to(device)\n",
    "\n",
    "net3.apply(init_weights)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net3.parameters(), lr=0.001)\n",
    "\n",
    "summary(net3, input_size=(batch_size, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "13a0d7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Win 10\\Desktop\\BME\\DeepL\\BMEVITMMA18_Deep-Learning_AnkleAlign_D6AE9F\\notebook\\wandb\\run-20251212_181934-rzeniie8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/rzeniie8' target=\"_blank\">confused-water-46</a></strong> to <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/rzeniie8' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/rzeniie8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:35,240 - INFO - Epoch 1/70, Train Loss: 1.2371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   1%|▏         | 1/70 [00:00<00:22,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:35,293 - INFO - Epoch 2/70, Train Loss: 1.0437\n",
      "2025-12-12 18:19:35,348 - INFO - Epoch 3/70, Train Loss: 1.0236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   4%|▍         | 3/70 [00:00<00:08,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:35,406 - INFO - Epoch 4/70, Train Loss: 0.9934\n",
      "2025-12-12 18:19:35,468 - INFO - Epoch 5/70, Train Loss: 0.9830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   7%|▋         | 5/70 [00:00<00:05, 10.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:35,534 - INFO - Epoch 6/70, Train Loss: 0.9624\n",
      "2025-12-12 18:19:35,592 - INFO - Epoch 7/70, Train Loss: 0.9606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  10%|█         | 7/70 [00:00<00:04, 12.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:35,649 - INFO - Epoch 8/70, Train Loss: 0.9642\n",
      "2025-12-12 18:19:35,703 - INFO - Epoch 9/70, Train Loss: 0.9533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  13%|█▎        | 9/70 [00:00<00:04, 14.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:35,756 - INFO - Epoch 10/70, Train Loss: 0.9462\n",
      "2025-12-12 18:19:35,806 - INFO - Epoch 11/70, Train Loss: 0.9395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  16%|█▌        | 11/70 [00:00<00:03, 15.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:35,860 - INFO - Epoch 12/70, Train Loss: 0.9669\n",
      "2025-12-12 18:19:35,912 - INFO - Epoch 13/70, Train Loss: 0.9383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  19%|█▊        | 13/70 [00:00<00:03, 16.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:35,963 - INFO - Epoch 14/70, Train Loss: 0.9247\n",
      "2025-12-12 18:19:36,029 - INFO - Epoch 15/70, Train Loss: 0.9538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  21%|██▏       | 15/70 [00:01<00:03, 16.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:36,090 - INFO - Epoch 16/70, Train Loss: 0.9217\n",
      "2025-12-12 18:19:36,167 - INFO - Epoch 17/70, Train Loss: 0.9180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  24%|██▍       | 17/70 [00:01<00:03, 16.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:36,236 - INFO - Epoch 18/70, Train Loss: 0.9242\n",
      "2025-12-12 18:19:36,298 - INFO - Epoch 19/70, Train Loss: 0.9216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  27%|██▋       | 19/70 [00:01<00:03, 15.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:36,347 - INFO - Epoch 20/70, Train Loss: 0.9110\n",
      "2025-12-12 18:19:36,397 - INFO - Epoch 21/70, Train Loss: 0.8896\n",
      "2025-12-12 18:19:36,447 - INFO - Epoch 22/70, Train Loss: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  31%|███▏      | 22/70 [00:01<00:02, 17.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:36,500 - INFO - Epoch 23/70, Train Loss: 0.8655\n",
      "2025-12-12 18:19:36,556 - INFO - Epoch 24/70, Train Loss: 0.8688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  34%|███▍      | 24/70 [00:01<00:02, 17.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:36,614 - INFO - Epoch 25/70, Train Loss: 0.9046\n",
      "2025-12-12 18:19:36,670 - INFO - Epoch 26/70, Train Loss: 0.8285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  37%|███▋      | 26/70 [00:01<00:02, 17.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:36,721 - INFO - Epoch 27/70, Train Loss: 0.8221\n",
      "2025-12-12 18:19:36,769 - INFO - Epoch 28/70, Train Loss: 0.8649\n",
      "2025-12-12 18:19:36,820 - INFO - Epoch 29/70, Train Loss: 0.8766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  41%|████▏     | 29/70 [00:01<00:02, 18.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:36,872 - INFO - Epoch 30/70, Train Loss: 0.8146\n",
      "2025-12-12 18:19:36,920 - INFO - Epoch 31/70, Train Loss: 0.8074\n",
      "2025-12-12 18:19:36,969 - INFO - Epoch 32/70, Train Loss: 0.7792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  46%|████▌     | 32/70 [00:02<00:02, 18.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:37,017 - INFO - Epoch 33/70, Train Loss: 0.7222\n",
      "2025-12-12 18:19:37,066 - INFO - Epoch 34/70, Train Loss: 0.7146\n",
      "2025-12-12 18:19:37,117 - INFO - Epoch 35/70, Train Loss: 0.6946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  50%|█████     | 35/70 [00:02<00:01, 19.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:37,168 - INFO - Epoch 36/70, Train Loss: 0.6792\n",
      "2025-12-12 18:19:37,217 - INFO - Epoch 37/70, Train Loss: 0.6535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  53%|█████▎    | 37/70 [00:02<00:01, 19.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:37,269 - INFO - Epoch 38/70, Train Loss: 0.7875\n",
      "2025-12-12 18:19:37,319 - INFO - Epoch 39/70, Train Loss: 0.8244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  56%|█████▌    | 39/70 [00:02<00:01, 19.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:37,368 - INFO - Epoch 40/70, Train Loss: 0.7356\n",
      "2025-12-12 18:19:37,419 - INFO - Epoch 41/70, Train Loss: 0.7206\n",
      "2025-12-12 18:19:37,467 - INFO - Epoch 42/70, Train Loss: 0.6663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  60%|██████    | 42/70 [00:02<00:01, 19.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:37,517 - INFO - Epoch 43/70, Train Loss: 0.6079\n",
      "2025-12-12 18:19:37,567 - INFO - Epoch 44/70, Train Loss: 0.5859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  63%|██████▎   | 44/70 [00:02<00:01, 19.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:37,617 - INFO - Epoch 45/70, Train Loss: 0.5472\n",
      "2025-12-12 18:19:37,666 - INFO - Epoch 46/70, Train Loss: 0.5453\n",
      "2025-12-12 18:19:37,715 - INFO - Epoch 47/70, Train Loss: 0.5276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  67%|██████▋   | 47/70 [00:02<00:01, 20.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:37,764 - INFO - Epoch 48/70, Train Loss: 0.5463\n",
      "2025-12-12 18:19:37,813 - INFO - Epoch 49/70, Train Loss: 0.4928\n",
      "2025-12-12 18:19:37,862 - INFO - Epoch 50/70, Train Loss: 0.4680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  71%|███████▏  | 50/70 [00:02<00:00, 20.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:37,914 - INFO - Epoch 51/70, Train Loss: 0.4946\n",
      "2025-12-12 18:19:37,963 - INFO - Epoch 52/70, Train Loss: 0.4655\n",
      "2025-12-12 18:19:38,013 - INFO - Epoch 53/70, Train Loss: 0.4537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  76%|███████▌  | 53/70 [00:03<00:00, 20.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:38,062 - INFO - Epoch 54/70, Train Loss: 0.4340\n",
      "2025-12-12 18:19:38,110 - INFO - Epoch 55/70, Train Loss: 0.4009\n",
      "2025-12-12 18:19:38,160 - INFO - Epoch 56/70, Train Loss: 0.4699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  80%|████████  | 56/70 [00:03<00:00, 20.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:38,210 - INFO - Epoch 57/70, Train Loss: 0.4040\n",
      "2025-12-12 18:19:38,257 - INFO - Epoch 58/70, Train Loss: 0.3753\n",
      "2025-12-12 18:19:38,306 - INFO - Epoch 59/70, Train Loss: 0.3521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  84%|████████▍ | 59/70 [00:03<00:00, 20.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:38,357 - INFO - Epoch 60/70, Train Loss: 0.4844\n",
      "2025-12-12 18:19:38,407 - INFO - Epoch 61/70, Train Loss: 0.5056\n",
      "2025-12-12 18:19:38,457 - INFO - Epoch 62/70, Train Loss: 0.4904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  89%|████████▊ | 62/70 [00:03<00:00, 20.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:38,507 - INFO - Epoch 63/70, Train Loss: 0.4131\n",
      "2025-12-12 18:19:38,557 - INFO - Epoch 64/70, Train Loss: 0.3676\n",
      "2025-12-12 18:19:38,607 - INFO - Epoch 65/70, Train Loss: 0.3849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  93%|█████████▎| 65/70 [00:03<00:00, 20.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:38,659 - INFO - Epoch 66/70, Train Loss: 0.3024\n",
      "2025-12-12 18:19:38,707 - INFO - Epoch 67/70, Train Loss: 0.3228\n",
      "2025-12-12 18:19:38,755 - INFO - Epoch 68/70, Train Loss: 0.3359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  97%|█████████▋| 68/70 [00:03<00:00, 20.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:38,806 - INFO - Epoch 69/70, Train Loss: 0.2487\n",
      "2025-12-12 18:19:38,863 - INFO - Epoch 70/70, Train Loss: 0.3159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 70/70 [00:03<00:00, 17.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:19:38,865 - INFO - [1.237086534500122, 1.0436917394399643, 1.0235626995563507, 0.9933677166700363, 0.9830075800418854, 0.9623955935239792, 0.9606431424617767, 0.9642038643360138, 0.9533436596393585, 0.946183055639267, 0.9394595623016357, 0.9669439196586609, 0.9382504522800446, 0.924747109413147, 0.9537858366966248, 0.9217498153448105, 0.9179900139570236, 0.9241834878921509, 0.9216127246618271, 0.9109524041414261, 0.8895670920610428, 0.8999549299478531, 0.8654675483703613, 0.8687680959701538, 0.9046307355165482, 0.8285076171159744, 0.8220992237329483, 0.8649306893348694, 0.8766479790210724, 0.8145528137683868, 0.8074246942996979, 0.7791862934827805, 0.722162663936615, 0.7145782709121704, 0.6946388632059097, 0.6792204082012177, 0.6534572243690491, 0.7875205725431442, 0.8243864625692368, 0.7356019616127014, 0.7205611914396286, 0.666285365819931, 0.6078769341111183, 0.5859226733446121, 0.5472287386655807, 0.5453073084354401, 0.527581550180912, 0.546343170106411, 0.49275290966033936, 0.4680470824241638, 0.4945518597960472, 0.46546386927366257, 0.4536589905619621, 0.4339843839406967, 0.4008968397974968, 0.46990082412958145, 0.4040455222129822, 0.37528080865740776, 0.35208554565906525, 0.48444680124521255, 0.5055892318487167, 0.49040957540273666, 0.4130803048610687, 0.3675960376858711, 0.38489601016044617, 0.3023696392774582, 0.3227691948413849, 0.33589814603328705, 0.24872523173689842, 0.3158691078424454]\n",
      "2025-12-12 18:19:38,900 - INFO - network accuracy: 18.37%\n",
      "2025-12-12 18:19:38,901 - INFO - network precision: 87.76%\n",
      "2025-12-12 18:19:38,902 - INFO - network recall: 18.37%\n",
      "2025-12-12 18:19:38,902 - INFO - network F1 score: 21.50%\n",
      "2025-12-12 18:19:38,916 - INFO - Detailed Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.57      0.23         7\n",
      "           1       1.00      0.12      0.21        42\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.18        49\n",
      "   macro avg       0.38      0.23      0.15        49\n",
      "weighted avg       0.88      0.18      0.22        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>test_precision</td><td>▁</td></tr><tr><td>test_recall</td><td>▁</td></tr><tr><td>train_loss</td><td>█▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▅▅▄▃▃▃▃▂▂▂▂▁▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>70</td></tr><tr><td>test_accuracy</td><td>0.18367</td></tr><tr><td>test_f1</td><td>0.21502</td></tr><tr><td>test_precision</td><td>0.87755</td></tr><tr><td>test_recall</td><td>0.18367</td></tr><tr><td>train_loss</td><td>0.31587</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">confused-water-46</strong> at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/rzeniie8' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/rzeniie8</a><br> View project at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251212_181934-rzeniie8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_wandb()\n",
    "train_model(net3, optimizer, loss_fn, enable_early_stopping=False)\n",
    "evaluate_model(net3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6a7a8852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train test split, for getting validation metrics during training\n",
    "x_train_tensor, x_val_tensor, y_train_tensor, y_val_tensor = train_test_split(\n",
    "    x_train_tensor, y_train_tensor, test_size=0.2, random_state=42, stratify=y_train_tensor)\n",
    "\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ceea8786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [32, 3]                   --\n",
       "├─Conv2d: 1-1                            [32, 8, 224, 224]         80\n",
       "├─BatchNorm2d: 1-2                       [32, 8, 224, 224]         16\n",
       "├─ReLU: 1-3                              [32, 8, 224, 224]         --\n",
       "├─MaxPool2d: 1-4                         [32, 8, 112, 112]         --\n",
       "├─Conv2d: 1-5                            [32, 16, 112, 112]        1,168\n",
       "├─BatchNorm2d: 1-6                       [32, 16, 112, 112]        32\n",
       "├─ReLU: 1-7                              [32, 16, 112, 112]        --\n",
       "├─MaxPool2d: 1-8                         [32, 16, 56, 56]          --\n",
       "├─Conv2d: 1-9                            [32, 32, 56, 56]          4,640\n",
       "├─BatchNorm2d: 1-10                      [32, 32, 56, 56]          64\n",
       "├─ReLU: 1-11                             [32, 32, 56, 56]          --\n",
       "├─MaxPool2d: 1-12                        [32, 32, 28, 28]          --\n",
       "├─Conv2d: 1-13                           [32, 64, 28, 28]          18,496\n",
       "├─BatchNorm2d: 1-14                      [32, 64, 28, 28]          128\n",
       "├─ReLU: 1-15                             [32, 64, 28, 28]          --\n",
       "├─MaxPool2d: 1-16                        [32, 64, 14, 14]          --\n",
       "├─Conv2d: 1-17                           [32, 32, 14, 14]          18,464\n",
       "├─BatchNorm2d: 1-18                      [32, 32, 14, 14]          64\n",
       "├─ReLU: 1-19                             [32, 32, 14, 14]          --\n",
       "├─MaxPool2d: 1-20                        [32, 32, 7, 7]            --\n",
       "├─AdaptiveAvgPool2d: 1-21                [32, 32, 1, 1]            --\n",
       "├─Flatten: 1-22                          [32, 32]                  --\n",
       "├─Linear: 1-23                           [32, 128]                 4,224\n",
       "├─ReLU: 1-24                             [32, 128]                 --\n",
       "├─Linear: 1-25                           [32, 64]                  8,256\n",
       "├─ReLU: 1-26                             [32, 64]                  --\n",
       "├─Linear: 1-27                           [32, 3]                   195\n",
       "==========================================================================================\n",
       "Total params: 55,827\n",
       "Trainable params: 55,827\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.64\n",
       "==========================================================================================\n",
       "Input size (MB): 6.42\n",
       "Forward/backward pass size (MB): 388.61\n",
       "Params size (MB): 0.22\n",
       "Estimated Total Size (MB): 395.26\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net4 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1),      # (3x3x1)x8\n",
    "    torch.nn.BatchNorm2d(8),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 224x224 -> 112x112\n",
    "\n",
    "    torch.nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),       # (3x3x8)x16\n",
    "    torch.nn.BatchNorm2d(16),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 112x112 -> 56x56\n",
    "\n",
    "    torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),       # (3x3x16)x32\n",
    "    torch.nn.BatchNorm2d(32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 56x56 -> 28x28 \n",
    "\n",
    "    torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),       # (3x3x32)x64\n",
    "    torch.nn.BatchNorm2d(64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 28x28 -> 14x14 \n",
    "\n",
    "    torch.nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),       # (3x3x64)x32\n",
    "    torch.nn.BatchNorm2d(32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),    # 14x14 -> 7x7\n",
    "\n",
    "    torch.nn.AdaptiveAvgPool2d(1),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(32, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 3)                       # Output layer     \n",
    ").to(device)\n",
    "\n",
    "net4.apply(init_weights)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net4.parameters(), lr=0.001)\n",
    "\n",
    "summary(net4, input_size=(batch_size, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2d66c699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Win 10\\Desktop\\BME\\DeepL\\BMEVITMMA18_Deep-Learning_AnkleAlign_D6AE9F\\notebook\\wandb\\run-20251212_183112-edq48qnd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/edq48qnd' target=\"_blank\">leafy-pond-52</a></strong> to <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/edq48qnd' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/edq48qnd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:31:13,643 - INFO - Epoch 1/70, Train Loss: 1.0647, Val Loss: 1.0436, Val Acc: 0.3871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   1%|▏         | 1/70 [00:00<00:21,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:31:13,735 - INFO - Epoch 2/70, Train Loss: 0.9453, Val Loss: 1.0350, Val Acc: 0.4839\n",
      "2025-12-12 18:31:13,846 - INFO - Epoch 3/70, Train Loss: 0.8866, Val Loss: 1.0337, Val Acc: 0.5161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   4%|▍         | 3/70 [00:00<00:10,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:31:13,951 - INFO - Epoch 4/70, Train Loss: 0.8378, Val Loss: 1.0360, Val Acc: 0.4516\n",
      "2025-12-12 18:31:13,952 - INFO - EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   6%|▌         | 4/70 [00:00<00:09,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:31:14,047 - INFO - Epoch 5/70, Train Loss: 0.8040, Val Loss: 1.0350, Val Acc: 0.4839\n",
      "2025-12-12 18:31:14,047 - INFO - EarlyStopping counter: 2 out of 5\n",
      "2025-12-12 18:31:14,137 - INFO - Epoch 6/70, Train Loss: 0.7524, Val Loss: 1.0361, Val Acc: 0.4839\n",
      "2025-12-12 18:31:14,138 - INFO - EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   9%|▊         | 6/70 [00:00<00:07,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:31:14,238 - INFO - Epoch 7/70, Train Loss: 0.7224, Val Loss: 1.0175, Val Acc: 0.4839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  10%|█         | 7/70 [00:00<00:07,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:31:14,327 - INFO - Epoch 8/70, Train Loss: 0.6972, Val Loss: 0.9962, Val Acc: 0.4839\n",
      "2025-12-12 18:31:14,413 - INFO - Epoch 9/70, Train Loss: 0.6614, Val Loss: 1.0571, Val Acc: 0.4516\n",
      "2025-12-12 18:31:14,414 - INFO - EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  13%|█▎        | 9/70 [00:01<00:06,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:31:14,498 - INFO - Epoch 10/70, Train Loss: 0.6113, Val Loss: 1.0052, Val Acc: 0.4839\n",
      "2025-12-12 18:31:14,499 - INFO - EarlyStopping counter: 2 out of 5\n",
      "2025-12-12 18:31:14,588 - INFO - Epoch 11/70, Train Loss: 0.5897, Val Loss: 1.0285, Val Acc: 0.4194\n",
      "2025-12-12 18:31:14,590 - INFO - EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  16%|█▌        | 11/70 [00:01<00:05, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:31:14,671 - INFO - Epoch 12/70, Train Loss: 0.5019, Val Loss: 1.0451, Val Acc: 0.5161\n",
      "2025-12-12 18:31:14,673 - INFO - EarlyStopping counter: 4 out of 5\n",
      "2025-12-12 18:31:14,751 - INFO - Epoch 13/70, Train Loss: 0.5277, Val Loss: 0.9351, Val Acc: 0.4839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  19%|█▊        | 13/70 [00:01<00:05, 11.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:31:14,829 - INFO - Epoch 14/70, Train Loss: 0.4907, Val Loss: 0.8818, Val Acc: 0.5161\n",
      "2025-12-12 18:31:14,903 - INFO - Epoch 15/70, Train Loss: 0.4176, Val Loss: 1.6310, Val Acc: 0.5161\n",
      "2025-12-12 18:31:14,904 - INFO - EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  21%|██▏       | 15/70 [00:01<00:04, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:31:14,983 - INFO - Epoch 16/70, Train Loss: 0.4139, Val Loss: 0.8027, Val Acc: 0.6452\n",
      "2025-12-12 18:31:15,062 - INFO - Epoch 17/70, Train Loss: 0.3917, Val Loss: 0.7938, Val Acc: 0.7097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  24%|██▍       | 17/70 [00:01<00:04, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:31:15,140 - INFO - Epoch 18/70, Train Loss: 0.3706, Val Loss: 1.0430, Val Acc: 0.6129\n",
      "2025-12-12 18:31:15,140 - INFO - EarlyStopping counter: 1 out of 5\n",
      "2025-12-12 18:31:15,218 - INFO - Epoch 19/70, Train Loss: 0.3978, Val Loss: 0.9023, Val Acc: 0.6774\n",
      "2025-12-12 18:31:15,219 - INFO - EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  27%|██▋       | 19/70 [00:01<00:04, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:31:15,302 - INFO - Epoch 20/70, Train Loss: 0.3191, Val Loss: 0.8841, Val Acc: 0.6129\n",
      "2025-12-12 18:31:15,302 - INFO - EarlyStopping counter: 3 out of 5\n",
      "2025-12-12 18:31:15,390 - INFO - Epoch 21/70, Train Loss: 0.2883, Val Loss: 0.9186, Val Acc: 0.5484\n",
      "2025-12-12 18:31:15,390 - INFO - EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  30%|███       | 21/70 [00:02<00:04, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:31:15,479 - INFO - Epoch 22/70, Train Loss: 0.2851, Val Loss: 0.9483, Val Acc: 0.5806\n",
      "2025-12-12 18:31:15,479 - INFO - EarlyStopping counter: 5 out of 5\n",
      "2025-12-12 18:31:15,479 - INFO - Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  30%|███       | 21/70 [00:02<00:05,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:31:15,485 - INFO - Loaded best model weights\n",
      "2025-12-12 18:31:15,486 - INFO - [1.0646775662899017, 0.9453068822622299, 0.8866231143474579, 0.8378106951713562, 0.803951233625412, 0.752399668097496, 0.7224159240722656, 0.6971715837717056, 0.6613590568304062, 0.6113146841526031, 0.5896765887737274, 0.5019043385982513, 0.5276547595858574, 0.4907457157969475, 0.41763219982385635, 0.41385509073734283, 0.3916967660188675, 0.3706493079662323, 0.39776717126369476, 0.3191038444638252, 0.2882870212197304, 0.2850576862692833]\n",
      "2025-12-12 18:31:15,515 - INFO - network accuracy: 38.78%\n",
      "2025-12-12 18:31:15,516 - INFO - network precision: 88.57%\n",
      "2025-12-12 18:31:15,516 - INFO - network recall: 38.78%\n",
      "2025-12-12 18:31:15,517 - INFO - network F1 score: 42.86%\n",
      "2025-12-12 18:31:15,527 - INFO - Detailed Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      1.00      0.33         7\n",
      "           1       1.00      0.29      0.44        42\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.39        49\n",
      "   macro avg       0.40      0.43      0.26        49\n",
      "weighted avg       0.89      0.39      0.43        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>test_precision</td><td>▁</td></tr><tr><td>test_recall</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▄▂▃▃▃▃▂▃▂▄▃▄▄▇█▆▇▆▅▅</td></tr><tr><td>val_loss</td><td>▃▃▃▃▃▃▃▃▃▃▃▃▂▂█▁▁▃▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>22</td></tr><tr><td>test_accuracy</td><td>0.38776</td></tr><tr><td>test_f1</td><td>0.42857</td></tr><tr><td>test_precision</td><td>0.88571</td></tr><tr><td>test_recall</td><td>0.38776</td></tr><tr><td>train_loss</td><td>0.28506</td></tr><tr><td>val_accuracy</td><td>0.58065</td></tr><tr><td>val_loss</td><td>0.9483</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">leafy-pond-52</strong> at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/edq48qnd' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/edq48qnd</a><br> View project at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251212_183112-edq48qnd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_wandb()\n",
    "train_model(net4, optimizer, loss_fn, enable_early_stopping=True, patience=5)\n",
    "evaluate_model(net4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "01a9ced2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [32, 3]                   --\n",
       "├─Conv2d: 1-1                            [32, 8, 224, 224]         80\n",
       "├─BatchNorm2d: 1-2                       [32, 8, 224, 224]         16\n",
       "├─ReLU: 1-3                              [32, 8, 224, 224]         --\n",
       "├─MaxPool2d: 1-4                         [32, 8, 112, 112]         --\n",
       "├─Conv2d: 1-5                            [32, 16, 112, 112]        1,168\n",
       "├─BatchNorm2d: 1-6                       [32, 16, 112, 112]        32\n",
       "├─ReLU: 1-7                              [32, 16, 112, 112]        --\n",
       "├─MaxPool2d: 1-8                         [32, 16, 56, 56]          --\n",
       "├─Conv2d: 1-9                            [32, 32, 56, 56]          4,640\n",
       "├─BatchNorm2d: 1-10                      [32, 32, 56, 56]          64\n",
       "├─ReLU: 1-11                             [32, 32, 56, 56]          --\n",
       "├─MaxPool2d: 1-12                        [32, 32, 28, 28]          --\n",
       "├─Conv2d: 1-13                           [32, 64, 28, 28]          18,496\n",
       "├─BatchNorm2d: 1-14                      [32, 64, 28, 28]          128\n",
       "├─ReLU: 1-15                             [32, 64, 28, 28]          --\n",
       "├─MaxPool2d: 1-16                        [32, 64, 14, 14]          --\n",
       "├─AdaptiveAvgPool2d: 1-17                [32, 64, 1, 1]            --\n",
       "├─Flatten: 1-18                          [32, 64]                  --\n",
       "├─Linear: 1-19                           [32, 128]                 8,320\n",
       "├─ReLU: 1-20                             [32, 128]                 --\n",
       "├─Linear: 1-21                           [32, 128]                 16,512\n",
       "├─ReLU: 1-22                             [32, 128]                 --\n",
       "├─Linear: 1-23                           [32, 3]                   387\n",
       "==========================================================================================\n",
       "Total params: 49,843\n",
       "Trainable params: 49,843\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.53\n",
       "==========================================================================================\n",
       "Input size (MB): 6.42\n",
       "Forward/backward pass size (MB): 385.42\n",
       "Params size (MB): 0.20\n",
       "Estimated Total Size (MB): 392.04\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net5 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1),      #(3x3x1)x16\n",
    "    torch.nn.BatchNorm2d(8),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2), # 224x224 -> 112x112\n",
    "\n",
    "    torch.nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),       #(3x3x16)x32\n",
    "    torch.nn.BatchNorm2d(16),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2), # 112x112 -> 56x56\n",
    "\n",
    "    torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),        #(3x3x32)x64\n",
    "    torch.nn.BatchNorm2d(32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2), # 56x56 -> 28x28\n",
    "    \n",
    "    torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),       #(3x3x64)x128\n",
    "    torch.nn.BatchNorm2d(64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2), # 28x28 -> 14x14 \n",
    "\n",
    "    torch.nn.AdaptiveAvgPool2d(1),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(64, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 3)                       # Output layer     \n",
    ").to(device)\n",
    "\n",
    "net5.apply(init_weights)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net5.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "summary(net5, input_size=(batch_size, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef30817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Win 10\\Desktop\\BME\\DeepL\\BMEVITMMA18_Deep-Learning_AnkleAlign_D6AE9F\\notebook\\wandb\\run-20251212_183209-d6y1y1lb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/d6y1y1lb' target=\"_blank\">breezy-fire-53</a></strong> to <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/d6y1y1lb' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/d6y1y1lb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:10,216 - INFO - Epoch 1/70, Train Loss: 1.1514, Val Loss: 1.0290, Val Acc: 0.4839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   1%|▏         | 1/70 [00:00<00:21,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:10,296 - INFO - Epoch 2/70, Train Loss: 0.9883, Val Loss: 1.0154, Val Acc: 0.3871\n",
      "2025-12-12 18:32:10,376 - INFO - Epoch 3/70, Train Loss: 0.9204, Val Loss: 1.0194, Val Acc: 0.4194\n",
      "2025-12-12 18:32:10,377 - INFO - EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   4%|▍         | 3/70 [00:00<00:09,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:10,457 - INFO - Epoch 4/70, Train Loss: 0.9009, Val Loss: 1.0026, Val Acc: 0.4839\n",
      "2025-12-12 18:32:10,535 - INFO - Epoch 5/70, Train Loss: 0.8774, Val Loss: 0.9977, Val Acc: 0.4839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   7%|▋         | 5/70 [00:00<00:07,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:10,611 - INFO - Epoch 6/70, Train Loss: 0.8885, Val Loss: 1.0023, Val Acc: 0.4194\n",
      "2025-12-12 18:32:10,612 - INFO - EarlyStopping counter: 1 out of 10\n",
      "2025-12-12 18:32:10,766 - INFO - Epoch 7/70, Train Loss: 0.8523, Val Loss: 0.9986, Val Acc: 0.3871\n",
      "2025-12-12 18:32:10,767 - INFO - EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  10%|█         | 7/70 [00:00<00:07,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:10,849 - INFO - Epoch 8/70, Train Loss: 0.8398, Val Loss: 0.9822, Val Acc: 0.5484\n",
      "2025-12-12 18:32:10,922 - INFO - Epoch 9/70, Train Loss: 0.8182, Val Loss: 0.9680, Val Acc: 0.5161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  13%|█▎        | 9/70 [00:01<00:06, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:10,997 - INFO - Epoch 10/70, Train Loss: 0.8029, Val Loss: 0.9614, Val Acc: 0.5161\n",
      "2025-12-12 18:32:11,074 - INFO - Epoch 11/70, Train Loss: 0.7732, Val Loss: 0.9278, Val Acc: 0.5161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  16%|█▌        | 11/70 [00:01<00:05, 10.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:11,153 - INFO - Epoch 12/70, Train Loss: 0.7683, Val Loss: 0.9107, Val Acc: 0.5161\n",
      "2025-12-12 18:32:11,232 - INFO - Epoch 13/70, Train Loss: 0.7719, Val Loss: 0.9299, Val Acc: 0.5806\n",
      "2025-12-12 18:32:11,232 - INFO - EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  19%|█▊        | 13/70 [00:01<00:04, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:11,311 - INFO - Epoch 14/70, Train Loss: 0.7248, Val Loss: 0.8936, Val Acc: 0.4839\n",
      "2025-12-12 18:32:11,386 - INFO - Epoch 15/70, Train Loss: 0.7287, Val Loss: 0.8860, Val Acc: 0.5484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  21%|██▏       | 15/70 [00:01<00:04, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:11,469 - INFO - Epoch 16/70, Train Loss: 0.7593, Val Loss: 0.8808, Val Acc: 0.5484\n",
      "2025-12-12 18:32:11,555 - INFO - Epoch 17/70, Train Loss: 0.7067, Val Loss: 0.9955, Val Acc: 0.5161\n",
      "2025-12-12 18:32:11,556 - INFO - EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  24%|██▍       | 17/70 [00:01<00:04, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:11,633 - INFO - Epoch 18/70, Train Loss: 0.6597, Val Loss: 0.8852, Val Acc: 0.5484\n",
      "2025-12-12 18:32:11,634 - INFO - EarlyStopping counter: 2 out of 10\n",
      "2025-12-12 18:32:11,711 - INFO - Epoch 19/70, Train Loss: 0.6633, Val Loss: 0.9231, Val Acc: 0.6452\n",
      "2025-12-12 18:32:11,712 - INFO - EarlyStopping counter: 3 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  27%|██▋       | 19/70 [00:01<00:04, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:11,789 - INFO - Epoch 20/70, Train Loss: 0.6473, Val Loss: 0.9171, Val Acc: 0.5484\n",
      "2025-12-12 18:32:11,790 - INFO - EarlyStopping counter: 4 out of 10\n",
      "2025-12-12 18:32:11,866 - INFO - Epoch 21/70, Train Loss: 0.6215, Val Loss: 0.9580, Val Acc: 0.5806\n",
      "2025-12-12 18:32:11,866 - INFO - EarlyStopping counter: 5 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  30%|███       | 21/70 [00:01<00:03, 12.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:11,940 - INFO - Epoch 22/70, Train Loss: 0.5964, Val Loss: 0.8933, Val Acc: 0.5806\n",
      "2025-12-12 18:32:11,940 - INFO - EarlyStopping counter: 6 out of 10\n",
      "2025-12-12 18:32:12,014 - INFO - Epoch 23/70, Train Loss: 0.5845, Val Loss: 0.8684, Val Acc: 0.4839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  33%|███▎      | 23/70 [00:02<00:03, 12.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:12,090 - INFO - Epoch 24/70, Train Loss: 0.5648, Val Loss: 0.8610, Val Acc: 0.5161\n",
      "2025-12-12 18:32:12,162 - INFO - Epoch 25/70, Train Loss: 0.5484, Val Loss: 0.8802, Val Acc: 0.5806\n",
      "2025-12-12 18:32:12,163 - INFO - EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  36%|███▌      | 25/70 [00:02<00:03, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:12,237 - INFO - Epoch 26/70, Train Loss: 0.5414, Val Loss: 0.8898, Val Acc: 0.5806\n",
      "2025-12-12 18:32:12,237 - INFO - EarlyStopping counter: 2 out of 10\n",
      "2025-12-12 18:32:12,311 - INFO - Epoch 27/70, Train Loss: 0.5144, Val Loss: 0.8478, Val Acc: 0.5806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  39%|███▊      | 27/70 [00:02<00:03, 13.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:12,384 - INFO - Epoch 28/70, Train Loss: 0.4909, Val Loss: 0.8658, Val Acc: 0.5161\n",
      "2025-12-12 18:32:12,384 - INFO - EarlyStopping counter: 1 out of 10\n",
      "2025-12-12 18:32:12,458 - INFO - Epoch 29/70, Train Loss: 0.5345, Val Loss: 0.9405, Val Acc: 0.5806\n",
      "2025-12-12 18:32:12,459 - INFO - EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  41%|████▏     | 29/70 [00:02<00:03, 13.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:12,534 - INFO - Epoch 30/70, Train Loss: 0.5016, Val Loss: 0.8938, Val Acc: 0.5806\n",
      "2025-12-12 18:32:12,535 - INFO - EarlyStopping counter: 3 out of 10\n",
      "2025-12-12 18:32:12,608 - INFO - Epoch 31/70, Train Loss: 0.4673, Val Loss: 0.8975, Val Acc: 0.5484\n",
      "2025-12-12 18:32:12,609 - INFO - EarlyStopping counter: 4 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  44%|████▍     | 31/70 [00:02<00:02, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:12,682 - INFO - Epoch 32/70, Train Loss: 0.4438, Val Loss: 0.8560, Val Acc: 0.5484\n",
      "2025-12-12 18:32:12,683 - INFO - EarlyStopping counter: 5 out of 10\n",
      "2025-12-12 18:32:12,758 - INFO - Epoch 33/70, Train Loss: 0.4405, Val Loss: 0.8118, Val Acc: 0.6452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  47%|████▋     | 33/70 [00:02<00:02, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:12,861 - INFO - Epoch 34/70, Train Loss: 0.4537, Val Loss: 0.8208, Val Acc: 0.5806\n",
      "2025-12-12 18:32:12,862 - INFO - EarlyStopping counter: 1 out of 10\n",
      "2025-12-12 18:32:12,951 - INFO - Epoch 35/70, Train Loss: 0.4062, Val Loss: 0.9000, Val Acc: 0.4839\n",
      "2025-12-12 18:32:12,951 - INFO - EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  50%|█████     | 35/70 [00:03<00:02, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:13,034 - INFO - Epoch 36/70, Train Loss: 0.3860, Val Loss: 0.8283, Val Acc: 0.5484\n",
      "2025-12-12 18:32:13,035 - INFO - EarlyStopping counter: 3 out of 10\n",
      "2025-12-12 18:32:13,114 - INFO - Epoch 37/70, Train Loss: 0.4251, Val Loss: 0.9002, Val Acc: 0.6129\n",
      "2025-12-12 18:32:13,114 - INFO - EarlyStopping counter: 4 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  53%|█████▎    | 37/70 [00:03<00:02, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:13,194 - INFO - Epoch 38/70, Train Loss: 0.4040, Val Loss: 1.0068, Val Acc: 0.5161\n",
      "2025-12-12 18:32:13,195 - INFO - EarlyStopping counter: 5 out of 10\n",
      "2025-12-12 18:32:13,341 - INFO - Epoch 39/70, Train Loss: 0.4549, Val Loss: 0.8694, Val Acc: 0.5806\n",
      "2025-12-12 18:32:13,342 - INFO - EarlyStopping counter: 6 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  56%|█████▌    | 39/70 [00:03<00:02, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:13,417 - INFO - Epoch 40/70, Train Loss: 0.3962, Val Loss: 0.9441, Val Acc: 0.6129\n",
      "2025-12-12 18:32:13,418 - INFO - EarlyStopping counter: 7 out of 10\n",
      "2025-12-12 18:32:13,493 - INFO - Epoch 41/70, Train Loss: 0.3680, Val Loss: 0.8807, Val Acc: 0.6129\n",
      "2025-12-12 18:32:13,493 - INFO - EarlyStopping counter: 8 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  59%|█████▊    | 41/70 [00:03<00:02, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:13,570 - INFO - Epoch 42/70, Train Loss: 0.3303, Val Loss: 0.8702, Val Acc: 0.5484\n",
      "2025-12-12 18:32:13,572 - INFO - EarlyStopping counter: 9 out of 10\n",
      "2025-12-12 18:32:13,653 - INFO - Epoch 43/70, Train Loss: 0.3159, Val Loss: 0.8641, Val Acc: 0.6129\n",
      "2025-12-12 18:32:13,654 - INFO - EarlyStopping counter: 10 out of 10\n",
      "2025-12-12 18:32:13,655 - INFO - Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  60%|██████    | 42/70 [00:03<00:02, 11.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:13,660 - INFO - Loaded best model weights\n",
      "2025-12-12 18:32:13,661 - INFO - [1.1514268517494202, 0.9883494526147842, 0.9204300343990326, 0.9009385257959366, 0.8774115741252899, 0.8885339796543121, 0.8522748202085495, 0.8397817760705948, 0.8182388693094254, 0.8029266744852066, 0.7731685042381287, 0.7683285623788834, 0.7718577235937119, 0.7247912436723709, 0.7287047058343887, 0.7592594772577286, 0.7066857218742371, 0.6597284078598022, 0.6633101105690002, 0.6473288983106613, 0.6214704513549805, 0.5964439809322357, 0.5845062360167503, 0.5648430213332176, 0.5483621954917908, 0.5413946062326431, 0.5143819451332092, 0.4909096360206604, 0.5345412939786911, 0.5016388967633247, 0.4672912210226059, 0.4438416063785553, 0.4405299797654152, 0.4536689445376396, 0.4061700403690338, 0.3859664499759674, 0.42508550733327866, 0.40400509536266327, 0.45491378754377365, 0.39615825563669205, 0.367956779897213, 0.33025261759757996, 0.3159133940935135]\n",
      "2025-12-12 18:32:13,690 - INFO - network accuracy: 38.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-12 18:32:13,690 - INFO - network precision: 82.77%\n",
      "2025-12-12 18:32:13,691 - INFO - network recall: 38.78%\n",
      "2025-12-12 18:32:13,692 - INFO - network F1 score: 44.84%\n",
      "2025-12-12 18:32:13,702 - INFO - Detailed Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.86      0.35         7\n",
      "           1       0.93      0.31      0.46        42\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.39        49\n",
      "   macro avg       0.38      0.39      0.27        49\n",
      "weighted avg       0.83      0.39      0.45        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>test_precision</td><td>▁</td></tr><tr><td>test_recall</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▆▆▆▆▅▅▅▅▅▅▅▄▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▄▁▂▄▄▂▁▅▅▅▅▅▆▅▅▅▅█▅▆▆▄▅▆▆▆▆▆▅▅█▆▄▅▇▅▆▇▇▇</td></tr><tr><td>val_loss</td><td>███▇▇▇▇▆▆▆▅▄▅▃▃▇▃▅▄▆▄▃▃▃▄▂▅▄▄▂▁▁▄▂▄▇▃▅▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>43</td></tr><tr><td>test_accuracy</td><td>0.38776</td></tr><tr><td>test_f1</td><td>0.44838</td></tr><tr><td>test_precision</td><td>0.82766</td></tr><tr><td>test_recall</td><td>0.38776</td></tr><tr><td>train_loss</td><td>0.31591</td></tr><tr><td>val_accuracy</td><td>0.6129</td></tr><tr><td>val_loss</td><td>0.86408</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">breezy-fire-53</strong> at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/d6y1y1lb' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model/runs/d6y1y1lb</a><br> View project at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align-inc-model</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251212_183209-d6y1y1lb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "init_wandb()\n",
    "train_model(net5, optimizer, loss_fn, enable_early_stopping=True, patience=5)\n",
    "evaluate_model(net5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLankle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
