{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e5ad81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import wandb\n",
    "\n",
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1818c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger(name=__name__):\n",
    "    \"\"\"\n",
    "    Sets up a logger that outputs to the console (stdout).\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(name)\n",
    "    if not logger.handlers:\n",
    "        logger.setLevel(logging.INFO)\n",
    "        handler = logging.StreamHandler(sys.stdout)\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "    return logger\n",
    "\n",
    "logger = setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9925531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:09,878 - INFO - Training images shape: torch.Size([221, 3, 224, 224])\n",
      "2025-12-06 13:00:09,879 - INFO - Training labels shape: torch.Size([221])\n",
      "2025-12-06 13:00:09,880 - INFO - Label mapping: {np.str_('1_Pronacio'): 0, np.str_('2_Neutralis'): 1, np.str_('3_Szupinacio'): 2}\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_folder = \"../data\"\n",
    "preped_folder = os.path.join(data_folder, \"_preped\")\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(data_folder, 'train_data.csv')).values.tolist()\n",
    "test_data = pd.read_csv(os.path.join(data_folder, 'test_data.csv')).values.tolist()\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to consistent size\n",
    "    transforms.ToTensor(),           # Convert to tensor [0, 1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "])\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for img_name, label in train_data:\n",
    "    img_path = os.path.join(preped_folder, img_name)\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img_tensor = transform(img)\n",
    "        x_train.append(img_tensor)\n",
    "        y_train.append(label)\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Error loading {img_name}: {e}\")\n",
    "\n",
    "# Stack into tensors\n",
    "x_train_tensor = torch.stack(x_train)\n",
    "logger.info(f\"Training images shape: {x_train_tensor.shape}\")\n",
    "\n",
    "# Encode labels to integers\n",
    "label_to_idx = {label: idx for idx, label in enumerate(np.unique(y_train))}\n",
    "y_train_encoded = [label_to_idx[label] for label in y_train]\n",
    "y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.long)\n",
    "\n",
    "logger.info(f\"Training labels shape: {y_train_tensor.shape}\")\n",
    "logger.info(f\"Label mapping: {label_to_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08b676a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:17,461 - INFO - Test images shape: torch.Size([49, 3, 224, 224])\n",
      "2025-12-06 13:00:17,462 - INFO - Test labels shape: torch.Size([49])\n"
     ]
    }
   ],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for img_name, label in test_data:\n",
    "    img_path = os.path.join(preped_folder, img_name)\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img_tensor = transform(img)\n",
    "        x_test.append(img_tensor)\n",
    "        y_test.append(label)\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Error loading {img_name}: {e}\")\n",
    "\n",
    "x_test_tensor = torch.stack(x_test)\n",
    "logger.info(f\"Test images shape: {x_test_tensor.shape}\")\n",
    "y_test_encoded = [label_to_idx[label] for label in y_test]\n",
    "y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long)\n",
    "\n",
    "logger.info(f\"Test labels shape: {y_test_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "397340fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:17,504 - INFO - CUDA available: True\n",
      "2025-12-06 13:00:17,506 - INFO - Number of GPUs: 1\n",
      "2025-12-06 13:00:17,513 - INFO - \n",
      "GPU 0: NVIDIA GeForce RTX 4060\n",
      "2025-12-06 13:00:17,514 - INFO -   Memory: 8.00 GB\n",
      "2025-12-06 13:00:17,515 - INFO -   Compute Capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    logger.info(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        logger.info(f\"\\nGPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        logger.info(f\"  Memory: {props.total_memory / 1024**3:.2f} GB\")\n",
    "        logger.info(f\"  Compute Capability: {props.major}.{props.minor}\")\n",
    "else:\n",
    "    logger.info(\"CUDA not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85d3e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 15\n",
    "lr = 0.001\n",
    "device = 'cuda' \n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c21e1d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Win 10\\_netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbencefarkas\u001b[0m (\u001b[33mbencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "# wandb login an init\n",
    "# Login to wandb with API key\n",
    "load_dotenv()\n",
    "wandb.login(key=os.getenv(\"wandbKey\"))\n",
    "\n",
    "def init_wandb():\n",
    "    # Initialize wandb project\n",
    "    wandb.init(\n",
    "        project=\"ankle-align\",\n",
    "        config={\n",
    "            \"batch_size\": batch_size,\n",
    "            \"num_epochs\": num_epochs,\n",
    "            \"learning_rate\": lr,\n",
    "            \"architecture\": \"Custom CNN\",\n",
    "            \"dataset\": \"AnkleAlign\",\n",
    "            \"optimizer\": \"Adam\"\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41f6790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.001, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.best_model = None\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = model.state_dict().copy()\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                logger.info(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = model.state_dict().copy()\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "790e62ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(network, optimizer, loss_fn, enable_early_stopping=False):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    loss_values = []\n",
    "\n",
    "    if enable_early_stopping:\n",
    "        early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "    network.train()\n",
    "    for epoch in tqdm(range(num_epochs), desc='Training model'):\n",
    "        network.train()\n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "        for images, target_labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            target_labels = target_labels.to(device)\n",
    "\n",
    "            pred_logits = network(images)\n",
    "            loss = loss_fn(pred_logits, target_labels)\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        avg_train_loss = epoch_loss / num_batches\n",
    "\n",
    "        if enable_early_stopping:\n",
    "            network.eval()\n",
    "            val_loss = 0.0\n",
    "            val_batches = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for images, target_labels in val_loader:\n",
    "                    images = images.to(device)\n",
    "                    target_labels = target_labels.to(device)\n",
    "                    \n",
    "                    pred_logits = network(images)\n",
    "                    loss = loss_fn(pred_logits, target_labels)\n",
    "                    val_loss += loss.item()\n",
    "                    val_batches += 1\n",
    "                    \n",
    "                    _, predicted = torch.max(pred_logits, 1)\n",
    "                    total += target_labels.size(0)\n",
    "                    correct += (predicted == target_labels).sum().item()\n",
    "            \n",
    "            avg_val_loss = val_loss / val_batches\n",
    "            val_accuracy = correct / total\n",
    "\n",
    "        # Log metrics\n",
    "        if enable_early_stopping:\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": avg_train_loss,\n",
    "                \"val_loss\": avg_val_loss,\n",
    "                \"val_accuracy\": val_accuracy\n",
    "            })\n",
    "        else:\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": avg_train_loss\n",
    "            })\n",
    "        \n",
    "        \n",
    "        if enable_early_stopping:\n",
    "            logger.info(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "        else:\n",
    "            logger.info(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if enable_early_stopping:\n",
    "            early_stopping(avg_val_loss, network)\n",
    "            if early_stopping.early_stop:\n",
    "                logger.info(\"Early stopping triggered\")\n",
    "                network.load_state_dict(early_stopping.best_model)\n",
    "                break\n",
    "    \n",
    "    # Load best model\n",
    "    if enable_early_stopping and early_stopping.best_model is not None:\n",
    "        network.load_state_dict(early_stopping.best_model)\n",
    "        logger.info(\"Loaded best model weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a64e9301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(network):\n",
    "    # Training score\n",
    "    true_labels = y_test_encoded\n",
    "    predicted_labels = []\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = network(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = np.mean([true == pred for true, pred in zip(true_labels, predicted_labels)])\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "    logger.info(f\"network accuracy: {accuracy * 100:.2f}%\")\n",
    "    logger.info(f\"network precision: {precision * 100:.2f}%\")\n",
    "    logger.info(f\"network recall: {recall * 100:.2f}%\")\n",
    "    logger.info(f\"network F1 score: {f1 * 100:.2f}%\")\n",
    "\n",
    "    logger.info(f\"Detailed Classification Report: \\n{classification_report(true_labels, predicted_labels)}\")\n",
    "\n",
    "    # Log test metrics\n",
    "    wandb.log({\n",
    "        \"test_accuracy\": accuracy,\n",
    "        \"test_precision\": precision,\n",
    "        \"test_recall\": recall,\n",
    "        \"test_f1\": f1\n",
    "    })\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "154b2306",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),  # 224x224 -> 112x112\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # 112x112 -> 56x56\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(64 * 56 * 56, 128),  # 64 channels * 56 * 56 spatial size\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 3)  # 3 classes output\n",
    ").to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net1.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2524672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Win 10\\Desktop\\BME\\DeepL\\BMEVITMMA18_Deep-Learning_AnkleAlign_D6AE9F\\notebook\\wandb\\run-20251206_130019-m7jd05hv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align/runs/m7jd05hv' target=\"_blank\">astral-sponge-17</a></strong> to <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align/runs/m7jd05hv' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align/runs/m7jd05hv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:23,009 - INFO - Epoch 1/15, Train Loss: 6.1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   7%|▋         | 1/15 [00:00<00:06,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:23,166 - INFO - Epoch 2/15, Train Loss: 1.2604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  13%|█▎        | 2/15 [00:00<00:03,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:23,322 - INFO - Epoch 3/15, Train Loss: 0.9692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  20%|██        | 3/15 [00:00<00:02,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:23,479 - INFO - Epoch 4/15, Train Loss: 0.7975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  27%|██▋       | 4/15 [00:00<00:02,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:23,640 - INFO - Epoch 5/15, Train Loss: 0.6145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  33%|███▎      | 5/15 [00:01<00:01,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:23,797 - INFO - Epoch 6/15, Train Loss: 0.4358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  40%|████      | 6/15 [00:01<00:01,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:23,953 - INFO - Epoch 7/15, Train Loss: 0.2441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  47%|████▋     | 7/15 [00:01<00:01,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:24,111 - INFO - Epoch 8/15, Train Loss: 0.1393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  53%|█████▎    | 8/15 [00:01<00:01,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:24,268 - INFO - Epoch 9/15, Train Loss: 0.0723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  60%|██████    | 9/15 [00:01<00:00,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:24,424 - INFO - Epoch 10/15, Train Loss: 0.0801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  67%|██████▋   | 10/15 [00:01<00:00,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:24,581 - INFO - Epoch 11/15, Train Loss: 0.0704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  73%|███████▎  | 11/15 [00:02<00:00,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:24,737 - INFO - Epoch 12/15, Train Loss: 0.0691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  80%|████████  | 12/15 [00:02<00:00,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:24,894 - INFO - Epoch 13/15, Train Loss: 0.0702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  87%|████████▋ | 13/15 [00:02<00:00,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:25,051 - INFO - Epoch 14/15, Train Loss: 0.0541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  93%|█████████▎| 14/15 [00:02<00:00,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:25,207 - INFO - Epoch 15/15, Train Loss: 0.0463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 15/15 [00:02<00:00,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:25,247 - INFO - network accuracy: 28.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:00:25,248 - INFO - network precision: 88.15%\n",
      "2025-12-06 13:00:25,249 - INFO - network recall: 28.57%\n",
      "2025-12-06 13:00:25,249 - INFO - network F1 score: 28.66%\n",
      "2025-12-06 13:00:25,259 - INFO - Detailed Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      1.00      0.29         7\n",
      "           1       1.00      0.17      0.29        42\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.29        49\n",
      "   macro avg       0.39      0.39      0.19        49\n",
      "weighted avg       0.88      0.29      0.29        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>test_precision</td><td>▁</td></tr><tr><td>test_recall</td><td>▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>test_accuracy</td><td>0.28571</td></tr><tr><td>test_f1</td><td>0.28656</td></tr><tr><td>test_precision</td><td>0.88153</td></tr><tr><td>test_recall</td><td>0.28571</td></tr><tr><td>train_loss</td><td>0.04627</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">astral-sponge-17</strong> at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align/runs/m7jd05hv' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align/runs/m7jd05hv</a><br> View project at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251206_130019-m7jd05hv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_wandb()\n",
    "train_model(net1, optimizer, loss_fn)\n",
    "evaluate_model(net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9999301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train test split, for getting validation metrics during training\n",
    "x_train_tensor, x_val_tensor, y_train_tensor, y_val_tensor = train_test_split(\n",
    "    x_train_tensor, y_train_tensor, test_size=0.2, random_state=42, stratify=y_train_tensor)\n",
    "\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03fe6d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),  # 224x224 -> 112x112\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # 112x112 -> 56x56\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(64 * 56 * 56, 128),  # 64 channels * 56 * 56 spatial size\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 3)  # 3 classes output\n",
    ").to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net1.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "619d51a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Win 10\\Desktop\\BME\\DeepL\\BMEVITMMA18_Deep-Learning_AnkleAlign_D6AE9F\\notebook\\wandb\\run-20251206_131446-1yrsz930</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align/runs/1yrsz930' target=\"_blank\">sleek-lion-19</a></strong> to <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align/runs/1yrsz930' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align/runs/1yrsz930</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:14:47,486 - INFO - Epoch 1/15, Train Loss: 6.2651, Val Loss: 1.8797, Val Acc: 0.4167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   7%|▋         | 1/15 [00:00<00:07,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:14:47,680 - INFO - Epoch 2/15, Train Loss: 1.0908, Val Loss: 1.0649, Val Acc: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  13%|█▎        | 2/15 [00:00<00:04,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:14:47,815 - INFO - Epoch 3/15, Train Loss: 0.8060, Val Loss: 1.2538, Val Acc: 0.5556\n",
      "2025-12-06 13:14:47,815 - INFO - EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  20%|██        | 3/15 [00:00<00:02,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:14:47,943 - INFO - Epoch 4/15, Train Loss: 0.6775, Val Loss: 1.1957, Val Acc: 0.5556\n",
      "2025-12-06 13:14:47,943 - INFO - EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  27%|██▋       | 4/15 [00:00<00:02,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:14:48,073 - INFO - Epoch 5/15, Train Loss: 0.5917, Val Loss: 1.2129, Val Acc: 0.5278\n",
      "2025-12-06 13:14:48,073 - INFO - EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  33%|███▎      | 5/15 [00:01<00:01,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:14:48,257 - INFO - Epoch 6/15, Train Loss: 0.4481, Val Loss: 1.4125, Val Acc: 0.5556\n",
      "2025-12-06 13:14:48,258 - INFO - EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  40%|████      | 6/15 [00:01<00:01,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:14:48,382 - INFO - Epoch 7/15, Train Loss: 0.3059, Val Loss: 1.4560, Val Acc: 0.5556\n",
      "2025-12-06 13:14:48,383 - INFO - EarlyStopping counter: 5 out of 5\n",
      "2025-12-06 13:14:48,383 - INFO - Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:  40%|████      | 6/15 [00:01<00:02,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 13:14:48,386 - INFO - Loaded best model weights\n",
      "2025-12-06 13:14:48,422 - INFO - network accuracy: 65.31%\n",
      "2025-12-06 13:14:48,423 - INFO - network precision: 86.83%\n",
      "2025-12-06 13:14:48,424 - INFO - network recall: 65.31%\n",
      "2025-12-06 13:14:48,425 - INFO - network F1 score: 70.95%\n",
      "2025-12-06 13:14:48,436 - INFO - Detailed Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.86      0.44         7\n",
      "           1       0.96      0.62      0.75        42\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.65        49\n",
      "   macro avg       0.42      0.49      0.40        49\n",
      "weighted avg       0.87      0.65      0.71        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>test_precision</td><td>▁</td></tr><tr><td>test_recall</td><td>▁</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂██▇██</td></tr><tr><td>val_loss</td><td>█▁▃▂▂▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>7</td></tr><tr><td>test_accuracy</td><td>0.65306</td></tr><tr><td>test_f1</td><td>0.70945</td></tr><tr><td>test_precision</td><td>0.86825</td></tr><tr><td>test_recall</td><td>0.65306</td></tr><tr><td>train_loss</td><td>0.30589</td></tr><tr><td>val_accuracy</td><td>0.55556</td></tr><tr><td>val_loss</td><td>1.45601</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sleek-lion-19</strong> at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align/runs/1yrsz930' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align/runs/1yrsz930</a><br> View project at: <a href='https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align' target=\"_blank\">https://wandb.ai/bencefarkas-budapesti-m-szaki-s-gazdas-gtudom-nyi-egyetem/ankle-align</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251206_131446-1yrsz930\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_wandb()\n",
    "train_model(net1, optimizer, loss_fn, enable_early_stopping=True)\n",
    "evaluate_model(net1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLankle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
