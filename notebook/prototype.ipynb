{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65ac0b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b27c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "data_folder = '../data'\n",
    "image_formats = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "output_folder = os.path.join(data_folder, '_preped')\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for foldername in os.listdir(data_folder):\n",
    "    folder_path = os.path.join(data_folder, foldername)\n",
    "    if os.path.isdir(folder_path) and foldername != '_preped':\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                name, extension = os.path.splitext(filename)\n",
    "                if extension in image_formats:\n",
    "                    new_filename = f\"{foldername}_{name}{extension}\"\n",
    "                    new_file_path = os.path.join(output_folder, new_filename)\n",
    "                    shutil.copy2(file_path, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afa61801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label file found: ../data\\B8V41Y\\b8v41y.json\n",
      "Total entries updated: 20\n",
      "Label file found: ../data\\C6037J\\C6037J.json\n",
      "Total entries updated: 34\n",
      "Label file found: ../data\\consensus\\b8v41y.json\n",
      "Total entries updated: 57\n",
      "Label file found: ../data\\D6AE9F\\D6AE9F.json\n",
      "Total entries updated: 22\n",
      "No label file found in folder: ECSGGY\n",
      "Label file found: ../data\\FGWUFP\\FGWUFP.json\n",
      "Total entries updated: 20\n",
      "Label file found: ../data\\FO6K58\\FO6K58_labels.json\n",
      "Total entries updated: 32\n",
      "No label file found in folder: GI9Y8B\n",
      "Label file found: ../data\\GK1XQ4\\project-1-at-2025-10-15-23-46-9d203653.json\n",
      "Total entries updated: 52\n",
      "Label file found: ../data\\H51B9J\\H51B9J.json\n",
      "Total entries updated: 23\n",
      "Label file found: ../data\\ITWQ3V\\ITWQ3V.json\n",
      "Total entries updated: 23\n",
      "Label file found: ../data\\NC1O2T\\hf_labels_export.json\n",
      "Total entries updated: 20\n",
      "Label file found: ../data\\NX9GA4\\NX9GA4_ankles_labeled.json\n",
      "Total entries updated: 20\n",
      "Label file found: ../data\\ODZF0M\\project-2-at-2025-10-16-02-08-8ee4fdfa.json\n",
      "Total entries updated: 20\n",
      "Label file found: ../data\\OJHGS8\\OJHGS8.json\n",
      "Total entries updated: 20\n",
      "Label file found: ../data\\XV0M8Z\\AnkleAlign_Cimkezes_XV0M8Z.json\n",
      "Total entries updated: 19\n",
      "No label file found in folder: _preped\n"
     ]
    }
   ],
   "source": [
    "label_file = ''\n",
    "# Create labels folder and save modified JSON\n",
    "labels_folder = '../data/_labels'\n",
    "os.makedirs(labels_folder, exist_ok=True)\n",
    "for foldername in os.listdir(data_folder):\n",
    "    folder_path = os.path.join(data_folder, foldername)\n",
    "    if os.path.isdir(folder_path) and foldername != '_labels': \n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                name, extension = os.path.splitext(filename)\n",
    "                if extension == '.json':\n",
    "                    label_file = file_path\n",
    "                    break\n",
    "                else:\n",
    "                    label_file = 'not found'\n",
    "        if label_file == 'not found':\n",
    "            print(f\"No label file found in folder: {foldername}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Label file found: {label_file}\")\n",
    "        with open(label_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        cnt = 0\n",
    "        # Process each entry\n",
    "        for entry in data:\n",
    "            if 'file_upload' in entry:\n",
    "                # Remove labelstudio hash prefix\n",
    "                parts = entry['file_upload'].split('-', 1)  # Split only on first '-'\n",
    "                if len(parts) > 1:\n",
    "                    entry['file_upload'] = f\"{foldername}_{parts[1]}\"\n",
    "                    cnt += 1\n",
    "\n",
    "        # Get original filename and create new path\n",
    "        original_filename = os.path.basename(label_file)\n",
    "        new_label_path = os.path.join(labels_folder, original_filename)\n",
    "\n",
    "        # Save the modified JSON\n",
    "        with open(new_label_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "        print(f\"Total entries updated: {cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cdd5737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matched entries: 242\n"
     ]
    }
   ],
   "source": [
    "#Match the file names with the labels\n",
    "image_names = list(os.listdir(output_folder))\n",
    "data_ready = []\n",
    "for label_filename in os.listdir(labels_folder):\n",
    "    label_path = os.path.join(labels_folder, label_filename)\n",
    "    with open(label_path, 'r', encoding='utf-8') as f:\n",
    "        labels = json.load(f)\n",
    "    for entry in labels:\n",
    "        if 'file_upload' in entry:\n",
    "            if entry['file_upload'] in image_names:\n",
    "                result = entry['annotations'][0].get('result')\n",
    "                if len(result) > 0:\n",
    "                    label = result[0].get('value').get('choices')[0]\n",
    "                    data_ready.append((entry['file_upload'], label))\n",
    "print(f\"Total matched entries: {len(data_ready)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a7d3ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class: 1_Pronacio\n"
     ]
    }
   ],
   "source": [
    "# Get the majority class\n",
    "labels = [label for _, label in data_ready]\n",
    "# Reaname the 3 wrong labels:\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 'neutral': labels[i] = '2_Neutralis'\n",
    "    elif labels[i] == 'pronation': labels[i] = '1_Pronacio'\n",
    "    elif labels[i] == 'supination': labels[i] = '3_Szupinacio'\n",
    "\n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "majority_class = unique_labels[np.argmax(counts)]\n",
    "print(f\"Majority class: {majority_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "024a0052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 43.39%\n",
      "Baseline precision: 18.83%\n",
      "Baseline recall: 43.39%\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  1_Pronacio       0.43      1.00      0.61       105\n",
      " 2_Neutralis       0.00      0.00      0.00        98\n",
      "3_Szupinacio       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.43       242\n",
      "   macro avg       0.14      0.33      0.20       242\n",
      "weighted avg       0.19      0.43      0.26       242\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\anaconda3\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Asus\\anaconda3\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Asus\\anaconda3\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Asus\\anaconda3\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "# Baseline: Always predict the majority class\n",
    "def baseline_predict(data):\n",
    "    return [majority_class] * len(data)\n",
    "\n",
    "# Evaluate baseline accuracy\n",
    "true_labels = labels\n",
    "predicted_labels = baseline_predict(data_ready)\n",
    "accuracy = np.mean([true == pred for true, pred in zip(true_labels, predicted_labels)])\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "print(f\"Baseline accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Baseline precision: {precision * 100:.2f}%\")\n",
    "print(f\"Baseline recall: {recall * 100:.2f}%\")\n",
    "\n",
    "# For detailed per-class metrics\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "850f8f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in consensus: 57\n",
      "Unique images (appearing exactly once): 49\n",
      "Duplicate images removed: 8\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Read what picture are in consensus text file\n",
    "consensus_file_path =  os.path.join(data_folder, 'consensus/anklealign-consensus.txt')\n",
    "with open(consensus_file_path, 'r', encoding='utf-8') as f:\n",
    "    consensus_images = f.read().splitlines()\n",
    "\n",
    "img_names = []\n",
    "# Get every image name from the consensus file\n",
    "for img in consensus_images:\n",
    "    parts = img.split('\\\\')\n",
    "    if len(parts) > 1:\n",
    "        img_names.append(parts[-1])\n",
    "\n",
    "# Count occurrences of each image name\n",
    "img_counts = Counter(img_names)\n",
    "\n",
    "# Keep only images that appear exactly once\n",
    "unique_consensus_image_names = [img for img, count in img_counts.items() if count == 1]\n",
    "\n",
    "print(f\"Total images in consensus: {len(img_names)}\")\n",
    "print(f\"Unique images (appearing exactly once): {len(unique_consensus_image_names)}\")\n",
    "print(f\"Duplicate images removed: {len(img_names) - len(unique_consensus_image_names)}\")\n",
    "\n",
    "unique_consensus_images = []\n",
    "\n",
    "# Rename the images as the prepared data\n",
    "for img in consensus_images:\n",
    "    parts = img.split('\\\\')\n",
    "    if len(parts) > 1 and parts[2] in unique_consensus_image_names:\n",
    "        unique_consensus_images.append(f\"{parts[1]}_{parts[2]}\")\n",
    "print(len(unique_consensus_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df466d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matched consensus entries: 23\n"
     ]
    }
   ],
   "source": [
    "# Match the consensus images with the prepared data\n",
    "matched_consensus = []\n",
    "for img in unique_consensus_images:\n",
    "    for data_img, _ in data_ready:\n",
    "        if img == data_img:\n",
    "            matched_consensus.append((data_img))\n",
    "\n",
    "print(f\"Total matched consensus entries: {len(matched_consensus)}\")\n",
    "\n",
    "train_data = [(img, label) for img, label in data_ready if img not in matched_consensus]\n",
    "test_data = unique_consensus_images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLankle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
