{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87385239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from collections import Counter\n",
    "import logging\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0403e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger(name=__name__):\n",
    "    \"\"\"\n",
    "    Sets up a logger that outputs to the console (stdout).\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(name)\n",
    "    if not logger.handlers:\n",
    "        logger.setLevel(logging.INFO)\n",
    "        handler = logging.StreamHandler(sys.stdout)\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "    return logger\n",
    "\n",
    "logger = setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0562af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename images to avoid name conflicts and copy to _preped folder\n",
    "data_folder = '../data/pre-downloaded'\n",
    "image_formats = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "preped_folder = os.path.join(data_folder, '_preped')\n",
    "os.makedirs(preped_folder, exist_ok=True)\n",
    "\n",
    "for foldername in os.listdir(data_folder):\n",
    "    folder_path = os.path.join(data_folder, foldername)\n",
    "    if os.path.isdir(folder_path) and foldername != '_preped':\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                name, extension = os.path.splitext(filename)\n",
    "                if extension in image_formats:\n",
    "                    new_filename = f\"{foldername}_{name}{extension}\"\n",
    "                    new_file_path = os.path.join(preped_folder, new_filename)\n",
    "                    shutil.copy2(file_path, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fabad135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-10 17:59:40,168 - INFO - Label file found: ../data/pre-downloaded\\B8V41Y\\b8v41y.json\n",
      "2025-12-10 17:59:40,176 - INFO - Total entries updated: 20\n",
      "2025-12-10 17:59:40,178 - INFO - Label file found: ../data/pre-downloaded\\C6037J\\C6037J.json\n",
      "2025-12-10 17:59:40,188 - INFO - Total entries updated: 34\n",
      "2025-12-10 17:59:40,190 - INFO - Label file found: ../data/pre-downloaded\\D6AE9F\\D6AE9F.json\n",
      "2025-12-10 17:59:40,197 - INFO - Total entries updated: 22\n",
      "2025-12-10 17:59:40,201 - INFO - No label file found in folder: ECSGGY\n",
      "2025-12-10 17:59:40,203 - INFO - Label file found: ../data/pre-downloaded\\FGWUFP\\FGWUFP.json\n",
      "2025-12-10 17:59:40,209 - INFO - Total entries updated: 20\n",
      "2025-12-10 17:59:40,211 - INFO - Label file found: ../data/pre-downloaded\\FO6K58\\FO6K58_labels.json\n",
      "2025-12-10 17:59:40,223 - INFO - Total entries updated: 32\n",
      "2025-12-10 17:59:40,228 - INFO - No label file found in folder: GI9Y8B\n",
      "2025-12-10 17:59:40,232 - INFO - Label file found: ../data/pre-downloaded\\GK1XQ4\\project-1-at-2025-10-15-23-46-9d203653.json\n",
      "2025-12-10 17:59:40,247 - INFO - Total entries updated: 52\n",
      "2025-12-10 17:59:40,249 - INFO - Label file found: ../data/pre-downloaded\\H51B9J\\H51B9J.json\n",
      "2025-12-10 17:59:40,255 - INFO - Total entries updated: 23\n",
      "2025-12-10 17:59:40,257 - INFO - Label file found: ../data/pre-downloaded\\ITWQ3V\\ITWQ3V.json\n",
      "2025-12-10 17:59:40,263 - INFO - Total entries updated: 23\n",
      "2025-12-10 17:59:40,264 - INFO - Label file found: ../data/pre-downloaded\\NC1O2T\\hf_labels_export.json\n",
      "2025-12-10 17:59:40,274 - INFO - Total entries updated: 20\n",
      "2025-12-10 17:59:40,276 - INFO - Label file found: ../data/pre-downloaded\\NX9GA4\\NX9GA4_ankles_labeled.json\n",
      "2025-12-10 17:59:40,283 - INFO - Total entries updated: 20\n",
      "2025-12-10 17:59:40,292 - INFO - Label file found: ../data/pre-downloaded\\ODZF0M\\project-2-at-2025-10-16-02-08-8ee4fdfa.json\n",
      "2025-12-10 17:59:40,307 - INFO - Total entries updated: 20\n",
      "2025-12-10 17:59:40,311 - INFO - Label file found: ../data/pre-downloaded\\OJHGS8\\OJHGS8.json\n",
      "2025-12-10 17:59:40,341 - INFO - Total entries updated: 20\n",
      "2025-12-10 17:59:40,343 - INFO - Label file found: ../data/pre-downloaded\\sample\\project-1-at-2025-09-30-21-17-d687dfd4.json\n",
      "2025-12-10 17:59:40,345 - INFO - Total entries updated: 2\n",
      "2025-12-10 17:59:40,347 - INFO - Label file found: ../data/pre-downloaded\\XV0M8Z\\AnkleAlign_Cimkezes_XV0M8Z.json\n",
      "2025-12-10 17:59:40,355 - INFO - Total entries updated: 19\n",
      "2025-12-10 17:59:40,392 - INFO - No label file found in folder: _preped\n"
     ]
    }
   ],
   "source": [
    "label_file = ''\n",
    "# Create labels folder and save modified JSON\n",
    "labels_folder = '../data/_labels'\n",
    "os.makedirs(labels_folder, exist_ok=True)\n",
    "for foldername in os.listdir(data_folder):\n",
    "    folder_path = os.path.join(data_folder, foldername)\n",
    "    if os.path.isdir(folder_path) and foldername != '_labels' and foldername != 'consensus': \n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                name, extension = os.path.splitext(filename)\n",
    "                if extension == '.json':\n",
    "                    label_file = file_path\n",
    "                    break\n",
    "                else:\n",
    "                    label_file = 'not found'\n",
    "        if label_file == 'not found':\n",
    "            logger.info(f\"No label file found in folder: {foldername}\")\n",
    "            continue\n",
    "\n",
    "        logger.info(f\"Label file found: {label_file}\")\n",
    "        with open(label_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        cnt = 0\n",
    "        # Process each entry\n",
    "        for entry in data:\n",
    "            if 'file_upload' in entry:\n",
    "                # Remove labelstudio hash prefix\n",
    "                parts = entry['file_upload'].split('-', 1)  # Split only on first '-'\n",
    "                if len(parts) > 1:\n",
    "                    entry['file_upload'] = f\"{foldername}_{parts[1]}\"\n",
    "                    cnt += 1\n",
    "\n",
    "        # Get original filename and create new path\n",
    "        original_filename = os.path.basename(label_file)\n",
    "        new_label_path = os.path.join(labels_folder, original_filename)\n",
    "\n",
    "        # Save the modified JSON\n",
    "        with open(new_label_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "        logger.info(f\"Total entries updated: {cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1699d11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-10 17:59:40,419 - INFO - Total matched entries: 264\n"
     ]
    }
   ],
   "source": [
    "#Match the file names with the labels\n",
    "image_names = list(os.listdir(preped_folder))\n",
    "data_ready = []\n",
    "for label_filename in os.listdir(labels_folder):\n",
    "    label_path = os.path.join(labels_folder, label_filename)\n",
    "    with open(label_path, 'r', encoding='utf-8') as f:\n",
    "        labels = json.load(f)\n",
    "    for entry in labels:\n",
    "        if 'file_upload' in entry:\n",
    "            if entry['file_upload'] in image_names:\n",
    "                result = entry['annotations'][0].get('result')\n",
    "                if len(result) > 0:\n",
    "                    label = result[0].get('value').get('choices')[0]\n",
    "                    data_ready.append((entry['file_upload'], label))\n",
    "logger.info(f\"Total matched entries: {len(data_ready)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d5970cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reaname the 3 wrong labels:\n",
    "for i in range(len(data_ready)):\n",
    "    imge_name, label = data_ready[i]\n",
    "    if label == 'neutral': data_ready[i] = (imge_name, '2_Neutralis')\n",
    "    elif label == 'pronation': data_ready[i] = (imge_name, '1_Pronacio')\n",
    "    elif label == 'supination': data_ready[i] = (imge_name, '3_Szupinacio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "215e7ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-10 17:59:40,446 - INFO - Total images in consensus: 57\n",
      "2025-12-10 17:59:40,447 - INFO - Unique images (appearing exactly once): 49\n",
      "2025-12-10 17:59:40,448 - INFO - Duplicate images removed: 8\n"
     ]
    }
   ],
   "source": [
    "# Read what picture are in consensus text file\n",
    "consensus_file_path =  os.path.join(data_folder, 'consensus')\n",
    "consensus_file = os.path.join(consensus_file_path, 'anklealign-consensus.txt')\n",
    "with open(consensus_file, 'r', encoding='utf-8') as f:\n",
    "    consensus_images = f.read().splitlines()\n",
    "\n",
    "img_names = []\n",
    "# Get every image name from the consensus file\n",
    "for img in consensus_images:\n",
    "    parts = img.split('\\\\')\n",
    "    if len(parts) > 1:\n",
    "        img_names.append(parts[-1])\n",
    "\n",
    "# Count occurrences of each image name\n",
    "img_counts = Counter(img_names)\n",
    "\n",
    "# Keep only images that appear exactly once\n",
    "unique_consensus_image_names = [img for img, count in img_counts.items() if count == 1]\n",
    "\n",
    "logger.info(f\"Total images in consensus: {len(img_names)}\")\n",
    "logger.info(f\"Unique images (appearing exactly once): {len(unique_consensus_image_names)}\")\n",
    "logger.info(f\"Duplicate images removed: {len(img_names) - len(unique_consensus_image_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7fe2600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_label_matrix = pd.DataFrame({\n",
    "    'image': unique_consensus_image_names,\n",
    "    '1_Pronacio': 0,\n",
    "    '2_Neutralis': 0,\n",
    "    '3_Szupinacio': 0\n",
    "})\n",
    "\n",
    "for consensus_label_file in os.listdir(consensus_file_path):\n",
    "    extension = os.path.splitext(consensus_label_file)[1]\n",
    "    consensus_label_path = os.path.join(consensus_file_path, consensus_label_file)\n",
    "    if extension != '.json' or os.path.getsize(consensus_label_path) == 0:\n",
    "        continue\n",
    "\n",
    "    with open(consensus_label_path, 'r', encoding='utf-8') as f:\n",
    "        labels = json.load(f)\n",
    "    for entry in labels:\n",
    "        if 'file_upload' in entry:\n",
    "            img_name = entry['file_upload'].split('-', 1)[1]  # Remove hash prefix\n",
    "            if img_name in unique_consensus_image_names:\n",
    "                result = entry['annotations'][0].get('result')\n",
    "                if len(result) > 0:\n",
    "                    label = result[0].get('value').get('choices')[0]\n",
    "                    if label == '1_Pronacio':\n",
    "                        consensus_label_matrix.loc[consensus_label_matrix['image'] == img_name, '1_Pronacio'] += 1\n",
    "                    elif label == '2_Neutralis':\n",
    "                        consensus_label_matrix.loc[consensus_label_matrix['image'] == img_name, '2_Neutralis'] += 1\n",
    "                    elif label == '3_Szupinacio':\n",
    "                        consensus_label_matrix.loc[consensus_label_matrix['image'] == img_name, '3_Szupinacio'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72520f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-10 17:59:41,260 - INFO - Total unique consensus images: 49\n"
     ]
    }
   ],
   "source": [
    "unique_consensus_images = []\n",
    "\n",
    "# Rename the images as the prepared data\n",
    "for img in consensus_images:\n",
    "    parts = img.split('\\\\')\n",
    "    if len(parts) > 1 and parts[2] in unique_consensus_image_names:\n",
    "        row = consensus_label_matrix.loc[consensus_label_matrix['image'] == parts[2]]\n",
    "        max_col = row[['1_Pronacio', '2_Neutralis', '3_Szupinacio']].idxmax(axis=1).values[0]\n",
    "        label = max_col\n",
    "        unique_consensus_images.append((f\"{parts[1]}_{parts[2]}\", label))\n",
    "logger.info(f\"Total unique consensus images: {len(unique_consensus_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe298a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-10 17:59:41,273 - INFO - Total training data: 241\n",
      "2025-12-10 17:59:41,274 - INFO - Total testing data: 49\n"
     ]
    }
   ],
   "source": [
    "# Match the consensus images with the prepared data\n",
    "matched_consensus = []\n",
    "for img, _ in unique_consensus_images:\n",
    "    for data_img, _ in data_ready:\n",
    "        if img == data_img:\n",
    "            matched_consensus.append((data_img))\n",
    "\n",
    "train_data = [(img, label) for img, label in data_ready if img not in matched_consensus]\n",
    "test_data = unique_consensus_images\n",
    "\n",
    "logger.info(f\"Total training data: {len(train_data)}\")\n",
    "logger.info(f\"Total testing data: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9b9875c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train and test data to files\n",
    "\n",
    "pd.DataFrame(train_data, columns=['image', 'label']).to_csv(os.path.join(data_folder, 'train_data.csv'), index=False)\n",
    "pd.DataFrame(test_data, columns=['image', 'label']).to_csv(os.path.join(data_folder, 'test_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd2b3918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-10 17:59:41,303 - INFO - Majority class: 2_Neutralis\n",
      "2025-12-10 17:59:41,319 - INFO - Baseline accuracy: 46.55%\n",
      "2025-12-10 17:59:41,320 - INFO - Baseline precision: 21.67%\n",
      "2025-12-10 17:59:41,320 - INFO - Baseline recall: 46.55%\n",
      "2025-12-10 17:59:41,321 - INFO - Baseline F1-score: 29.57%\n",
      "2025-12-10 17:59:41,330 - INFO - Detailed Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  1_Pronacio       0.00      0.00      0.00       119\n",
      " 2_Neutralis       0.47      1.00      0.64       135\n",
      "3_Szupinacio       0.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           0.47       290\n",
      "   macro avg       0.16      0.33      0.21       290\n",
      "weighted avg       0.22      0.47      0.30       290\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\conda-envs\\envs\\DLankle\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Get the majority class\n",
    "all_data = train_data + test_data\n",
    "labels = [label for _, label in all_data]\n",
    "\n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "majority_class = unique_labels[np.argmax(counts)]\n",
    "logger.info(f\"Majority class: {majority_class}\")\n",
    "\n",
    "# Baseline: Always predict the majority class\n",
    "def baseline_predict(data):\n",
    "    return [majority_class] * len(data)\n",
    "\n",
    "# Evaluate baseline accuracy\n",
    "true_labels = labels\n",
    "predicted_labels = baseline_predict(all_data)\n",
    "accuracy = np.mean([true == pred for true, pred in zip(true_labels, predicted_labels)])\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "logger.info(f\"Baseline accuracy: {accuracy * 100:.2f}%\")\n",
    "logger.info(f\"Baseline precision: {precision * 100:.2f}%\")\n",
    "logger.info(f\"Baseline recall: {recall * 100:.2f}%\")\n",
    "logger.info(f\"Baseline F1-score: {f1 * 100:.2f}%\")\n",
    "\n",
    "# For detailed per-class metrics\n",
    "logger.info(f\"Detailed Classification Report: \\n{classification_report(true_labels, predicted_labels)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLankle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
